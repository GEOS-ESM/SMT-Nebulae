{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SMT Knowledge Base","text":"<p>We are the Software Modernization Team (SMT), part of ASTG, NASA's Advanced Software Technology Group. Welcome to our knowledge base.</p> <p>This knowledge base serves to document</p> <ul> <li>results &amp; progress of the 24-26 project</li> <li>how to setup a development environment</li> <li>how to work with GEOS</li> <li>notes on porting</li> </ul> <p>and more. Easiest is to use the search function or browsing the navigation on the side.</p>"},{"location":"#other-documentation","title":"Other documentation","text":"<ul> <li>NASA/NOAA DSL middleware</li> <li>DaCe</li> <li>GT4Py Cartesian</li> </ul>"},{"location":"GEOS/","title":"GEOS model","text":"<p>Website | GitHub</p> <p>The Goddard Earth Observing System (GEOS) model consists of a group of model components that can be connected in a flexible manner in order to address questions related to different aspects of Earth Science.</p>"},{"location":"GEOS/#resolution","title":"Resolution","text":"<p>GEOS uses a spherical cube to as discretization of the earth. Resolution is usually given in the form Cxxx / Lxx, e.g. C1120 / L191, where <code>L</code> denotes the number of vertical levels and <code>C</code> encodes the horizontal resolution as number of grid points per axis on a cube side. Sticking with the example of C1120 / L191, we have</p> <ul> <li>1120 grid points per horizontal axis</li> <li>1120 x 1120 grid points per cube side</li> <li>6 x 1120 x 1120 grid points for the full cube</li> <li>and 191 vertical levels (for all sides of the cube)</li> </ul> <p>The following table \"translates\" Cxxx to approximate horizontal resolution in kilo meters and GEOS common resolutions. Production runs marked with *.</p> <pre><code>{ \n    'C12'  : 773.91\n    'C24'  : 386.52\n    'C48'  : 193.07\n    'C90'  : 102.91\n    'C180' : 51.44\n    'C270' : 40\n    'C360' : 25.71\n    'C540' : 19\n    'C720' : 12.86 *\n    'C1080': 10    *\n    'C1120': 8.26  *\n    'C1440': 6.43\n    'C1539': 6\n    'C2160': 5\n    'C2880': 3.21\n    'C5760': 1.61\n}\n</code></pre>"},{"location":"GEOS/#vertical-pressure-level-data-eta-files","title":"Vertical pressure level data (\"eta files\")","text":"<p>FV3, the dynamical core in GEOS, requires so called \"eta files\" as input to run. These files contain pressure at every level. According to Lucas Harris,</p> <p> </p> <p>the values are typically hard-coded as there is no real formula for generating \"good\" level setups.</p> <p>NDSL ships two eta files (79 and 91 levels) in its test data, which are required to run NDSL tests and re-used in PyFV3 tests and examples. FV3 has many more pre-defined pressure-level configurations. If we ever get to a point that we need them, start re-reading in this issue on how to extract that information from the fortran files.</p>"},{"location":"GEOS/discover_build/","title":"Build &amp; Run GEOS on Discover","text":""},{"location":"GEOS/discover_build/#deploying-smt-stack-via-modules","title":"Deploying SMT stack via modules","text":"<p>On <code>Discover</code>, we have a pre-built stack that is accessible via <code>module load</code>.</p> <ul> <li><code>module use -a &lt;Path to SMT-Nebulae Repo&gt;/sw_stack/discover/sles15/modulefiles</code> adds the various stack versions to your module list</li> <li><code>ml SMTStack/YYYY.MM.PP</code> to load the targeted version of the stack</li> </ul> <p>For development, a module <code>SMTStack/YYYY.MM.PP-no-venv</code> is available that doesn't pull <code>ndsl</code> or any other python packages.</p> <p>Versions of all the software in the stack are present in <code>/discover/nobackup/projects/geosongpu/sw_sles15/HISTORY.md</code></p>"},{"location":"GEOS/discover_build/#build-run-geos","title":"Build &amp; Run GEOS","text":"<ul> <li>Git clone the root of GEOS then using <code>mepo</code>, you clone the rest of the components which pull on the <code>components.yaml</code> at the root of <code>GEOSgcm</code><ul> <li>There are two sources for a component: the default and the <code>develop</code> source</li> <li><code>v11.5.2</code> is our baseline GEOS version (or tag), but we have <code>dsl/develop</code> branch where needed</li> <li>We do not use <code>develop</code> for <code>GEOSgcm_App</code> or <code>cmake</code> since those have been setup for OpenACC but are not up-to-date for <code>v11.5.2</code></li> </ul> </li> </ul> <pre><code>git clone -b dsl/develop git@github.com:GEOS-ESM/GEOSgcm.git geos\ncd geos\nmepo clone --partial blobless\nmepo develop env GEOSgcm GEOSgcm_GridComp FVdycoreCubed_GridComp pyFV3\n</code></pre> <ul> <li>Use CMake to set up the GEOS makefile that uses the SMT stack.</li> <li>Then <code>make install</code>. Grab a coffee (or 2)<ul> <li>We override the compiler with their <code>mpi</code> counterpart to make sure <code>libmpi</code> is pulled properly. CMake should deal with that, but there's some failure floating around.</li> </ul> </li> </ul> <p>Single script to execute both cmake &amp; make to install GEOS:</p> <pre><code>module use -a SW_STACK/modulefiles\nml SMTStack/2024.04.00\n\nmkdir -p build\ncd build\nexport TMP=GEOS_DIR/geos/build/tmp\nexport TMPDIR=$TMP\nexport TEMP=$TMP\nmkdir $TMP\necho $TMP\n\nexport FC=mpif90\nexport CC=mpicc\nexport CXX=mpic++\n\ncmake .. -DBASEDIR=$BASEDIR/Linux \\\n         -DCMAKE_Fortran_COMPILER=mpif90 \\\n         -DBUILD_PYFV3_INTERFACE=ON \\\n         -DCMAKE_INSTALL_PREFIX=../install \\\n         -DPython3_EXECUTABLE=`which python3`\n\nmake -j48 install\n</code></pre> <ul> <li>Matt T. prepared us some GEOS-FP like data. Copy them from <code>/discover/nobackup/projects/geosongpu/geos_data/geos-fp/stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-cX-L137</code> where the <code>X</code> in <code>cX</code> is set as the resolution from {24, 180, 720}</li> <li>We need to set a soft link to the <code>GEOSgcm.x</code> executable from the GEOS <code>install/bin</code> directory, e.g.</li> </ul> <pre><code>cd &lt;PATH_TO&gt;/stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-cX-L137\nln -s &lt;PATH_TO_geos&gt;/install/bin/GEOSgcm.x GEOSgcm.x\n</code></pre> <ul> <li>We then need to edit the <code>gcm_run.j</code> to make it local to our experience directory and have the job parameters match our account and the GPU partition.  The following assumes that we're running c24 GEOS-FP experiment.</li> </ul> <p>gcm_run.j</p> <pre><code>#SBATCH --time=0:30:00\n- #SBATCH --nodes=1 --ntasks-per-node=126\n+ #SBATCH --nodes=1 --ntasks-per-node=48\n- #SBATCH --job-name=stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-c24-L137_RUN\n+ #SBATCH --job-name=NDSL-geos-fp\n- #SBATCH --constraint=mil\n+ #SBATCH --constraint=rome\n- #SBATCH --account=g0620\n+ #SBATCH --account=j1013\n- #SBATCH --partition=preops\n+ #SBATCH --partition=gpu_a100\n- #SBATCH --qos=benchmark\n+ #SBATCH --qos=4n_a100\n- #SBATCH --mail-type=ALL\n</code></pre> <pre><code>setenv SITE             NCCS\n- setenv GEOSDIR          /gpfsm/dnb05/projects/p50/Models/GEOSgcm-v11.5.2-GNU-SLES15/GEOSgcm/install-Release\n+ setenv GEOSDIR          PATH_TO_GEOS/install/\n- setenv GEOSBIN          /gpfsm/dnb05/projects/p50/Models/GEOSgcm-v11.5.2-GNU-SLES15/GEOSgcm/install-Release/bin\n+ setenv GEOSBIN          PATH_TO_GEOS/install/bin\n- setenv GEOSETC          /gpfsm/dnb05/projects/p50/Models/GEOSgcm-v11.5.2-GNU-SLES15/GEOSgcm/install-Release/etc\n+ setenv GEOSETC          PATH_TO_GEOS/install/etc\n- setenv GEOSUTIL         /gpfsm/dnb05/projects/p50/Models/GEOSgcm-v11.5.2-GNU-SLES15/GEOSgcm/install-Release\n+ setenv GEOSUTIL         PATH_TO_GEOS/install/\n</code></pre> <pre><code>setenv  EXPID   stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-c24-L137\n- setenv  EXPDIR  /discover/nobackup/mathomp4/Experiments/RunsForFlorian/stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-c24-L137\n+ setenv  EXPDIR  PATH_TO_EXP_DIR/stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-c24-L137\n- setenv  HOMDIR  /discover/nobackup/mathomp4/Experiments/RunsForFlorian/stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-c24-L137\n+ setenv  HOMDIR  PATH_TO_EXP_DIR/stock-v11.5.2-1day-GNU-NH-GDATA-RRTMGP-GFDL-GF2020-OPS-c24-L137\n</code></pre> <ul> <li>The pipeline of GEOSgcm calculates the numbers of process required based on the <code>NX/NY</code> given in <code>AGCM.rc</code>. Previously we modified the sbatch parameters to be <code>--ntasks-per-node=48</code> to fit within a Rome node. Therefore, we need to adapt the <code>AGCM.rc</code></li> </ul> <p>AGCM.rc</p> <pre><code># Atmospheric Model Configuration Parameters\n# ------------------------------------------\n- NX: 4\n+ NX: 2\n- NY: 24\n+ NY: 12\n</code></pre> <ul> <li> <p>Running the simulation on the compute node is now as simple as a <code>sbatch gcm_run.j</code>. The environment will be loaded via <code>PATH_TO_GEOS/@env/g5_modules</code>. Logged will be dumped in <code>slurm-XXXXX.out</code></p> </li> <li> <p>To run the <code>pyFV3</code> version, modification to the <code>AGCM.rc</code> and <code>gcm_run.j</code>. This will run the <code>numpy</code> backend.</p> </li> </ul> <p>AGCM.rc</p> <pre><code>###########################################################\n# dynamics options\n# ----------------------------------------\nDYCORE: FV3\n FV3_CONFIG: HWT\n+ RUN_PYFV3: 1\nAdvCore_Advection: 0\n</code></pre> <p>gcm_run.j</p> <pre><code>setenv RUN_CMD \"$GEOSBIN/esma_mpirun -np \"\n\nsetenv GCMVER `cat $GEOSETC/.AGCM_VERSION`\necho   VERSION: $GCMVER\n\n+setenv FV3_DACEMODE           Python\n+setenv GEOS_PYFV3_BACKEND     numpy\n+setenv PACE_CONSTANTS         GEOS\n+setenv PACE_FLOAT_PRECISION   32\n+setenv PYTHONOPTIMIZE         1\n+setenv PACE_LOGLEVEL          Debug\n\n+setenv FVCOMP_DIR PATH_TO_GEOS/src/Components/@GEOSgcm_GridComp/GEOSagcm_GridComp/GEOSsuperdyn_GridComp/@FVdycoreCubed_GridComp/\n+setenv PYTHONPATH $FVCOMP_DIR/python/interface:$FVCOMP_DIR/python/@pyFV3\n\n\n#######################################################################\n#             Experiment Specific Environment Variables\n######################################################################\n</code></pre>"},{"location":"GEOS/gh200/","title":"Running GEOS on Prism's GH200","text":""},{"location":"GEOS/gh200/#logging-into-prisms-gh200","title":"Logging into Prism's GH200","text":"<ol> <li><code>ssh</code> into the Adapt system : <code>ssh adapt.nccs.nasa.gov</code></li> <li>Once logged into <code>adapt</code>,  <code>ssh</code> into <code>gpulogin1</code> : <code>ssh gpulogin1</code></li> <li>Once logged into <code>gpulogin1</code>, a user can get an interactive GH200 node via <code>salloc</code> : <code>salloc -p grace --nodes=1 --gpus-per-node=1</code></li> </ol> <p>\u26a0\ufe0f NOTE : Always <code>salloc</code> onto a GH node - currently, <code>adapt</code> and <code>gpulogin</code> nodes are x86 but GH nodes are ARM64 \u26a0\ufe0f</p>"},{"location":"GEOS/gh200/#gh200-ndsl-modules","title":"GH200 NDSL Modules","text":"<p>Access preset NDSL modules via <code>ml use -a /explore/nobackup/people/fgdeconi/work/modules/modules</code>.  From there, NDSL modules are viewable when <code>module av</code> is run.</p> <pre><code>$ ml use -a /explore/nobackup/people/fgdeconi/work/modules/modules\n$ module av\n\n----------------------------------------------------- /panfs/ccds02/app/modulefiles_aarch64/core -----------------------------------------------------\n   binutils/2.44    gcc/11.2.0            (D)    go/1.23.1          miniforge/24.9.2     nvidia/12.1       (D)\n   clang/18.1.2     gcc/12.1.0                   go/1.24.1   (D)    mvapich4-plus/4.1    nvidia/12.5\n   emacs/31.0.50    gcc/14.2.0                   gsl/2.8            netcdf4/4.9.3s       nvidia/12.8\n   gcc/9.2.0        gnu_parallel/20210422        llvm/10.0          nvidia/11.7          singularity/4.3.1\n   gcc/10.1.0       gnu_parallel/20250322 (D)    llvm/20.1.0 (D)    nvidia/12.0          ucx/1.19.0        (D)\n\n----------------------------------------------- /explore/nobackup/people/fgdeconi/work/modules/modules -----------------------------------------------\n   baselibs/8.14.0    dsl/build_geos        openblas/0.3.29    openmpi/4.1.8 (D)    ucx/1.15.0\n   cuda/12.1          dsl/runtime    (D)    openmpi/4.1.6      python/3.11.7        ucx/1.18.1\n</code></pre> <p>\u26a0\ufe0f NOTE : Load modules after <code>ssh</code>ing into the GH box! \u26a0\ufe0f</p>"},{"location":"GEOS/gh200/#building-geos","title":"Building GEOS","text":"<p>Module <code>dsl/build_geos</code> loads all required modules for building GEOS:</p> <ul> <li>Compilers are <code>gcc</code> / <code>g++</code> / <code>gfortran</code></li> <li><code>nvidia</code> suite is not loaded on purpose, or else the <code>mpicc/c++/f90</code> will default to Nvidia's compiler which are not capable of compiling GEOS</li> </ul>"},{"location":"GEOS/gh200/#running-geos","title":"Running GEOS","text":"<p>Once GEOS is built, running GEOS + NDSL requires you to fiddle with the compilers.</p> <p>First we load &amp; install the stack w/ proper nvidia support:</p> <ul> <li>load <code>nvidia/12.8</code>: your default compilers are now the <code>NVHPC</code> suite (nvc/nvc++/nvcc). Those are faulty for C/C++, we will need to enforce GNU</li> <li>load/create a conda environment with python <code>3.9</code>. Once the stack is installed, re-installed MPI4Py with the following</li> </ul> <pre><code># To link the correct MPI to be linked in\nCC=nvc CFLAGS=\"-noswitcherror\" pip install --force --no-cache-dir --no-binary=mpi4py mpi4py\n</code></pre> <p>We can then run GEOS with the following env modifications:</p> <ul> <li>In your <code>gcm_run.j</code> (or before running) export as follows to force compiler &amp; fix UCX interface</li> </ul> <p>For GPU backends</p> <pre><code>#CSH-style\nsetenv CC gcc # restore C compiler to GNU\nsetenv CXX g++ # restore C++ compiler to GNU\nsetenv CUDA_HOST_CXX g++ # force nvcc host compiler to GNU (GT4Py specific)\nsetenv CUDA_HOME $NVHPC_ROOT/cuda # help GT4Py found the nvcc binary\nsetenv UCX_NET_DEVICES mlx5_2:1\n</code></pre> <p>For CPU backends, the same but comment out the <code>CUDA_HOST_CXX</code>.</p> <p>To run <code>nsys</code> with a low overhead you can prefix the <code>mpirun</code> call with</p> <pre><code>nsys profile --output report_%h_%p.nsys-rep \\ # Output file name, unique\n             --trace=\"cuda,nvtx\" \\ # Trace only the cuda and nvtx event\n             --cuda-event-trace=false \\ # Deactivate to reduce overhead\n             --sample=none \\ # No CPU sampling (overhead--)\n             --cpuctxsw=none \\ # No process switch tracking (overhead--)\n             --stats=true \\ # Optional, bigger files but print some stats\n</code></pre>"},{"location":"GEOS/gh200/#common-issues","title":"Common issues","text":"<ul> <li> <p>I hit a <code>@GLIBCXX_3.4.32 cannot load library</code> error: your GCC module is the x86 one, you need to reload <code>module reload gcc/14.2.0</code></p> </li> <li> <p>I hit a <code>--ccbin unknown options</code>: you have <code>CUDA_HOST_CXX</code> set in your env, and GT4Py is misdirecting the GPU host linker flag onto GCC. Unset variable.</p> </li> </ul>"},{"location":"GEOS/gh200/#gh200-timings-on-c180-problem","title":"GH200 Timings on C180 Problem","text":"<p>This is the timing breakdown within the GEOS run region executing Fortran-only code.</p> <pre><code>--Run                                                     1 30131.367  99.87     1.082   0.00\n----EXTDATA                                            1011     0.050   0.00     0.050   0.00\n----GCM                                                2022 29574.395  98.02     3.537   0.01\n------AGCM                                             2022 29561.707  97.98   193.294   0.64\n--------SUPERDYNAMICS                                  3033  8878.824  29.43    11.887   0.04\n----------DYN                                          3033  8866.937  29.39  8866.937  29.39\n--------PHYSICS                                        2022 20489.447  67.91   176.392   0.58\n----------GWD                                          2022   331.073   1.10   331.073   1.10\n----------MOIST                                        2022  7782.298  25.79  7782.298  25.79\n----------TURBULENCE                                   3033  1054.626   3.50  1054.626   3.50\n----------CHEMISTRY                                    3033  1505.943   4.99     2.289   0.01\n------------CHEMENV                                    3033   124.704   0.41   124.704   0.41\n------------HEMCO                                      3033   188.383   0.62   188.383   0.62\n------------PCHEM                                      2022   424.569   1.41   424.569   1.41\n------------ACHEM                                      2022   106.343   0.35   106.343   0.35\n------------GOCART                                     3033    38.127   0.13    38.127   0.13\n------------GOCART2G                                   3033    29.287   0.10     0.536   0.00\n--------------DU.data                                  2022     7.089   0.02     7.089   0.02\n--------------SS.data                                  2022     7.081   0.02     7.081   0.02\n--------------CA.oc.data                               2022     2.933   0.01     2.933   0.01\n--------------CA.bc.data                               2022     2.915   0.01     2.915   0.01\n--------------CA.br.data                               2022     2.914   0.01     2.914   0.01\n--------------SU.data                                  2022     1.510   0.01     1.510   0.01\n--------------NI.data                                  2022     4.309   0.01     4.309   0.01\n------------TR                                         2022   592.240   1.96   592.240   1.96\n----------SURFACE                                      3033   738.635   2.45    83.314   0.28\n------------SALTWATER                                  3033    37.756   0.13     3.160   0.01\n--------------SEAICETHERMO                             3033    11.346   0.04    11.346   0.04\n--------------OPENWATER                                3033    23.251   0.08    23.251   0.08\n------------LAKE                                       3033     5.131   0.02     5.131   0.02\n------------LANDICE                                    3033     1.075   0.00     1.075   0.00\n------------LAND                                       3033   611.358   2.03     0.337   0.00\n--------------VEGDYN                                   2022     5.277   0.02     5.277   0.02\n--------------CATCH                                    3033   605.743   2.01   605.743   2.01\n----------RADIATION                                    2022  8900.481  29.50    28.077   0.09\n------------SOLAR                                      2022  4970.295  16.47  4970.295  16.47\n------------IRRAD                                      2022  3407.428  11.29  3407.428  11.29\n------------SATSIM                                     2022   494.682   1.64   494.682   1.64\n--------ORBIT                                          2022     0.142   0.00     0.142   0.00\n------AIAU                                             1011     0.057   0.00     0.057   0.00\n------ADFI                                             2022     0.247   0.00     0.247   0.00\n------OGCM                                             2022     8.847   0.03     3.462   0.01\n--------ORAD                                           2022     0.782   0.00     0.782   0.00\n--------SEAICE                                         2022     1.151   0.00     0.390   0.00\n----------DATASEAICE                                   2022     0.761   0.00     0.761   0.00\n--------OCEAN                                          2022     3.451   0.01     0.862   0.00\n----------DATASEA                                      2022     2.589   0.01     2.589   0.01\n----HIST                                               2022   555.841   1.84   555.841   1.84\n</code></pre>"},{"location":"GEOS/local_build/","title":"Build &amp; Run GEOS on desktop","text":""},{"location":"GEOS/local_build/#requirements","title":"Requirements","text":"<ul> <li><code>tcsh</code> for GEOS workflow</li> <li>A <code>gcc/g++/gfortran</code> compiler (gcc-12 is our current workhorse in Linux.  macOS has been tested using gcc-14 via Homebrew)<ul> <li>As of macOS Sequoia 15.5, <code>clang/clang++</code> can also be used in place of <code>gcc/g++</code>.</li> </ul> </li> <li>If using macOS, Homebrew is needed to install certain packages</li> </ul> <pre><code># *** If building on Linux ***\nsudo apt install g++ gcc gfortran\n# If you have multiple installation, you might have to set the preferred\n# compiler using the combo:\n# sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12\n# sudo update-alternatives --config gcc\n\n# *** If building on macOS, use Homebrew to install gcc-14 to access gfortran***\nbrew install gcc@14\n</code></pre> <ul> <li>A <code>cuda</code> toolkit if GPU backends will be used. (nvhpc/23.5+ or appropriate for your hardware)</li> <li>Use <code>lmod</code> to manipulate the stack with module like on HPCs: https://lmod.readthedocs.io/en/latest/030_installing.html</li> </ul> <pre><code>sudo apt install -y lua5.3 lua-bit32 lua-posix lua-posix-dev liblua5.3-0 liblua5.3-dev tcl tcl-dev tcl8.6 tcl8.6-dev libtcl8.6\nwget https://github.com/TACC/Lmod/archive/refs/tags/8.7.37.tar.gz\ntar -xvf 8.7.37.tar.gz\ncd Lmod-8.7.37/\nsudo ./configure --prefix=/opt/apps\nsudo make install\nsudo ln -s /opt/apps/lmod/lmod/init/profile        /etc/profile.d/z00_lmod.sh\nsudo ln -s /opt/apps/lmod/lmod/init/cshrc          /etc/profile.d/z00_lmod.csh\nsudo ln -s /opt/apps/lmod/lmod/init/profile.fish   /etc/fish/conf.d/z00_lmod.fish\n\n# On macOS, lmod can be installed via Homebrew without the above commands\nbrew install lmod\n</code></pre> <ul> <li>For macOS, install the following additional packages via Homebrew<ul> <li><code>brew install automake autoconf libtool texinfo m4 cmake wget boost</code></li> <li>IMPORTANT : Examine <code>brew info libtool</code> and <code>brew info m4</code> to access <code>libtool</code> and <code>m4</code> easily on macOS</li> </ul> </li> </ul>"},{"location":"GEOS/local_build/#build-our-software-stack","title":"Build our software stack","text":"<ul> <li>Copy code from SMT-Nebulae from the <code>main</code> branch on the <code>sw_stack/discover/sles15</code></li> <li>Change all <code>/discover</code> path to local</li> <li>In <code>build_0_on-node.sh</code> remove the <code>--with-gdrcopy=</code> line for UCX (you don't have it installed or/and it doesn't matter outside of HPCs)</li> <li>Then run the pipeline</li> </ul> <pre><code>./download.sh\n./build_0_on-node.sh\n./build_1_on-login.sh\n</code></pre> <p>The stack will take some time to install, especially the <code>baselibs</code> part of it. To check that baselibs has been built and installed, you can run</p> <pre><code>./verify_baselibs.sh\n</code></pre> <p>which should output</p> <pre><code>-------+---------+---------+--------------\nConfig | Install |  Check  |   Package\n-------+---------+---------+--------------\n  ok   |   ok    |   --    | jpeg\n  ok   |   ok    |   --    | zlib\n  ok   |   ok    |   --    | szlib\n  ok   |   ok    |   --    | hdf5\n  ok   |   ok    |   --    | netcdf\n  ok   |   ok    |   --    | netcdf-fortran\n  ok   |   ok    |   --    | udunits2\n  ok   |   ok    |   --    | fortran_udunits2\n  ok   |   ok    |   --    | esmf\n  ok   |   ok    |   --    | GFE\n-------+---------+---------+--------------\n</code></pre>"},{"location":"GEOS/local_build/#macos-notes-on-building-software-stack","title":"macOS Notes on building Software stack","text":"<ul> <li> <p>Use the <code>SMT-Nebulae</code> branch called <code>feature/functional_mac_build</code> that contains build scripts specific to macOS.</p> </li> <li> <p>Adjust <code>basics.sh</code> as follows</p> </li> </ul> <pre><code>-source /Users/ckropiew/SMT-Nebulae/sw_stack/local/modulefiles/SMTStack/2024.08.LOCAL.sh\n+source &lt;YOUR PATH TO SMT-Nebulae&gt;/sw_stack/local/modulefiles/SMTStack/2024.08.LOCAL.sh\n\n-export DSLSW_BASELIBS_VER=7.27.0\n+export DSLSW_BASELIBS_VER=8.14.0\n\n-export DSLSW_BOOST_VER=1.76.0\n-export DSLSW_BOOST_VER_STR=1_76_0 \n+export DSLSW_BOOST_VER=1.88.0\n+export DSLSW_BOOST_VER_STR=1_88_0\n\n-export DSLSW_BASE=/Users/ckropiew/SMT-Nebulae/sw_stack/local/src/build\n+export DSLSW_BASE=&lt;YOUR PATH TO SMT-Nebulae&gt;/sw_stack/local/src/build\n</code></pre> <ul> <li>Adjust <code>2024.08.LOCAL.sh</code> as follows</li> </ul> <pre><code>-install_dir=\"/Users/ckropiew/GEOS_dependencies/install\"\n-ser_pkgdir=\"/Users/ckropiew/GEOS_dependencies/install/serialbox\"\n+install_dir=\"&lt;YOUR PATH TO SMT-Nebulae&gt;/sw_stack/local/src/install\"\n+ser_pkgdir=\"&lt;YOUR PATH TO SMT-Nebulae&gt;/sw_stack/local/src/install/serialbox\"\n\n-boost_pkgdir=\"$homebrew_install_dir/boost/1.86.0_1\"\n+boost_pkgdir=\"$homebrew_install_dir/boost/1.88.0\"\n\n-baselibs_pkgdir=\"$install_dir/baselibs-7.27.0/install/\"\n+baselibs_pkgdir=\"$install_dir/baselibs-8.14.0/install/\"\n\n-export PYTHONPATH=\"$ser_pkgdir/python\":$PYTHONPATH\n+#export PYTHONPATH=\"$ser_pkgdir/python\":$PYTHONPATH\n\n-py_pkgdir=\"/Library/Frameworks/Python.framework/Versions/3.11\"\n-export PATH=\"$py_pkgdir/bin\":$PATH\n-export LD_LIBRARY_PATH=\"$py_pkgdir/lib\":$LD_LIBRARY_PATH\n-export LD_LIBRARY_PATH=\"$py_pkgdir/lib64\":$LD_LIBRARY_PATH\n+py_pkgdir=\"&lt;YOUR PATH TO miniconda&gt;/envs/venv\"\n+#export PATH=\"$py_pkgdir/bin\":$PATH\n+#export LD_LIBRARY_PATH=\"$py_pkgdir/lib\":$LD_LIBRARY_PATH\n+#export LD_LIBRARY_PATH=\"$py_pkgdir/lib64\":$LD_LIBRARY_PATH\n\n# *** If clang/clang++ is the C/C++ compiler, make the changes below\n-export CC=/opt/homebrew/opt/gcc@14/bin/gcc-14\n-export CXX=/opt/homebrew/opt/gcc@14/bin/g++-14\n+export CC=clang\n+export CXX=clang++\n</code></pre> <ul> <li> <p>Install miniconda for access to Python</p> <ul> <li>In the terminal, retrieve the installation file for miniconda via <code>curl https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh -o miniconda.sh</code></li> <li>Run <code>minconda.sh</code> to set up miniconda</li> <li>Create a virtual Python v3.11.7 environment via miniconda.  The command below will create a virtual environment called <code>venv</code>.<ul> <li><code>conda create -n venv python=3.11.7</code></li> </ul> </li> <li>Whenever you want to activate the environment, run <code>conda activate venv</code></li> </ul> </li> <li> <p>If you are using <code>clang</code> and <code>clang++</code> in place of <code>gcc</code> and <code>g++</code> for compiling, modify the setup of Baselibs in <code>build_baselibs.sh</code> as follows.</p> </li> </ul> <pre><code>make -j ESMF_COMM=openmpi \\\n-    ESMF_COMPILER=gfortran \\\n+    ESMF_COMPILER=gfortranclang \\\n</code></pre> <ul> <li>Install OpenMPI by running the <code>build_ompi.sh</code> script</li> <li>Install serialbox by running the <code>build_serialbox.sh</code> script</li> <li>Install Baselibs by running the <code>build_baselibs.sh</code> script</li> <li> <p>Install NDSL by running the <code>build_ndsl.sh</code> script</p> </li> <li> <p>Check that Baselibs is installed properly by running <code>./verify_baselibs.sh</code> and see if you get the output shown above when running <code>./verify_baselibs.sh</code>.</p> </li> </ul> <p>\u26a0\ufe0f <code>cffi</code>, <code>venv</code> and embedded Python interpreter \u26a0\ufe0f Due to a non standard approach of non-Posix or Posix-adjacent (Darwin, Windows...) file pathing, the <code>venv</code> can be misdetected when using an embedded Python interpreter via CPython. The CPython crew is aware of the issue but noe fix is ready. To test build the following:</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;Python.h&gt;\n\nint main(void)\n{\n    Py_InitializeEx(0);\n    PyObject *f = PySys_GetObject((char *)\"stderr\");\n    PyFile_WriteString(\"\\nsys.path: \", f);\n    PyFile_WriteObject(PySys_GetObject((char *)\"path\"), f, 0);\n    PyFile_WriteString(\"\\n\\n\", f);\n    return 0;\n}\n</code></pre> <p>with (replace the path to include &amp; lib of Python)</p> <pre><code>gcc -o pex \\\n    -I/home/fgdeconi/.pyenv/versions/3.11.9/include/python3.11/ \\\n    run_python.c \\\n    -L/home/fgdeconi/.pyenv/versions/3.11.9/lib -lpython3.11\n</code></pre> <p>Then run <code>./pex</code>. This will print the python <code>sys.path</code> which should have your virtual environement <code>sites-packages</code> in there. If it doesn't then it's the bug.</p> <p>Our workaround is to use <code>conda</code> which seems to use a different approach, more sandboxy, which goes around the issue.</p> <p>macOS Note: You may have to set the <code>DYLD_LIBRARY_PATH</code> environment variable to the <code>lib</code> path related to your conda Python environment to run the <code>pex</code> binary.</p> <p>Some reference: https://github.com/PyO3/pyo3/issues/1741</p>"},{"location":"GEOS/local_build/#notes-on-building-software-stack-with-linux-kernel-v68","title":"Notes on building Software stack with Linux Kernel v6.8+","text":"<p>Make the following adjustments before running the above pipeline...</p> <ul> <li>Adjust <code>basics.sh</code> as follows</li> </ul> <pre><code>-export DSLSW_OMPI_MAJOR_VER=4.1\n-export DSLSW_OMPI_VER=${DSLSW_OMPI_MAJOR_VER}.6\n+export DSLSW_OMPI_MAJOR_VER=5.0\n+export DSLSW_OMPI_VER=${DSLSW_OMPI_MAJOR_VER}.2\n\n-export DSLSW_BASELIBS_VER=7.17.1\n+export DSLSW_BASELIBS_VER=7.23.0\n\n-export DSLSW_BOOST_VER=1.76.0\n-export DSLSW_BOOST_VER_STR=1_76_0\n+export DSLSW_BOOST_VER=1.86.0\n+export DSLSW_BOOST_VER_STR=1_86_0\n\n+#CUDA_DIR=/usr/local/other/nvidia/hpc_sdk/Linux_x86_64/23.9/cuda/\n\n-export FC=gfortran\n+export FC=gfortran-12\n-export CC=gcc\n+export CC=gcc-12\n-export CXX=g++\n+export CXX=g++-12\n</code></pre> <ul> <li>Modify the command to configure OpenMPI in <code>build_0_on-node.sh</code></li> </ul> <pre><code>-./configure --prefix=$DSLSW_INSTALL_DIR/ompi \\\n-            --disable-libxml2 \\\n-            --disable-wrapper-rpath \\\n-            --disable-wrapper-runpath \\\n-            --with-pmix \\\n-            --with-cuda=$CUDA_DIR \\\n-            --with-cuda-libdir=$CUDA_DIR/lib64/stubs \\\n-            --with-ucx=$DSLSW_INSTALL_DIR/ucx \\\n-            --with-slurm \\\n-            --enable-mpi1-compatibility\n\n+./configure --disable-wrapper-rpath --disable-wrapper-runpath \\\n+    CC=gcc-12 CXX=g++-12 FC=gfortran-12 \\\n+           --with-hwloc=internal --with-libevent=internal --with-pmix=internal --prefix=$DSLSW_INSTALL_DIR/ompi\n</code></pre> <p>As of September 6th, 2024, there is a fix that needs to be applied to ESMF file <code>ESMCI_Time.C</code> to resolve a GEOS runtime issue.</p> <pre><code>diff --git a/src/Infrastructure/TimeMgr/src/ESMCI_Time.C b/src/Infrastructure/TimeMgr/src/ESMCI_Time.C\nindex 78c21bce04..ab40a39379 100644\n--- a/src/Infrastructure/TimeMgr/src/ESMCI_Time.C\n+++ b/src/Infrastructure/TimeMgr/src/ESMCI_Time.C\n@@ -1479,7 +1479,10 @@ namespace ESMCI{\n      if (sN != 0) {\n         sprintf(timeString, \"%s%02d:%lld/%lld\", timeString, s, sN, sD);\n       } else { // no fractional seconds, just append integer seconds\n-        sprintf(timeString, \"%s%02d\", timeString, s);\n+       char *tmpstr;\n+       tmpstr = strdup(timeString);\n+        sprintf(timeString, \"%s%02d\", tmpstr, s);\n+       free(tmpstr);\n</code></pre>"},{"location":"GEOS/local_build/#build-geos","title":"Build GEOS","text":"<ul> <li>Get and setup <code>mepo</code> which is pre-installed on <code>Discover</code><ul> <li><code>mepo</code> stands for \"Multiple rEPOsitory\": a Python tool held by Matt T in the SI team that handles the GEOS multi-repository strategy.  It can be installed using <code>pip</code>.</li> </ul> </li> </ul> <pre><code>pip install mepo\n</code></pre> <ul> <li>Git clone the root of GEOS then using <code>mepo</code>, you clone the rest of the components which pull on the <code>components.yaml</code> at the root of <code>GEOSgcm</code><ul> <li>There is two sources for a component the default and the <code>develop</code> source</li> <li><code>v11.5.2</code> is our baseline, but we have <code>dsl/develop</code> branch where needed</li> <li>We do not use <code>develop</code> for <code>GEOSgcm_App</code> or <code>cmake</code> since those have been setup for OpenACC but are not up-to-date for v11.5.2</li> </ul> </li> </ul> <pre><code>git clone -b dsl/develop git@github.com:GEOS-ESM/GEOSgcm.git geos\ncd geos\nmepo clone --partial blobless\nmepo develop env GEOSgcm GEOSgcm_GridComp FVdycoreCubed_GridComp pyFV3\n</code></pre> <ul> <li>CMake GEOS, using the stack, our custom build <code>baselibs</code> and turning on the interface to <code>pyFV3</code> for the dynamical core</li> <li>Then <code>make install</code>. Grab a coffee (or 2)<ul> <li>We override the compiler with their <code>mpi</code> counterpart to make sure <code>libmpi</code> is pulled properly. CMake should deal with that, but there's some failure floating around.</li> </ul> </li> </ul> <pre><code>module use -a SW_STACK/modulefiles\nml SMTStack/2024.04.00\nexport BASEDIR=SW_STACK/src/2024.04.00/install/baselibs-7.17.1/install/x86_64-pc-linux-gnu\n# *** Note: Above BASEDIR path will be different for macOS ***\n\nmkdir -f build\ncd build\nexport TMP=GEOS_DIR/geos/build/tmp\nexport TMPDIR=$TMP\nexport TEMP=$TMP\nmkdir $TMP\necho $TMP\n\nexport FC=mpif90\nexport CC=mpicc\nexport CXX=mpic++\n\ncmake .. -DBASEDIR=$BASEDIR/Linux \\\n         -DCMAKE_Fortran_COMPILER=mpif90 \\\n         -DBUILD_PYFV3_INTERFACE=ON \\\n         -DCMAKE_BUILD_TYPE=Debug \\\n         -DCMAKE_INSTALL_PREFIX=../install \\\n         -DPython3_EXECUTABLE=`which python3`\n\n# *** To add Serialbox serialization to GEOS, add the following two flags to the above cmake command\n#     1) -DBUILD_SERIALBOX_SER=ON \n#     2) -DSERIALBOX_ROOT=&lt;Path to Serialbox Installation&gt;\n\n# *** If MKL isn't found by cmake, add the following flag to the above cmake command: -DMKL_INCLUDE_DIR=&lt;MKL Include Path&gt;\n\nmake -j48 install\n</code></pre> <p>Note: There may be an error that occurs when building GEOS on macOS that refers to <code>./src/Shared/@GMAO_Shared/LANL_Shared/CICE4/bld/makdep.c</code>.  This error points out that the <code>main</code> routine in <code>makdep.c</code> is missing a type.  Simply put <code>int</code> in front of <code>main</code> to resolve this problem (ex: <code>int main</code>).</p> <p>macOS Note: To build GEOS using <code>clang</code>/<code>clang++</code>, there are additional OpenMP files needed that macOS does not have.  Here is how to get those files and set up the environment variables needed for building GEOS using <code>clang</code>/<code>clang++</code> on macOS.</p> <ul> <li>Use Homebrew to get the <code>libomp</code> package : <code>brew install libomp</code></li> <li>Set up the following environment variables<ul> <li><code>export OPENMP_CPPFLAGS=\"-I/opt/homebrew/opt/libomp/include</code></li> <li><code>export OPENMP_LDFLAGS=\"-L/opt/homebrew/opt/libomp/lib -lomp -Xpreprocessor -fopenmp</code></li> <li><code>export GT4PY_EXTRA_COMPILE_OPT_FLAGS=\"-fbracket-depth=512</code></li> </ul> </li> </ul> <p>\u26a0\ufe0f MKL Dependency\u26a0\ufe0f</p> <p>Some code in GEOS requires MKL. It's unclear which (apart from a random number generator in Radiation) and it seems to be an optional dependency. The <code>cmake</code> process will look for it. If you want to install it follow steps for the standalone OneAPI MKL installer</p> <ul> <li>Get data (curtesy of Matt T.) in it's most compact form: TinyBC<ul> <li>WARNING: TinyBC is Matt way to move around a small example and/or develop on desktop, it's fragile and we shall treat it as a dev tool, offer help when needed.</li> <li>Do not rename it</li> </ul> </li> </ul> <pre><code>wget https://portal.nccs.nasa.gov/datashare/astg/smt/geos-fp/restarts/TinyBCs-GitV10.2024Apr04.tar.gz\ntar -xvf TinyBCs-GitV10.2024Apr04.tar.gz\nrm TinyBCs-GitV10.2024Apr04.tar.gz\ncd TinyBCs-GitV10\n</code></pre> <ul> <li>Make experiment, using TinyBC. First we will make our live easier by aliasing the relevant script. In your <code>.bashrc</code> (remember to re-bash)</li> </ul> <pre><code>alias tinybc_create_exp=PATH_TO/TinyBCs-GitV10/scripts/create_expt.py\nalias tinybc_makeoneday=PATH_TO/TinyBCs-GitV10/scripts/makeoneday.bash\n</code></pre> <ul> <li>Then we can make experiment for c24</li> </ul> <pre><code>cd PATH_TO_GEOS/install/bin\ntinybc_create_exp --horz c24 --vert 72 --nonhydro --nooserver --gocart C --moist GFDL --link --expdir /PATH_TO_EXPERIMENT/ TBC_C24_L72\ncd /PATH_TO_EXPERIMENT/TBC_C24_L72\ntinybc_makeoneday noext # Temporary: we deactivate ExtData to go around a crash\n</code></pre> <p>\u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f Bash might not work, if you see errors try to run under <code>tcsh</code>. Prefer a PATH_TO_EXPERIMENT outside of GEOS to not mix experiment data &amp; code. \u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f</p> <ul> <li>The simulation is ready to run a 24h simulation (with the original Fortran) with</li> </ul> <pre><code>module load SMTStack/2024.04.04\n./gcm_run.j\n</code></pre> <ul> <li>To run the <code>pyFV3</code> version, modification to the <code>AGCM.rc</code> and <code>gcm_run.j</code> needs to be done after the <code>tinybc_makeoneday</code>. This runs the <code>numpy</code> backend.</li> </ul> <p>AGCM.rc</p> <pre><code>###########################################################\n# dynamics options\n# ----------------------------------------\nDYCORE: FV3\n FV3_CONFIG: HWT\n+ RUN_PYFV3: 1\nAdvCore_Advection: 0\n</code></pre> <p>gcm_run.j</p> <pre><code>setenv RUN_CMD \"$GEOSBIN/esma_mpirun -np \"\n\nsetenv GCMVER `cat $GEOSETC/.AGCM_VERSION`\necho   VERSION: $GCMVER\n\n+setenv FV3_DACEMODE           Python\n+setenv GEOS_PYFV3_BACKEND     numpy\n+setenv PACE_CONSTANTS         GEOS\n+setenv PACE_FLOAT_PRECISION   32\n+setenv PYTHONOPTIMIZE         1\n+setenv PACE_LOGLEVEL          Debug\n\n+setenv FVCOMP_DIR PATH_TO_GEOS/src/Components/@GEOSgcm_GridComp/GEOSagcm_GridComp/GEOSsuperdyn_GridComp/@FVdycoreCubed_GridComp/\n+setenv PYTHONPATH $FVCOMP_DIR/python/interface:$FVCOMP_DIR/python/@pyFV3\n\n\n#######################################################################\n#             Experiment Specific Environment Variables\n######################################################################\n</code></pre> <p>Remove the <code>source $GEOSBIN/g5_modules</code> to make sure your local environment is left clean.</p>"},{"location":"GEOS/validation_basics/","title":"Validating our GEOS port","text":""},{"location":"GEOS/validation_basics/#fine-grain-numerical-validation-translate-test","title":"Fine-grain numerical validation: Translate test","text":"<p>Using Serialbox to output test data and the translate test infrastructure of <code>ndsl</code> we can make numerical regression test, known as Translate test.</p> <p>This documentation is based on the work done at AI2 to do the original port FV3 dycore, which is still available:</p> <ul> <li>fv3gfs-fortran is the serialbox annotated source Fortran</li> <li>pyFV3 is the ported code which also contains the translate test</li> </ul>"},{"location":"GEOS/validation_basics/#example-fillqzero-from-moist-physics","title":"Example <code>FillQZero</code> from <code>moist</code> physics","text":"<p>We are going to port the following simple subroutine.</p> <pre><code>  subroutine FILLQ2ZERO1( Q, MASS, FILLQ  )\n    real, dimension(:,:,:),   intent(inout)  :: Q\n    real, dimension(:,:,:),   intent(in)     :: MASS\n    real, dimension(:,:),     intent(  out)  :: FILLQ\n    integer                                  :: IM,JM,LM\n    integer                                  :: I,J,K,L\n    real                                     :: TPW, NEGTPW\n    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n    ! Fills in negative q values in a mass conserving way.\n    ! Conservation of TPW was checked.\n    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n    IM = SIZE( Q, 1 )\n    JM = SIZE( Q, 2 )\n    LM = SIZE( Q, 3 )\n    do j=1,JM\n       do i=1,IM\n          TPW = SUM( Q(i,j,:)*MASS(i,j,:) )\n          NEGTPW = 0.\n          do l=1,LM\n             if ( Q(i,j,l) &lt; 0.0 ) then\n                NEGTPW   = NEGTPW + ( Q(i,j,l)*MASS( i,j,l ) )\n                Q(i,j,l) = 0.0\n             endif\n          enddo\n          do l=1,LM\n             if ( Q(i,j,l) &gt;= 0.0 ) then\n                Q(i,j,l) = Q(i,j,l)*( 1.0+NEGTPW/(TPW-NEGTPW) )\n             endif\n          enddo\n          FILLQ(i,j) = -NEGTPW\n       end do\n    end do\n  end subroutine FILLQ2ZERO1\n</code></pre>"},{"location":"GEOS/validation_basics/#generate-data-using-serialbox","title":"Generate data using <code>serialbox</code>","text":"<ol> <li>First we need to annotate the Fortran on a relevant call with serialbox.</li> </ol> <p>\u26a0\ufe0f Some serializer code has been omitted for simplification \u26a0\ufe0f</p> <pre><code>!$ser savepoint FILLQ2ZERO-In\n!$ser data q=RAD_QV\n!$ser data mass=MASS\n!$ser data fillq=TMP2D\ncall FILLQ2ZERO(RAD_QV, MASS, TMP2D)\n!$ser savepoint FILLQ2ZERO-Out\n</code></pre> <p>It's easier to keep a <code>*.F90.ser</code> version of the file with serialization, because the system will generate the <code>F90</code> that needs to be compiled.</p> <p>Turn the annotated code to proper fortran using</p> <pre><code>python /PATH_TO_SERIALBOX/src/serialbox-python/pp_ser/pp_ser.py ./microphysics.F90.ser &gt;| ./microphysics.F90\n</code></pre> <p>This will dump two <code>netcdf</code> when running a simulation:</p> <ul> <li>FILLQZERO-In.nc4</li> <li>FILLQZERO-Out.nc4</li> </ul> <p>For the translate test the naming convention is that the <code>-In</code> and <code>-Out</code> exists, and the string before will be the name of the test.</p> <ol> <li>Turn the raw Fortran to NETCDF</li> </ol> <p>A script existing in the original fv3gfs-fortran source used for the original port.</p>"},{"location":"GEOS/validation_basics/#testing-the-ported-code","title":"Testing the ported code","text":"<p>In <code>ndsl</code> we structure the code using classes that wraps all relevant stencils and in-between code from a scientific standpoint. <code>FillQZero</code> would be part of the <code>microphysics</code> code, for simplicity we will write it as a standalone class.</p> <p>Note</p> <p>In <code>ndsl</code>, because we code generate and optimize across code, your code structure does not impact the performance and should be as readable as possible.</p> <p>\u26a0\ufe0f Some <code>ndsl</code> code has been omitted for simplification \u26a0\ufe0f</p> <p>Ported code looks as follows</p> <pre><code>from ndsl import StencilFactory, QuantityFactory\nfrom ndsl.dsl.typing import Float, FloatField, FloatFieldIJ, IntFieldIJ\n\ndef fill_q_zero_stencil(q:FloatField, mass: FloatField, fillq: FloatFieldIJ, tpw:FloatFieldIJ)\n    with computation(PARALLEL), interval(...):\n        neg_tpw = 0.\n        if q &lt; 0:\n            neg_tpw = neg_tpw + q*mass\n            q = 0\n        if q &gt;= 0\n            q = q * (1+neg_tpw/(tpw_negtpw))\n        fillq = -neg_tpw\n\n\n\nclass FillQZero:\n    def __init__(stencil_factory: StencilFactory, quantity_factory: QuantityFactory):\n        self._tpw = quantity_factory.zeros(\n            [X_DIM, Y_DIM],\n            units=\"unknown\",\n            dtype=Float,\n        )\n        self._fillq = quantity_factory.zeros(\n            [X_DIM, Y_DIM],\n            units=\"unknown\",\n            dtype=Float,\n        )\n        self._fill_q_zero = stencil_factory.from_dims_halo(\n            fill_q_zero_stencil,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n    def __call__(\n        q: FloatField,\n        mass: FloatField,\n    )\n        # This is not a stencil code, so we do it outside\n        self._tpw = np.sum(q, 3) \n        # Call stencil code\n        self._fill_q_zero(\n            q=q,\n            mass=mass,\n            fillq=self._fillq,\n            tpw=self._tpw\n        )\n</code></pre> <ol> <li>Make a Translate test</li> </ol> <p>Write a <code>translate_fill_q_zero.py</code></p> <pre><code>from ndsl import Namelist, StencilFactory\nfrom fill_q_zero import FillQZero\nfrom ndsl.testing.translate import TranslateFortranData2Py\n\nclass TranslateFillQZero(TranslateFortranData2Py):\n    def __init__(\n        self,\n        grid,\n        namelist: Namelist,\n        stencil_factory: StencilFactory,\n    ):\n        super().__init__(grid, namelist, stencil_factory)\n        self.compute_func = FillQZero(\n            self.stencil_factory,\n            self.grid.quantity_factory,\n        )\n\n    def compute_from_storage(self, inputs):\n        self.compute_func(**inputs)\n        return inputs\n</code></pre> <ol> <li>Run</li> </ol> <p>The above uses the <code>pytest</code> system under the hood, therefore the command is using pytest.</p> <pre><code>pytest \\\n    -v -s --data_path=/PATH/TO/DATA_DIR \\\n    --backend=numpy --which_modules=FillQZero \\\n    --threshold_overrides_file=/PATH/TO/threshold.yaml \\\n    /PATH/TO/TEST_FILE_DIR/\n</code></pre>"},{"location":"GEOS/validation_basics/#scientific-validation-plotting","title":"Scientific Validation: plotting","text":"<p>The diagnostics output of GEOS is driven by the <code>HISTORY.rc</code> files. The output is a well formed Netcdf4 file with relevant comments and units. Those are the basis for the large GEOS products.</p>"},{"location":"GEOS/validation_basics/#tcn-package","title":"<code>tcn</code> package","text":""},{"location":"GEOS/validation_basics/#tcbplots","title":"<code>tcb.plots</code>","text":"<p>Automatic plotting system with default to match GEOS needs. See <code>tcn-plots</code> command.</p>"},{"location":"GEOS/validation_basics/#discover-jupyter-and-tcn-package","title":"Discover Jupyter and <code>tcn</code> package","text":"<p>In order to quickly check results we have developed a <code>tcn.plots</code> and made it available as part of a Jupyter notebook on Discover. That way, plotting results can be done on the HPC directly, removing the need for downloading the data.</p> <p>Basic howto</p> <ul> <li>Get IT access (talk to Florian)</li> <li>On the Hub use the <code>smt-tcn</code> conda kernel</li> <li>Code:</li> </ul> <pre><code>import plotly.io as pio\npio.renderers.default = 'iframe' #required for display\n\nfrom tcn.plots.geos.plot_via_plotly import plot\nimport xarray as xr\n\nd = xr.open_mfdataset(\"/path/to/dump.nc4\")\nvar = \"U\"\n\nf = plot(dataset=d, variable=var, write=False)\nf.show()\n</code></pre> <p>As of 24.01 the <code>tcn</code> package version is the unreleased develop version of <code>fdeconinck</code></p>"},{"location":"GEOS/components/","title":"GEOS component documentation","text":"<p>This part of the knowledge base holds GEOS documentation with things that we discover while porting. It is organized by component.</p> <p>Note</p> <p>Porting currently happens on the following branches: -  <code>dsl/develop</code> of GEOS-ESM/GEOSgcm_GridComp.</p>"},{"location":"GEOS/components/chemistry/pchem/","title":"PCHEM NOTES","text":"<ul> <li>All the code is in one file: GEOS_PChemGridComp.F90</li> <li>Pchem is a simple parameterization of the Aerochem species</li> <li>Work on three types of species: chemical species (oxygen, nitrous oxide, CFC-11, CFC-12, CFC-22, methane, water vapor), diagnostic species (age-of-air), and aerosols</li> <li>Chemical species can be treated in one of two ways: <ul> <li>parameterized prediction from tabled zonally-symmetric production and loss (P-L) data</li> <li>or specification from zonally-symmetric values (see Resources section)</li> <li>A single flat file containing both the P-L and climatology data must be provided</li> </ul> </li> <li>Aerosols are set to 3-dimensional climatological values.</li> <li>The ``age-of-air'' is predicted by setting the surface values of this tracer to the to zero and advancing other levels by dt</li> <li>All of these quantities except water vapor are INTERNAL state variables of PCHEM </li> <li>Water vapor is assumed to be a Friendly Import and PChem leaves it unmodified below the tropopause, or the 200 hPa level if the tropopause is below this level</li> <li>For chemical species, the production rate is tabled directly. For the loss, a rate coefficient is tabled.</li> <li>See summary at top of GEOS_PChemGridComp.F90 for description of how species are updated based on P-L rates</li> <li>Ozone is diagnosed from $O_x$ by assuming that it accounts for all $O_x$ at pressures greater than 100 Pa (1 hPa) during the day and at all pressures at night. For those day lit cells where pressures are less than 1 hPa, we assume that the ozone fraction in $O_x$ decreases exponentially with decreasing pressure.</li> <li>Aerosols are read from 3-dimensional data files that have to be on model levels but may be on any regular lat-lon grid. These are hdf files and horizontal interpolation is done through CFIO. The aerosols are read into a bundle that is exported, and the number and names of the aerosols in the bundle are set from the CFIO file. </li> <li>Resources section contains names/descriptions of files/variables that are needed to run PChem</li> <li>From what I have gathered so far, it seems that PChem Run reads in pretabulated concentration data, interpolates the data to GEOS grid, and then updates the concentrations if certain conditions are met.</li> </ul>"},{"location":"GEOS/components/chemistry/pchem/#questionsconcerns","title":"QUESTIONS/CONCERNS","text":"<ol> <li>PChem seems to be reading in a data file that contains tabulated concentrations of the 7 species - I am not exactly where this file is located, but it must exist somewhere.</li> <li>PChem is very MAPL heavy and contains a lot of MAPL calls, mixed in with some math. We will need to at some point find a way to replicate these MAPL calls (there may be more):</li> <li>MAPL_GetPointer </li> <li>MAPL_GetResource</li> <li>MAPL_AM_I_ROOT()</li> <li>MAPL_INTERP</li> <li>MAPL_SunGetInsolation</li> <li>MAPL_VerifyFriendly</li> <li>MAPL_Get</li> <li>MAPL_GetObjectFromGC</li> <li>MAPL_MetaComp</li> <li>MAPL_SunOrbit</li> <li>MAPL_ClimInterpFac</li> <li>What do we want to port? Everything in GEOS_PChemGridComp.F90 or just the stuff in Run? Run is responsible for about 40% of the total compute time, the time it takes to read in the data files is neglibible. PChem Run seems portable, and we have already started to port the <code>Update</code> subroutine in Run (dsl/PChem branch). However, <code>interp_no_extrap</code> involves some MAPL calls, which make the port more difficult. </li> </ol>"},{"location":"GEOS/components/dynamics/pyFV3/","title":"pyFV3","text":""},{"location":"GEOS/components/dynamics/pyFV3/#breakdown","title":"Breakdown","text":"<p>Dynamics (FVDynamics)</p> <ul> <li>compute_preamble<ul> <li>fluxes/courant to zero</li> <li>fv_setup</li> <li>== consv_te &gt; 0<ul> <li>ComputeTotalEnergy</li> </ul> </li> <li>pt_to_potential_density_pt</li> <li>DryMassRoundOff.reset</li> </ul> </li> <li>=o= K SPLIT loop<ul> <li>reset <code>delp</code></li> <li>Acoustics (DynCore)<ul> <li>Halos</li> <li>zero_data</li> <li>=o= N SPLIT loop<ul> <li>gz_from_surface_height_and_thicknesses</li> <li>interface_pressure_from_toa_pressure_and_thickness</li> <li>CGridShallowWaterDynamics (C_SW)</li> <li>UpdateGeopotentialHeightOnCGrid (UpdateDzC)</li> <li>NonhydrostaticVerticalSolverCGrid (Riem_Solver_C)</li> <li>p_grad_c</li> <li>DGridShallowWaterLagrangianDynamics (D_SW)</li> <li>UpdateHeightOnDGrid (UpdateDzD)</li> <li>NonhydrostaticVerticalSolver (Riem_Solver3)</li> <li>== remap_step<ul> <li>edge_pe</li> </ul> </li> <li>compute_geopotential</li> <li>NonHydrostaticPressureGradient (NH_P_Grad)</li> <li>== rf_fast<ul> <li>RayleighDamping (Ray_Fast)</li> </ul> </li> </ul> </li> <li>== do_del2cubed<ul> <li>HyperdiffusionDamping (del2cubed)</li> <li>apply_diffusive_heating (PressureAdjustedTemperature_NonHydrostatic)</li> </ul> </li> </ul> </li> <li>Copy acoustics fluxes/courant f64 into local f32</li> <li>== Last K<ul> <li>DryMassRoundOff.apply</li> </ul> </li> <li>== z_tracer<ul> <li>TracerAdvection (Tracer2D1L)</li> </ul> </li> <li>LagrangianToEulerian_GEOS (Remapping)</li> <li>Increment global fluxes/courant with local f32</li> <li>== Last K<ul> <li>omega_from_w</li> <li>== nf_omega &gt; 0<ul> <li>HyperdiffusionDamping (Del2Cubed)</li> </ul> </li> </ul> </li> </ul> </li> <li>AdjustNegativeTracerMixingRatio (Neg_Adj3)</li> <li>CubedToLatLon (CubedToLatLon)</li> </ul>"},{"location":"GEOS/components/dynamics/pyFV3/#links","title":"Links","text":"<p>FV3 docs at NOAA:</p> <ul> <li>Global documentation</li> <li>GFDL Technical documentation</li> </ul>"},{"location":"GEOS/components/moist/","title":"GEOS moist component","text":"<ul> <li>Component name <code>GEOSmoist_GridComp</code></li> <li>NDSL port name <code>pyMoist</code></li> <li>Sub-directory <code>GEOSgcm_GridComp/GEOSagcm_GridComp/GEOSphysics_GridComp/GEOSmoist_GridComp</code></li> <li>NDSL port <code>GEOSgcm_GridComp/GEOSagcm_GridComp/GEOSphysics_GridComp/GEOSmoist_GridComp/pyMoist</code></li> </ul>"},{"location":"GEOS/components/moist/#notes-on-the-port","title":"Notes on the Port","text":""},{"location":"GEOS/components/moist/#dead-code","title":"Dead code","text":"<ul> <li>Aer Activation (<code>GEOSmoist_GridComp/aer_actv_single_moment.F90</code>) The pre-loop before computation in</li> </ul> <pre><code>!--- determining aerosol number concentration at cloud base\nDO j=1,JM\n  DO i=1,IM\n       k            = kpbli(i,j)\n       tk           = T(i,j,k)              ! K\n       press        = plo(i,j,k)            ! Pa\n       air_den      = press*28.8e-3/8.31/tk ! kg/m3\nENDDO;ENDDO\n</code></pre>"},{"location":"GEOS/components/moist/GF/","title":"GF","text":"<p>Map of GF </p>"},{"location":"GEOS/components/moist/GFDL_1M/","title":"GFDL_1M","text":"<p>Map of GFDL_1M </p>"},{"location":"GEOS/components/moist/RAS/","title":"RAS","text":"<p>Map of RAS </p>"},{"location":"GEOS/components/moist/UW/","title":"UW","text":"<p>Map of UW </p> <p>UW logic diagram </p>"},{"location":"project2426/","title":"2024 - 2026: Proving NDSL for GEOS","text":"<p>The Software Modernization team proposes a two-year plan to prove the NDSL technology at scale on NASA's GEOS flagship model. The timeline of the project goes as follows:</p> <pre><code>    timeline\n        title 24-26 Project\n        section Milestone 1 (M1) &lt;br&gt; \n           August 24 : Project kickoff : M1 tasklist frozen\n           November 24: [16-22 November] &lt;br&gt; All team attends SC24\n           December 24: [9-13 December] &lt;br&gt; Two team members attends AGU24\n           January 25 : M1 Review : Dynamical core FP-ready : Moist physics validating : CPU performance progress : Target metrics refined and documented\n        section Milestone 2 (M2) &lt;br&gt; \n          February 25 : M2 tasklist frozen\n          July 25 : M2 Review : Integrated and accelerated moist physics : CPU Performance : TBD...\n        section Milestone 3 (M3) &lt;br&gt; \n          August 25 : M3 tasklist frozen\n          January 26 : M3 Review : TBD...\n        section Milestone 4 (M4) &lt;br&gt; \n          January 26 : M4 tasklist frozen\n          August 26 : M4 Review: Full project post-mortem : TBD...</code></pre> <p>Kanban board and full project breakdown available on Github project.</p> <p>Any questions please email: florian.g.deconinck@nasa.gov</p> <p>The work is divided in 4 6-months milestone. As part of Milestone 1 (M1) the team as defined science targets and HPC metrics that'll be reviewed for each benchmark.</p>"},{"location":"project2426/#publicly-presented-results","title":"Publicly presented results","text":"<ul> <li>Supercomputing 23 (November 2023)</li> </ul>"},{"location":"project2426/#relevant-previous-and-surrounding-work","title":"Relevant previous and surrounding work","text":"<ul> <li>Validation and benchmark of the Pace model, leading to the 24-26 project at NASA.</li> </ul>"},{"location":"project2426/milestone1/","title":"Milestone 1","text":"<p>Kanban board</p>"},{"location":"project2426/milestone2/","title":"Milestone 2","text":"<p>Milestone 2 was started on March 2025 and will run until the end of August 2025.</p> <p>Results can be found in the results section.</p>"},{"location":"project2426/milestone2/#branches-setup","title":"Branches setup","text":"<p>Not all features that we use in the results for milestone 2 are/were merged to mainline at the time. We have/had the following setup:</p>"},{"location":"project2426/milestone2/#ndsl","title":"NDSL","text":"<p>Follows branch <code>nasa/milestone2</code> (see PR #189). This branch includes</p> <ul> <li>a hard-coded DaCe version with the new schedule tree bridge and</li> <li>a hardcoded GT4Py version with the following experimental features (in the <code>dace:*</code> backends only)<ul> <li>Hybrid indexing, i.e. absolute indexes in K via <code>field.at(K=absolute_index)</code></li> <li>Access to the iteration variable through <code>K</code>, working title <code>THIS_K</code></li> <li>Access to the <code>round()</code> function in stencils</li> </ul> </li> </ul> <code>int</code> / <code>float</code> literal precision, working title \"mixed precision work\" <p>The \"mixed precision work\" made it into mainline GT4Py with this PR. There was only one major change compared to previous versions: the names of type annotations and casts changed in the following way</p> <ul> <li><code>i32</code> -&gt; <code>int32</code></li> <li><code>i64</code> -&gt; <code>int64</code></li> <li><code>f32</code> -&gt; <code>float32</code></li> <li><code>f64</code> -&gt; <code>float64</code></li> </ul> <p>If you get issues/errors about <code>i32</code>, <code>i64</code>, <code>f32</code>, <code>f64</code> not being defined, update your code with the above mapping.</p>"},{"location":"project2426/milestone2/#taskboard","title":"TaskBoard","text":"<p>As of March 2nd:</p> <p></p>"},{"location":"project2426/milestone3/","title":"Milestone 3","text":"<p>Milestone 3 is planned to start around October 2025.</p>"},{"location":"project2426/milestone4/","title":"Milestone 4","text":"<p>Milestone 4 is planned to start around March 2026.</p>"},{"location":"project2426/results/SC23/","title":"Supercomputing 23 results","text":"<p>Those results where presented at SC23 and represent the state of the work at that date (November 2023).</p>"},{"location":"project2426/results/SC23/#node-to-node-benchmarks","title":"Node-to-node benchmarks","text":"<p>The benchmark were conducted on the Dynamical Core, on an Held-Suarez and Aquaplanet application of GEOS. We measured the performance at multiple points in the code to show the results of integration when looking at:</p> <ul> <li>directly ported code (including Fortran &lt;-&gt; Python transfers)</li> <li>component level</li> <li>model level</li> </ul> <p></p> <p>All results are given in speed up for a \"note to node\" setup, e.g. a CPU-only node is compared to a CPU-GPU fat node.</p> <p>On Discover, we ran resolution benchmarks with hardware setup as follows:</p> <ul> <li>2 nodes \u2013 with Dual HDR Infiniband 2x200 Gbps</li> <li>8x A100 GPUs \u2013 40 GB (released 2021)</li> <li>4x EPYC 7402 \u2013 96 cores (released 2020)</li> </ul> <p></p> <p>On Perlmutter, we ran scaling benchmarks for C720-L72 resolution with hardware setup as follows:</p> <ul> <li>Slingshot 11 interconnect</li> <li>4x A100 GPUs \u2013 40 GB (released 2021)</li> <li>1x EPYC 7763 \u2013 64 cores (released 2022)</li> </ul> <p></p>"},{"location":"project2426/results/SC23/#other-metrics","title":"Other metrics","text":"<p>We ran a power-envelop comparison. This was done using software level sampling of the power usage, therefore the precision of the numbers is average. The following results should be taken as an indication of the magnitude of the difference rather than a precise measurement.</p> <ul> <li>Setup : 24h simulation of GEOS Held-Suarez</li> </ul> <p></p> <p>Another metric is a cost-comparison when taking into account the speed up between CPU and GPU. GPU cost varies wildly, again this should be taken as an indication of the magnitude of the difference rather than a precise measurement.</p> <ul> <li>Based on NCCS\u2019s Discover SC16 GPU partition.</li> <li>Measures the median dynamical core call</li> <li>To break even in cost, we need at least 5.5x improvement in performance on this setup</li> </ul> <p></p>"},{"location":"project2426/results/hpc-metrics/","title":"HPC metrics","text":"<p>In collaboration with the NCCS, we are listing below a range of metrics that should be evaluated for each benchmark.</p> <p>Time to solution</p> <ul> <li>Despite not aiming for production-ready code by the end of the project, we will still keep an eye on the \"job-level\" turn around and document improvement and potential non-numerics slowdown due to the technology swap.</li> </ul> <p>Energy</p> <ul> <li>Light software sampling to document amplitude of TPU\u2019s chip: imprecise but can be easily ran with little overhead.</li> <li>Hardware monitoring on selected runs for precise measure: precise but requires close cooperation with NCCS sys admin and IT.</li> </ul> <p>Node-to-node</p> <ul> <li>Compare CPU node with GPU nodes</li> <li>Minimize generation difference for valid comparison</li> </ul> <p>Node usage</p> <ul> <li>Chip usage: measure in % of theoretical throughput rather than FLOP/s</li> <li>Chip idle time: important for hybrid work</li> </ul> <p>Minimal hardware requirements</p> <ul> <li>For developments</li> <li>For scientific runs</li> </ul>"},{"location":"project2426/results/science-targets/","title":"Science targets","text":"<p>In collaboration with the GMAO we have identified two scenarios to cover weather and climate simulations pragmatically and one moonshot to push the envelop given adequate previous success and resources.</p>"},{"location":"project2426/results/science-targets/#forward-processing-weather-geos-fp","title":"Forward Processing Weather (GEOS-FP)","text":"<p>Configuration</p> <ul> <li>8.5 km horizontal resolution (C1120)</li> <li>191 atmospheric levels</li> <li>No Data Assimilation (DA)</li> <li>All physics</li> <li>All tracers</li> </ul> <p>Implementation</p> <ul> <li>Fortran/Python hybrid</li> <li>Dynamics and moist physics under NDSL</li> </ul> <p>Expected performance</p> <ul> <li>GPU: 2 \u2013 2.5x speed up</li> <li>CPU: within 15%</li> </ul>"},{"location":"project2426/results/science-targets/#co2-climate","title":"CO2 Climate","text":"<p>Configuration</p> <ul> <li>3 km horizontal resolution (C3072)</li> <li>191 atmospheric levels</li> <li>No Data Assimilation (DA)</li> <li>All physics minus Grell-Freitas Convection</li> <li>All tracers</li> </ul> <p>Implementation</p> <ul> <li>Fortran/Python hybrid</li> <li>Dynamics, moist physics and gases chemistry (GOCART) under NDSL</li> </ul> <p>Performance</p> <ul> <li>Currently 15-20 SDPD on 200 nodes of NCCS\u2019s Discover, we want to reach 30 SDPD</li> </ul>"},{"location":"project2426/results/science-targets/#moonshot-co2-climate-at-1-sypd","title":"Moonshot: CO2 Climate at 1 SYPD","text":"<p>Same configuration as the <code>CO2 Climate</code> scenario but we scale up to reach 1 Simulated Year per Day or 365 SDPD. This will most likely require a large allocation of GPUs at best, more code porting at worst (which in the later case will probably make it our of reach of our timeline).</p>"},{"location":"project2426/results/M2_Sept25/benchmark_overview/","title":"Benchmarks","text":"<p>TBD</p>"},{"location":"project2426/results/M2_Sept25/dynamics_pace/","title":"Dynamics Pace: Validation &amp; Benchmark","text":"<p>Back to M2 results summary</p> <p>Specification</p> <ul> <li>Date: August 25</li> <li>Validation &amp; benchmark using the Discover hardware</li> <li>Code:<ul> <li>NDSL: [release version]</li> <li>Pace: [release version] / [branch] / [commit]</li> </ul> </li> </ul>"},{"location":"project2426/results/M2_Sept25/dynamics_pace/#validation","title":"Validation","text":"<p>Thresholds for <code>FVDynamics</code>....</p> <p>Scientifically we run...</p>"},{"location":"project2426/results/M2_Sept25/dynamics_pace/#benchmark","title":"Benchmark","text":"<p>[Insert graphs]</p>"},{"location":"project2426/results/M2_Sept25/early_microphys/","title":"Early Microphysics results (March)","text":"<p>Back to M2 results summary</p> <p>Project call for the porting of the GFDL One Moment Microphysics (GFDL_1M). The work was concluded in March with validation on performance backends and early pre-optimization benchmarks</p>"},{"location":"project2426/results/M2_Sept25/early_microphys/#validation","title":"Validation","text":"<p>Hardware &amp; software stack</p> <p>Validation using the Discover hardware</p> <p>Validation was done on a GEOS-FP run at C180-L137 (~51 km horizontal resolution) over 7 days of simulated time. Only the GFDL Microphysics scheme was swapped from Fortran to NDSL, the rest of the model code is running the original Fortran.</p> <p>Below are the distribution of differences between the reference Fortran and the GPU performance backend after 7 days of simulation.</p> <p>Note: validation was done on CPU performance backend first but isn't shown here because the results are similar</p> <p>We start with an histogram showing the repartition of differences between the reference Fortran. We have good agreement with a few outliers:</p> <p></p> <p>Looking at the zonal wind in particular to explore the outliers, we show below the reference Fortran and the NDSL performance backend:</p> <p></p> <p></p> <p>The above graphs show differences around storm regions (Brazil). Those differences are on the position of the front leading to large value differences. Below we graph the difference between Fortran and NDSL to show a good spatial agreement of the runs:</p> <p></p>"},{"location":"project2426/results/M2_Sept25/early_microphys/#benchmark","title":"Benchmark","text":"<p>Benchmark is done by measuring CPU time (post sync for GPU) at the Fortran level (overhead of going to GPU from CPU is included in the number). This mirrors the real life application of the technology running an \"hybrid\" GEOS.</p> <p>Time are given in seconds. Positive speed up means NDSL is faster, negative means original Fortran is faster.</p> Resolution Layout Fortran NDSL GPU (dace:gpu) NDSL CPU (gt:cpu_kfirst) Speed up CPU/GPU Speed up CPU/CPU C180 (~51km) 4x4 0.23s 0.04s 0.37s 6.29x -1.62x"},{"location":"project2426/results/M2_Sept25/early_uw/","title":"Early UW Shallow Convection results (August)","text":"<p>Back to M2 results summary</p> <p>Project call for the porting of the UW Shallow Convection scheme (UW). The work was concluded in August with validation on performance backends and early pre-optimization benchmarks.</p>"},{"location":"project2426/results/M2_Sept25/early_uw/#validation","title":"Validation","text":"<p>Hardware &amp; software stack</p> <p>Validation using the Discover hardware</p> <p>Validation was done on a GEOS-FP run at C180-L137 (~51 km horizontal resolution) over 7 days of simulated time. Only the UW Shallow Convection scheme was swapped from Fortran to NDSL, the rest of the model code is running the original Fortran.</p> <p>Below are the distribution of differences between the reference Fortran and the CPU performance backend after 7 days of simulation.</p> <p>We start with an histogram showing the distribution of differences between the reference Fortran. While a good portion of the differences are centered around zero, there are still a larger number of non-zero outliers. especially for relative humidity and wind. These outliers are most likely due to numerical differences that still exist between the Fortran and NDSL in the UW shallow convection scheme. Alhough these errors are relatively small, they can become quite large over a 7 day simulation:</p> <p></p> <p>Looking at temperature in particular to explore the outliers, we show below the reference Fortran and the NDSL performance backend:</p> <p></p> <p></p> <p>The temperature patterns look very similar between the Fortran and Python. However some differences do exist at places where the temperature gradient is slightly misplaced in the NDSL. Below we graph the difference between Fortran and NDSL to show generally good spatial agreement of the runs, however some large errors do exist at several places. Again, these errors are most likely due to the numerical differences that still exist between the Fortan and the NDSL in the UW shallow convection scheme:</p> <p></p>"},{"location":"project2426/results/M2_Sept25/early_uw/#benchmark","title":"Benchmark","text":"<p>Benchmarking in progress...</p>"},{"location":"project2426/results/M2_Sept25/early_uw/#perturbed-initial-condition-fortran-runs","title":"Perturbed initial condition Fortran runs","text":"<p>To demonstrate how small errors can grow into larger errors throughout a 7-day Fortran simulation, we experimented by applying small perturbations to several UW inputs (e.g., T, Q, U, V) at initialization. We then ran the model for 7 days. The differences (Fortran - Fortran Perturbed) after the 7 day run are shown below:</p> <p></p> <p>Looking at temperature again, here are temperature fields for the Fortran and the perturbed Fortran runs: </p> <p></p> <p></p> <p>And the temperature differences between the reference Fortran and the perturbed Fortran runs:</p> <p></p> <p>It can be seen that by initializing the Fortran run with relatively small errors, those errors can become exacerbated over time and grow into much larger errors. Therefore, even though we have achieved very close numerical validation of the UW shallow convection scheme, the small errors that still exist between the Fortran and NDSL have the potential to grow into large errors throughout a longer simulation. Going forward, we plan to pay close attention to these errors and try to minimize them as best we can.</p>"},{"location":"project2426/results/M2_Sept25/summary/","title":"NDSL powered GEOS: CPU &amp; GPU validation &amp; benchmark","text":""},{"location":"project2426/results/M2_Sept25/summary/#tldr","title":"TL;DR","text":"<p>Bug</p> <p>A one-liner of bench &amp; validation results</p>"},{"location":"project2426/results/M2_Sept25/summary/#table-of-results","title":"Table of results","text":"Science Code Numerical Validation(C24) Scientific Validation(C180) CPU Benchmark (C180) GPU Benchmark (C180) GPU Benchmark (C720) Dynamics (Pace) \u274c: details \u274c \u274c \u274c \u274c Dynamics (GEOS v11.4.2) \u274c \u274c \u274c \u274c \u274c Moist - Microphysics \u274c \u274c \u274c \u274c \u274c Moist - Shallow Convection \u274c \u274c \u274c \u274c \u274c <p>C24 resolutions have 72 levels. All other resolutions have 137 levels.</p>"},{"location":"project2426/results/M2_Sept25/summary/#methodology","title":"Methodology","text":"<p>Bug</p> <p>Expand</p>"},{"location":"project2426/results/M2_Sept25/summary/#validation","title":"Validation","text":"<p>Numerical validation:</p> <p>Numerical validation is done comparing a single time step between Fortran and NDSL on the CPU. It was the base of the porting.</p> <p> <ul> <li>Both codes run with <code>-O0</code>, e.g., with compiler optimization turned off.</li> <li>A multi-modal metric is used for measuring difference that combines absolute and relative differences, and ULP measurement.</li> <li>Differences are expected (compilers, different codes) and reasonable thresholding will be used.</li> </ul> <p>Scientific validation:</p> <p>Scientific validation is done by comparing the results of 7 days of GEOS runs.</p> <p>See more details and discussion in the overview</p> <p>"},{"location":"project2426/results/M2_Sept25/summary/#benchmark","title":"Benchmark","text":"<p>Benchmark is done both on CPU and GPU at C180 L137. To showcase the difference in device bandwidth, we also run GPU on C720 L137.</p> <p>Benchmark are done online in GEOS but measure several performance which are all interconnected</p> <p>"},{"location":"project2426/results/M2_Sept25/summary/#hardware","title":"Hardware","text":"<p>NCCS's Discover A100 partition, referred as \"Discover\", per node:</p> <ul> <li>4x A100 GPUs \u2013 40 GB (released 2021)</li> <li>1x EPYC 7402 \u2013 96 cores (released 2020)</li> <li>Dual HDR Infiniband 2x200 Gbps</li> </ul> <p>NCCS's PRISM GH partition, referred as \"Prism GH\", per node:</p> <ul> <li>GH200: 1x H100 (96 GB HBME3) + 1 Grace (72 cores @ 2GHz- 480 GB LPPDR5) on the same die (released 2023)</li> <li>Dual HDR Infiniband 2x100 Gbps</li> </ul>"},{"location":"project2426/results/M2_Sept25/summary/#software-stack","title":"Software stack","text":"<p>Bug</p> <p>TODO</p>"},{"location":"project2426/results/M2_Sept25/summary/#data","title":"Data","text":"<p>The \"numerical validation\" data (a.k.a translate test) are available on NCCS datashare:</p> <ul> <li>Dynamics (Pace)</li> <li>Dynamics (GEOS v11.4.2)</li> </ul>"},{"location":"project2426/results/M2_Sept25/summary/#overviews-and-earlier-results","title":"Overviews and earlier results","text":"<ul> <li>Validation - overview</li> <li>Benchmark - overview</li> <li>Early GFDL Single Moment microphysics</li> <li>Early UW Shallow Convection Scheme</li> </ul>"},{"location":"project2426/results/M2_Sept25/validation_overview/","title":"Validation","text":"<p>TBD</p>"},{"location":"satellite-work/pace/","title":"Pace","text":"<p>Funded by Vulcan and AI2<sup>1</sup>, the Pace model was a pure python model based on the GT4Py DSL combined with leveraging DaCe for full program optimization. The model is a port combining the FV3 Dynamical Core and the microphysics of NOAA's GFDL. The two papers published on it are:</p> <ul> <li>Dahm, Johann et al. \u201cPace v0.2: a Python-based performance-portable atmospheric model.\u201d Geoscientific Model Development (2023): n. pag. PDF</li> <li>Ben-Nun, Tal et al. \u201cProductive Performance Engineering for Weather and Climate Modeling with Python.\u201d SC22: International Conference for High Performance Computing, Networking, Storage and Analysis (2022): 1-14. PDF</li> </ul> <p>Below we summarize the findings. For more figures and in-depth explanation read the papers.</p>"},{"location":"satellite-work/pace/#validation","title":"Validation","text":"<p>The model ran for an idealistic baroclinic wave for 9 days at 1.8km average horizontal resolution. Validation of the model code was done numerically section by section first and was followed up with a scientifically relevant diagnostics.</p> <p>Here the temperature at 850mb for the reference Fortran model and Pace:</p> <p></p> <p>The 9 days simulation was stable and produced rain as expected. Below is a plot of rain, cloud cover and pressure gradients after 9 days.</p> <p></p>"},{"location":"satellite-work/pace/#benchmark","title":"Benchmark","text":"<p>The 9 days simulation presented above was computed on the 4056 nodes of the Piz Daint supercomputer with 4056 P100 Nvidia GPUs. The throughput was 0.11 SYPD or 40.15 SDPD.</p> <p>More complete figures for benchmarking on smaller runs are shown below.</p> <p></p> <p>Comparison of CPU-Fortran run vs GPU-Python runs relative to node scaling</p> <p></p> <p>Performance analysis of representative FV3 (dynamical core) modules</p> <ol> <li> <p>Results presented here by a co-authors of the quoted papers\u00a0\u21a9</p> </li> </ol>"},{"location":"tcn/","title":"The Code Nebulae","text":"<p>The Code Nebulae is a sandbox storing early PoC, benchmark data, useful scripts, etc. Shortname for the package is <code>tcn</code>.</p> <p>\ud83d\udea7 This is a staging/PoC area for code, inherently every code here is unstable. \ud83d\udea7</p>"},{"location":"tcn/packages/","title":"tcn packages","text":""},{"location":"tcn/packages/#tcnbenchmark","title":"<code>tcn.benchmark</code>","text":"<ul> <li>Overview \ud83d\udea7</li> <li>Tasklist \ud83d\udea7</li> </ul>"},{"location":"tcn/packages/#tcnci","title":"<code>tcn.ci</code>","text":"<ul> <li>Overview \ud83d\udea7</li> <li>Tasklist \ud83d\udea7</li> </ul>"},{"location":"tcn/packages/#tcnhws","title":"<code>tcn.hws</code>","text":"<ul> <li>Overview \ud83d\udea7</li> <li>Tasklist \ud83d\udea7</li> </ul>"},{"location":"tcn/packages/#tcnplots","title":"<code>tcn.plots</code>","text":"<ul> <li>Overview \ud83d\udea7</li> <li>Tasklist \ud83d\udea7</li> </ul>"},{"location":"tcn/packages/#tcnpy_ftn_interface","title":"<code>tcn.py_ftn_interface</code>","text":"<ul> <li>Overview \ud83d\udea7</li> <li>Tasklist \ud83d\udea7</li> </ul>"},{"location":"tcn/packages/#tcnvalidation","title":"<code>tcn.validation</code>","text":"<ul> <li>Overview \ud83d\udea7</li> <li>Tasklist \ud83d\udea7</li> </ul>"},{"location":"tcn/results/","title":"Results","text":"<ul> <li>Overview \ud83d\udea7</li> </ul>"},{"location":"technical/","title":"Technical documentation","text":"<p>This is technical part of the documentation, intended primarily for DSL developers (in contrast to DSL users). The docs here differentiate frontend and backend, give tips for your development setup and include notes on the translate tests system used to port FORTRAN code to NDSL.</p> <p>We have many ideas on what to do in the future. Since the work is so fragmented, across repositories, we started a laundry list in the hope keep things together in one place.</p>"},{"location":"technical/laundry-list/","title":"\ud83d\udc55 Laundry list","text":"<p>This document is a loose list of topics, bringing together planned and known issues from multiple repositories into what we hope is a better overview.</p>"},{"location":"technical/laundry-list/#performance-related-topics","title":"\u23f1\ufe0f Performance related topics","text":""},{"location":"technical/laundry-list/#planned-optimizations","title":"Planned optimizations \ud83d\ude80","text":"<p>There are a bunch of optimizations that we have planned with the schedule tree bridge and a bunch of optimization that we need to build back with the new bridge:</p> <ul> <li>Different loops per target hardware: like previously, but less confusing</li> <li>Tiling: like previously, but hardware dependent. More details in this file.</li> <li>CPU: temps are allocated &amp; de-allocated on the fly</li> <li>Axis-split merge</li> <li>Over-computation merge</li> <li>Local caching</li> <li>Inline thread-local transients: like previously.</li> <li>Optimize OpenMP pragmas: Check which of the previous optimizations still make sense.</li> <li>We ran a special version of <code>TrivialMapElimination</code> with more condition to when it applies.</li> <li>Special cases for stencils without effect? They were treated separately in the previous bridge.</li> <li>In the previous bridge, we'd merge a horizontal region with the loop bounds in case the horizontal region was the only thing inside that loop.</li> <li>In the previous bridge, we'd split horizontal execution regions. This was also used for orchestration in NDSL. To be re-evaluated.</li> <li>When orchestrating a lot of the fields that are held by the classes (the <code>self.tmp_field</code>) are transient to the local object (could be multiple stencils!) but those are flagged as global memory anyway. Re-scoping them to proper transients could lead to better memory &amp; scalarization. At the <code>stree</code> level we don't scope the arrays to any space, we just flag them and the STREE-to-SDFG bridge deals with localizing them. Could we just write a pass scoping the containers post parsing and let the bridge do it?</li> <li>\u2705 For stencils only we are missing a <code>simplify</code> (and potentially a <code>validate</code>?) right before going to code generation</li> <li>Initialization code is not recognized as a special case and badly optimized. Code like this</li> </ul> <pre><code>    with computation(PARALLEL), interval(...):\n        # Initialize output variables defined for all grid points\n        dcm_out = 0.0\n        cufrc_out = 0.0\n        fer_out = constants.MAPL_UNDEF\n        fdr_out = constants.MAPL_UNDEF\n        qldet_out = 0.0\n        qidet_out = 0.0\n        qlsub_out = 0.0\n        qisub_out = 0.0\n        ndrop_out = 0.0\n</code></pre> <p>will cache miss given enough fields when they are, in truth, a <code>memcopy</code> away from being optimized.</p>"},{"location":"technical/laundry-list/#allocation-lifetime-of-temporaries-in-stencils","title":"Allocation lifetime of temporaries (in stencils) \ud83d\uddd1\ufe0f","text":"<p>IN the OIR -&gt; Schedule Tree bridge, we allocate temporary fields with <code>AllocationLifetime.Persistent</code>. This has been done before (in the initial GT4Py-DaCe bridge). This isn't a good default and we tried to change it. Ideally we'd like to keep the scope of temporary fields as small as possible. <code>AllocationLifetime.Global</code> seems like a good default (since <code>AllocationLifetime.Scope</code>is too small for temporaries that are populated in one <code>with computation(..)</code> block and re-used subsequent ones).</p> <p>We tried allocating temporary field with <code>AllocationLifetime.Global</code> and hit two issues</p> <ol> <li>Dead dataflow elimination (DDE) crashed hard when we access (non-scalarized) temporaries with data dimension inside Tasklets (DaCe issue). We put a temporary workaround in place, such that DDE doesn't try to remove such calls.</li> <li>With the above fix in place, Florian ran into (massive) memory leaks with tracers when running the dycore. Basically, the generated SDFG validates, but code generation writes <code>new</code> without corresponding <code>delete[]</code>. It looks like the workaround from above, generates \"Zombie 3D fields\" (e.g. <code>br</code> which is allocated, never read and never deleted) in <code>FvTp2d</code> under certain conditions. As per Florian, not easy to repro and no smaller repro found thus far.</li> </ol>"},{"location":"technical/laundry-list/#dynamics-runtime","title":"Dynamics runtime \ud83d\udc0c","text":"<p>Chris reported a runtime of 25 sec per timestep for dynamics (<code>NX=2</code> and <code>NY=12</code>) with <code>gt:cpu_kfirst</code> where the Fortran baseline is only 5 sec / timestep. This is with the new amount of tracers, but still, we shouldn't be so far off.</p>"},{"location":"technical/laundry-list/#load-time-of-so-files","title":"Load time of <code>.so</code> files \u231b","text":"<p>Running (<code>FV3_DACEMODE=Run</code>) the pre-compiled, orchestrated translate test for <code>D_SW</code> shows that the majority of time (5 sec) is spent in loading the <code>.so</code> file, compared to the actual run time (27 ms).</p> <pre><code>2025-07-08 17:44:40|INFO|rank 0|ndsl.logging:[DaCeOrchestration.Run] Rank 0 reading/writing cache .gt_cache_FV3_A\n[DaCe Config] Rank 0 loading SDFG [...]/PyFV3/.gt_cache_FV3_A/dacecache/pyFV3_stencils_d_sw_DGridShallowWaterLagrangianDynamics___call__\n2025-07-08 17:44:40|DEBUG|rank 0|ndsl.logging:[DaCeOrchestration.Run] Load precompiled .sdfg (.so)...\n2025-07-08 17:44:45|DEBUG|rank 0|ndsl.logging:[DaCeOrchestration.Run] Load precompiled .sdfg (.so)...4.979876279830933s.\n2025-07-08 17:44:45|DEBUG|rank 0|ndsl.logging:[DaCeOrchestration.Run] Run...\n2025-07-08 17:44:45|DEBUG|rank 0|ndsl.logging:[DaCeOrchestration.Run] Run...0.026755094528198242s.\n</code></pre>"},{"location":"technical/laundry-list/#repro","title":"Repro","text":"<p>Run the orchestrated translate test for <code>D_SW</code> from the PyFV3 repository. Build once with <code>FV3_DACEMODE=Build</code> and then run with <code>FV3_DACEMODE=Run</code>.</p>"},{"location":"technical/laundry-list/#hardware-detection","title":"Hardware detection \ud83d\udee0\ufe0f","text":"<p>We might want to centralize hardware detection. We currently</p> <ul> <li>detect HW for CPU/GPU through the presence of cupy,</li> <li>check for GH200 nodes explicitly to build a valid DaCe config in NDSL,</li> <li>and plan to use HW-dependent tiling (in NDSL/gt4py).</li> </ul>"},{"location":"technical/laundry-list/#frontend","title":"&lt;/&gt; Frontend","text":""},{"location":"technical/laundry-list/#locals","title":"Locals","text":"<ul> <li>See PR description</li> </ul>"},{"location":"technical/laundry-list/#pot-pourri","title":"Pot-pourri","text":"<ul> <li>\ud83d\udc1e: Unable to do operation in absolute indexer in stencils.<ul> <li>This WORKS: <code>field.at(K=k22 - k_index)</code> with <code>k22</code> and <code>k_index</code> as <code>IntField32</code></li> <li>This FAILS: <code>field.at(K=kbcon - 1)</code> with <code>kbcon</code> as <code>IntField32</code></li> </ul> </li> <li>ChrisH and Katrina report that <code>.at(K=...)</code> only works with 64-bit integers. 2D integer fields (e.g. <code>IntFieldIJ</code>) also seem to make problems. Sounds like this is related to the bug above.</li> <li>Missing integer divide operator (<code>//</code>) in GT4Py (issue)</li> <li>Support for <code>pass</code> inside stencils</li> <li>Support for use of <code>Enum</code> within the stencils to allow for modes, errors, and other integer based identifiers to be readable</li> <li>Introduce type hints that would help see which fields are <code>Interface</code>, e.g. a <code>FloatField_KInterface</code> or equivalent</li> <li>Rename the <code>X|Y|Z_DIM</code> into <code>I|J|K_DIM</code> and overall flush <code>X|Y|Z</code> from the middleware</li> <li>Grell-Freitas Deep Convection scheme implemented a small perturbation per grid point: we need a way to generate randomness per point</li> </ul>"},{"location":"technical/laundry-list/#debug","title":"\ud83d\udc1e Debug","text":"<ul> <li>Most of the time we could do <code>ast.unparse(node)</code> to give a better idea of where the error is, even when the source/line fails.</li> </ul>"},{"location":"technical/laundry-list/#code-maintenance","title":"\ud83d\udea7 Code maintenance","text":""},{"location":"technical/laundry-list/#the-one-runtime-design","title":"The One Runtime Design","text":"<p>The spaghetti code God needs to die.</p>"},{"location":"technical/laundry-list/#grid-layout","title":"Grid layout \ud83c\udf10","text":"<ul> <li>Issues with 3x3 layouts (because of the tile \"in the middle\", the one that has no edge/corner) - is this still a problem?</li> </ul>"},{"location":"technical/laundry-list/#layout-transparency-missing-tests","title":"Layout transparency: missing tests \ud83c\udf10","text":"<p>We are missing layout transparency tests.</p> <p>Issue: https://github.com/NOAA-GFDL/NDSL/issues/131</p>"},{"location":"technical/laundry-list/#oir-mask-statements","title":"OIR mask statements \ud83d\ude37","text":"<p>There are two issues with OIR mask statements in GT4Py.</p>"},{"location":"technical/laundry-list/#else-branches-are-not-preserved","title":"<code>else</code> branches are not preserved \ud83d\udd00","text":"<p>OIR translates</p> <pre><code>if condition:\n    pass\nelse:\n    pass\n</code></pre> <p>into</p> <pre><code>if condition:\n    pass\nif not condition:\n    pass\n</code></pre> <p>while this is great for e.g. the numpy backend, it makes DaCe graphs overly complicated and generates ugly (and maybe slow?) C++ code.</p> <p>The current plan is to work around this by not applying the above transformation if we are lowering to the DaCe backend. This way, we don't have to add support for <code>else</code>-branches in all other backends.</p>"},{"location":"technical/laundry-list/#condition-evaluation-split-from-condition","title":"Condition evaluation split from condition \ud83d\udd00","text":"<p>OIR will translate</p> <pre><code>if condition:\n    pass\n</code></pre> <p>into</p> <pre><code>condition_eval = condition\nif condition_eval:\n    pass\n</code></pre> <p>in case <code>condition</code> contains a <code>FieldAccess</code>. While this is great for e.g. the numpy backend, it makes DaCe graphs overly complicated and generates ugly (and maybe slow?) C++ code. This optimization should be a backend choice (e.g. be applied after OIR).</p> <p>The current plan is to work around this by not applying the above transformation if we are lowering to the DaCe backend. This way, we don't have to touch all other backends.</p>"},{"location":"technical/laundry-list/#schedule-tree-horizontal-regions-oob-memlet-warnings","title":"Schedule tree / horizontal regions: oob memlet warnings \u26a0\ufe0f","text":"<p>DaCe (most times?) emits warnings about potential out of bound memory access when horizontal regions are used. We think this is okay (e.g. we think there are no out-of-bounds memory accesses) and tracked it down to how we setup the data, define the iteration variable and how we set the Memlets.</p> <p>Ideally, we'd like to refactor data setup, iteration scopes and memlet definition such that the warning disappears. Since validation is okay and this warning has been there before, we don't take immediate action.</p> <p>Issues:</p> <ul> <li>https://github.com/GridTools/gt4py/issues/727 (mentions \"add issue (and fix) for negative origins in DaCe-orchestrated context\")</li> </ul>"},{"location":"technical/laundry-list/#python-version-and-numpy-support","title":"Python version and numpy support \ud83d\udc0d","text":"<p>NDSL python version support is currently hard-coded to 3.11. Moving on to 3.12 reportedly breaks things. To be investigated.</p> <p>Bottom line, this will come in the future as 3.12 is the last to support numpy &lt; 2.0. DaCe and GT4Py (next) moved to support numpy 2.0. Python version 3.12 (see discussion above) is the last python version to support 1.26.4.</p>"},{"location":"technical/laundry-list/#stabilize-schedule-tree-and-move-to-dace-20","title":"Stabilize schedule tree and move to DaCe 2.0 \ud83c\udf33","text":"<p>DaCe stopped feature development on the v1 branch (only critical fixes can go in) and is working actively on shaping the next major version. According to Tal, DaCe 2.0 will be much nicer and fix everything ;)</p> <p>We built the schedule tree on top of the v1 branch see here why and are thus currently in limbo between versions. We'll need to update once DaCe 2.0 gets stable or - at least - takes shape.</p>"},{"location":"technical/laundry-list/#storing-compressed-sdfgs","title":"Storing compressed SDFGs \ud83d\udddc\ufe0f","text":"<p>DaCe has the option to store SDFGs in compressed format. Since SDFGs are stored as (human readable) plain-text json, this can reduce file sizes drastically. To be evaluated if this has a negative impact on save &amp; load times. The hypothesis is no, but it's always better to check and there are probably a bunch of hard-coded <code>.sdfg</code> extension that need to be adapted.</p>"},{"location":"technical/laundry-list/#interval-context-drop-explicit-parallel","title":"Interval context: drop explicit <code>PARALLEL</code> \ud83d\udff0","text":"<p>Currently, users need to specify whether their stencil can run in parallel or not. From data dependency analysis, we should be able to derive if it is safe to run a stencil in parallel or not. The would allow us to remove the <code>PARALLEL</code> option and auto-magically enable parallelism when possible.</p> <p>Issue: https://github.com/GridTools/gt4py/issues/1009</p>"},{"location":"technical/laundry-list/#auto-detect-compile-time-constant-conditions","title":"Auto-detect compile-time constant conditions \ud83e\ude84","text":"<p>Currently, users can mark compile-time constant conditions with the <code>__INLINED</code> keyword. Since we are a DSL and since the idea is that users shouldn't need to care, we'd like to detect auto-magically when a condition is compile-time constant. We can then automatically remove compile-time constant conditions that evaluate to <code>False</code>.</p> <p>Issue:https://github.com/GridTools/gt4py/issues/1011</p>"},{"location":"technical/laundry-list/#stencil-call-arguments-shouldnt-be-pruned","title":"Stencil call arguments shouldn't be pruned \ud83e\uddf9","text":"<p>We might find arguments to be unused or we might make them unused by removing compile-time constant branches of conditions. Even in these scenarios, we shouldn't attempt to remove call arguments because this is hard to trace through all backends and shouldn't have any noticeable performance impact. A general compiler should be able to prune unused function arguments.</p> <p>Issues:</p> <ul> <li>https://github.com/GridTools/gt4py/issues/710</li> <li>https://github.com/GridTools/gt4py/issues/1010</li> <li>https://github.com/GridTools/gt4py/issues/2083</li> <li>https://github.com/NOAA-GFDL/NDSL/issues/70</li> </ul> <p>We should double-check everything, but it seems like the gt4py/dace bridge based on schedule tree fixed that (at least for the moment - not that it's not still fragile).</p>"},{"location":"technical/laundry-list/#ndsl-constants-system","title":"NDSL constants system \ud83d\udccb","text":"<p>There are a bunch of issue floating around (in NDSL) about constants and that they should be refactored into a new/better system.</p> <p>Issues:</p> <ul> <li>https://github.com/NOAA-GFDL/NDSL/issues/6</li> <li>https://github.com/NOAA-GFDL/NDSL/issues/32</li> <li>https://github.com/NOAA-GFDL/NDSL/issues/64</li> </ul>"},{"location":"technical/laundry-list/#build-system","title":"\ud83c\udfd7\ufe0f Build system","text":""},{"location":"technical/laundry-list/#multi-compiler-native-support","title":"Multi-compiler native support \u2692\ufe0f","text":"<ul> <li><code>clang</code> compilation fails on <code>dace:cpu</code> because of <code>-fopenmp</code> default flag</li> <li><code>icc</code>/<code>ifx</code> support (NOAA tried and Frank has an old branch from Xingqiu)</li> </ul>"},{"location":"technical/laundry-list/#reflect-orchestration-in-backend-name","title":"Reflect orchestration in backend name \ud83c\udfbc","text":"<p>Currently, orchestration (or not) defined as a combination of backend name <code>dace:{cpu, gpu}</code> and the environment variable <code>FV3_DACEMODE</code>.</p> <p>Issue: https://github.com/NOAA-GFDL/NDSL/issues/46</p>"},{"location":"technical/laundry-list/#move-dace-cache-into-gt4py-cache-folder","title":"Move dace cache into gt4py cache folder \u267b\ufe0f","text":"<p>Issue: https://github.com/GridTools/gt4py/issues/1035</p>"},{"location":"technical/laundry-list/#leverage-cmake-in-gt4py-toolchain","title":"Leverage cmake in GT4Py toolchain \ud83d\udee0\ufe0f","text":"<p>In GT4py, we'd like to move away from setuptools and leverage cmake. This will unlock goodies like parallel compilation and more modern build backends (e.g. we might give ninja a try), which will hopefully speed up code generation.</p> <p>Issue: https://github.com/GridTools/gt4py/issues/83</p>"},{"location":"technical/laundry-list/#dace-bridge-caching","title":"Dace bridge caching \u267b\ufe0f","text":"<p>The OIR -&gt; schedule tree -&gt; SDFG bridge has support for caching the generated (unspecific) SDFG. It's used as \"online\" caching where the first SDFG is always generated (and then written to disk for re-use). We could expand this to \"offline\" caching where we'd fist check if an SDFG exists on disk and use this one if it does.</p>"},{"location":"technical/laundry-list/#dependabot-for-gha-dependencies","title":"Dependabot for GHA dependencies \ud83e\udd16","text":"<p>Dependabot can be used to keep dependencies up to date. We could start by letting the bot check versions of GitHub Actions. In the <code>pace</code> repo, there's even a dormant <code>dependabot.yml</code> config for updating the submodules.</p>"},{"location":"technical/laundry-list/#python-packaging-questions-ndsl-pyfv3-pyshield-pace","title":"\u2705 Python packaging questions (NDSL, PyFV3, PySHiELD, pace) \ud83d\uddc4\ufe0f","text":"<p>We are considering to move to <code>pyproject.toml</code>. Some questions about developer installs remain.</p> <p>Issues:</p> <ul> <li>https://github.com/NOAA-GFDL/NDSL/issues/138</li> <li>https://github.com/NOAA-GFDL/PyFV3/issues/52</li> <li>https://github.com/NOAA-GFDL/pace/issues/118</li> <li>https://github.com/NOAA-GFDL/PySHiELD/issues/32</li> </ul>"},{"location":"technical/laundry-list/#work-organization","title":"\ud83d\udcc1 Work organization","text":""},{"location":"technical/laundry-list/#issue-duplication-fragmentation","title":"Issue duplication / fragmentation \ud83d\udcc4","text":"<p>For milestone 1, we were using a GitHub project in the <code>GEOS-ESM</code> organization. This forced us to have a fork of NDSL under that organization, which lead to issue fragmentation / duplication on that fork. We should find the time to clean these issues.</p>"},{"location":"technical/backend/","title":"Backend overview","text":"<p>NDSL has multiple backends, each serving different purposes:</p> <ul> <li>Debug backend: easy to read python code. Playground for new DSL features. Really, really slow.</li> <li>Numpy backend: \"fast\" python-based backend. Playground for new science code.</li> <li>DaCe backends: performance backends for running at scale in production. DaCe backends have the ability to do full program optimization (e.g. analyze and optimize even code in between stencils), see orchestration.</li> </ul> <p>Note: DaCe backends is plural because that backend can either generate code that targets CPUs or GPUs.</p> <pre><code>---\ntitle: GT4Py IR overview\n---\nflowchart LR\n    stencil[\"`\n        Stencil code\n        (NDSL)\n    `\"]\n    defir[\"Definition IR\"]\n    gtir[\"GT script IR\"]\n    oir[\"`\n        Optimization IR\n        (per stencil)\n    `\"]\n    debug[\"Debug backend\"]\n    numpy[\"Numpy backend\"]\n    dace[\"DaCe backends\"]\n\n    stencil --&gt; defir --&gt; gtir --&gt; oir\n    oir --&gt; debug\n    oir --&gt; numpy\n    oir --&gt; dace</code></pre>"},{"location":"technical/backend/#dace-backend-details","title":"DaCe backend details","text":"<p>The DaCe backend workflow cleanly separates scheduling choices (i.e. macro-level optimizations like loop order, kernel merges, ...) from DaCe dataflow optimization.</p> <pre><code>---\ntitle: DaCe backend workflow\n---\nflowchart LR\n    oir[\"`\n        OIR\n        (GT4Py)\n    `\"]\n    stree[\"`\n        Schedule Tree\n        (DaCe)\n    `\"]\n    sdfg[\"`SDFG`\"]\n    cpu[\"`\n        CPU\n        codegen\n    `\"]\n    gpu[\"`\n        GPU\n        codegen\n    `\"]\n\n    oir --&gt; stree --&gt; sdfg\n    sdfg --&gt; cpu\n    sdfg --&gt; gpu</code></pre> <p>All scheduling choices happen in the schedule tree. After the schedule is fixed, we create a Stateful Dataflow multiGraphs (SDFG), DaCe's representation for data-driven optimizations. Code generation (to multiple targets) follows from the SDFG.</p>"},{"location":"technical/backend/#schedule-tree","title":"Schedule tree","text":"<ul> <li>current state of the feature</li> <li>choice of representation</li> <li>choice of DaCe version to work against (for the first version)</li> <li>choice of integration point (for the first version)</li> </ul>"},{"location":"technical/backend/#orchestration","title":"Orchestration","text":"<p>DaCe backends can either optimize per-stencil or do full program optimization through orchestration. Orchestration is a system that bring GT4Py stencils and regular python code together. This opens up the potential for full program optimization. Orchestration enables the most potent wide-context optimizations. Details and Limitations.</p>"},{"location":"technical/backend/#repositories","title":"Repositories","text":"<p>Backend work is split into multiple repositories, each having their quirks to work with. In particular,</p> <ul> <li>NDSL - Pulls everything together and exposes \"the DSL\". In particular, orchestration code lives in this repository.</li> <li>GT4Py - The component that defines the frontend, has all the intermediate representations (IR) and dispatches to multiple backends.</li> <li>DaCe - Data-driven optimization framework used in GT4Py as performance backend. Full program optimizer driving orchestration.</li> </ul> <p>NDSL is then used in the following repositories:</p> <ul> <li>PyFV3 NDSL port of the FV3 dynamical core.</li> <li>pace combines the PyFV3 port with PySHiELD physics, a DSL port of the SHiELD physics.</li> </ul>"},{"location":"technical/backend/coding-guidelines/","title":"General coding guidelines","text":"<p>This page documents very general coding guidelines as emerged from team discussions.</p> <p>Note</p> <p>In case you are contributing to downstream repositories such as GT4Py or DaCe, be sure to comply with their coding guidelines.</p>"},{"location":"technical/backend/coding-guidelines/#string-concatenation","title":"string concatenation","text":"<p>Prefer <code>f-strings</code> over any other method of concatenation strings.</p> String concatenation with f-strings <pre><code>my_world = \"world\"\ngreeting = \"Hello\"\nconcatenated_string = \"f{greeting} {my_world}\"\n</code></pre> <p>Rationale: Florian likes this way and nobody else had a strong opinion.</p>"},{"location":"technical/backend/coding-guidelines/#pytest-raises-vs-xfail-vs-skip","title":"pytest:  <code>raises</code> vs. <code>xfail</code> vs. <code>skip</code>","text":"<p>In short:</p> <ul> <li>use <code>pytest.raises</code> to check that we raise an exception if the user makes a mistake, e.g. to check that for a program with syntax error we raise an exception.</li> <li>use <code>xfail</code> to indicate that a test fails, but should be supported, e.g. because we are missing a feature (or missing a feature for a certain backend).</li> <li>use <code>skip</code> to indicate that under a certain condition the test doesn't make sense.</li> </ul> <p>That means: <code>skip</code> and <code>pytest.raises</code> are used in bug-free cases, <code>xfail</code>s are the ones that should be fixed. Further reading in the pytest docs.</p> <p>Rationale: Established standard in the ecosystem and actively promoted by the <code>pytest</code> documentation.</p>"},{"location":"technical/backend/dace-bridge/","title":"GT4Py / DaCe bridge","text":"<p>\"The bridge\" commonly refers to the DaCe backends of GT4Py. The backends translate GT4Py stencils into SDFGs, which allows DaCe to do its magic on them. Since stencil-level optimization isn't enough for application performance, NDSL supercharges the DaCe backends by transforming all code to SDFGs. We call this orchestration.</p>"},{"location":"technical/backend/dace-bridge/#building-the-bridge-a-two-step-process","title":"Building the bridge - a two step process","text":"<p>Roughly, the dace backends are built in two steps:</p> <ol> <li>For each stencil, we build a \"coarse-grained SDFG\" with a library node for every <code>VerticalLoop</code></li> <li>We then \"expand\" each library node, replacing it with a nested SDFG</li> </ol>"},{"location":"technical/backend/dace-bridge/#building-the-coarse-grained-sdfg","title":"Building the coarse-grained SDFG","text":"<p>Building the coarse-grained SDFG happens in the <code>OirSDFGBuilder</code><sup>1</sup> and is cached as <code>unexpanded_sdfg</code> in the <code>SDFGManager</code><sup>2</sup> after \"pre-expand transformations\" (e.g. setting loop expansion order and tile sizes) are applied.</p> Refactor opportunity: Transient read after write <p><code>OirSDFGBuilder</code> follows a simple algorithm that connects an incoming Memlet for every read access and an outgoing Memlet for every write access to the library node. For transient memory that is only read after written (within that library node), this results in an unused incoming Memlet. DaCe will warn about such situation while building the SDFG, reporting a Memlet that reads undefined memory.</p>"},{"location":"technical/backend/dace-bridge/#expanding-the-library-nodes","title":"Expanding the library nodes","text":"<p>Expanding a library node results in what the <code>SDFGManager</code> knows as the <code>expanded_sdfg</code>. There's no caching at this level. All library nodes are - one by one - transformed by the <code>expansion()</code> call on <code>StencilComputationExpansion</code><sup>3</sup>. This forms one big SDFG on which \"post expansion transformations\" (eliminating trivial maps, controlling OpenMP parallelization) are applied.</p> <p>Library node expansion is again a two step process:</p> <ol> <li>Build DaCe-IR from OIR</li> <li>Build a nested SDFG from the DaCe-IR<ol> <li>Codegen for code in Tasklets.</li> </ol> </li> </ol>"},{"location":"technical/backend/dace-bridge/#building-dace-ir-from-oir","title":"Building DaCe-IR from OIR","text":"<p>The DaCe-IR is built in <code>DaCeIRBuilder</code><sup>4</sup>. DaCe-IR is a hybrid IR somewhere between keeping semantic information (e.g. <code>dcir.HorizontalRestriction</code>) used for potential optimizations and - on the other hand - trying to be close to the SDFG (e.g. <code>dcir.Memlet</code> and <code>dcir.Tasklet</code>). This dual-use make the IR a bit cumbersome to work with at times. A task<sup>5</sup> was logged to evaluate splitting the IR.</p> First version and bridge refactors <p>The original bridge was written in a way that pushed all code of a <code>oir.HorizontalRegion</code> into one big <code>Tasklet</code>, hiding all control flow happening inside horizontal regions. Control flow was exposed with this PR. In many places, you might see remnants of that past and sub-optimal design decisions that we'll need to address in the future.</p> <p>A rundown of what we do while building the IR</p> <ol> <li>The IR starts a the <code>oir.VerticalLoop</code> level, where the \"unexpanded SDFG\" left off.</li> <li>\"Expansions\" are the current system to change loop order depending on HW (currently: hard-coded lists for CPU- and GPU-devices)</li> <li>While visiting <code>oir.HorizontalRegion</code>s, we recursively create <code>oir.CodeBlock</code>s, to group statements that belong together. Initially, the body the <code>oir.HorizontalRegion</code> is put in a <code>CodeBlock</code>. As we then process the <code>oir</code> statements in that <code>CodeBlock</code> and we recursively add nested <code>oir.CodeBlocks</code> to group the bodies of <code>oir.MaskStmt</code>s and <code>oir.While</code> loops. This allows us to keep track of <code>targets</code>, the set of variables written in the current <code>Tasklet</code>. <code>targets</code> are used when visiting <code>FieldAccess</code> or <code>ScalarAccess</code> to name the variables. For each Tasklet map incoming Memlets to <code>gtIN__{name}</code> and outgoing Memlets to <code>gtOUT__{name}</code>. We thus need to know if read from or write to a variable/field. Furthermore, when reading after writing to the same variable within a Tasklet, we need to read from the \"out\"-version of the variable that was previously written.</li> <li>While loops and if statements inside horizontal regions are translated to <code>dcir.While</code> and <code>dcir.MaskStmt</code> which will generate control flow in tasklet code. A task was logged to change this in the future. For now we keep it as-is because this would need changes to the <code>HorizontalMaskRemover</code>, which operates on the DaCe-IR mid-flight while building (see <code>remove_horizontal_region()</code> inside <code>_process_map_item()</code> in the <code>DaCeIRBuilder</code>).</li> <li>Each <code>oir.CodeBlock</code> is then translated into one of three objects<ol> <li><code>dcir.ComputeState</code> wraps assignment statements in a <code>dcir.Tasklet</code></li> <li><code>dcir.Condition</code> contains a <code>dcir.Tasklet</code> to evaluate the condition and a <code>true_state</code> of type <code>ComputeState | Condition | WhileLoop</code>. Technically, the DaCe-IR also allows a <code>false_state</code>. However, somewhere in \"higher IRs\" the decision was made to transform all <code>else</code> branches to separate <code>if</code> statements with a negated condition.</li> <li><code>dcir.WhileLoop</code> contains a <code>dcir.Tasklet</code> to evaluate the condition and a <code>body</code> of type <code>ComputeState | Condition | WhileLoop</code></li> </ol> </li> <li>When a <code>dcir.Tasklet</code>s is built, we construct <code>dcir.Memlets</code> for field access inside that Tasklet from the oir. Memlets for scalar access are only added when building the SDFG from the DaCe-IR (see below).</li> <li>After a tasklet is built, <code>_fix_memlet_array_access()</code> runs a pass for Memlets with partial index subset, variable offset reads, or K-write offsets. This pass writes explicit indices into <code>explicit_indices</code>, which are then used during Tasklet codegen (see below). We should revisit this and clean up our approach to indexing (see note below).</li> </ol> Refactor opportunity: <code>if</code> / <code>else</code> statements <p>We should track down where <code>else</code> branches of <code>if</code> statements get \"lost\" and propagate them all the way down to DaCe-IR and when we build the SDFGs. While DaCe has a pass that detects subsequent <code>if</code> statements with negated conditions, it doesn't always apply. As a result, our generated code is over complicated. We don't expect this to impact performance to the point that it matters now, but it might in the future and - more importantly - it makes debugging and reasoning about generated code more complicated than it has to be.</p> Refactor opportunity: Indexing <p><code>_fix_memlet_array_access()</code> was introduced as a temporary fix after DaCe stopped support for partial index subset. We should re-visit indexing as a whole and find a cleaner solution that doesn't create partial index subsets in the first place and supports new features like variable offset reads and K-offset writes.</p> <p></p> Refactor opportunity: <code>CodeBlock</code>s <p><code>CodeBlock</code>s were added at the OIR-level such that the DaCe-IR visitor could recursively create and visit them at the same time. <code>oir.CodeBlock</code>s are not used in any other backend for now. This is fundamentally not the way to how build things nicely and a temporary duct tape solution. We should propagate <code>gtir.BlockStmt</code> throughout the <code>oir</code>-level and re-use that instead in the DaCe-IR. <code>if</code> / <code>else</code> statements should be kept together at the <code>oir</code>-level. <code>oir.MaskStmt</code> sounds like we were catering too much for the <code>numpy</code> backend in the past.</p>"},{"location":"technical/backend/dace-bridge/#building-sdfg-from-dace-ir","title":"Building SDFG from DaCe-IR","text":"<p>The main work is done in <code>StencilComputationSDFGBuilder</code><sup>6</sup>. Tasklet code is generated in a separate visitor, <code>TaskletCodegen</code><sup>7</sup>.</p> <p><code>StencilComputationSDFGBuilder</code> is your standard node visitor translating the DaCe-related concepts of DaCe-IR to actual SDFGs. Whenever this process is not straight forward, it's because we didn't prepare things well enough in previous steps. One notable pain point is how we access scalar variables. In the image above, note how <code>statements{0,1,8}</code> are in the same (blue) <code>CodeBlock</code>. In the SDFG representation, the picture looks more like this</p> <p></p> <p>Notice how <code>statements{0,1}</code> are in one Tasklet and <code>statement8</code> is in another Tasklet. If any local temporaries are written as part of statements 0 or 1, they could be read in <code>statement8</code>. We thus don't have any local scalars anymore and expose all writes (to scalars) for possible future reads. A standard DaCe cleanup pass will get rid of any unused write access node. This only needs special care for local scalar accesses because array memory is managed at the (nested) SDFG level. In the first version of the bridge, scalars could be represented as local scalars of the one big Tasklet. This leave a refactor opportunity to adapt the DaCe-IR.</p> Refactor opportunity: Memlets for scalar accesses <p>In the first version of the bridges, scalar could be treated as local scalars of the one big Tasklet that existed. There was thus no need for scalar access to be represented in Memlets. When re-designing the DaCe-IR and/or when looking at Indexing, we should take a moment to asses what we could do better in terms of how we handle scalars. We should aim for knowing if a scalar is going to be read in a subsequent Tasklet when we build the SDFG.</p> Refactor opportunity: Memlets and <code>node_ctx</code> <p>The <code>StencilComputationSDFGBuilder</code> holds a \"node context\" to keep track of Memlets and where to connect them to/from. When re-designing the DaCe-IR, we should aim for getting that information into the last IR before building SDFGs such that we can just focus on building the SDFG at this point.</p>"},{"location":"technical/backend/dace-bridge/#code-generation-for-tasklets","title":"Code generation for Tasklets","text":"<p>Tasklet code is generated in <code>TaskletCodegen</code>, which is called from <code>StencilComputationSDFGBuilder</code> when visiting Tasklets. It translates DaCe-IR statements back into python code and - more importantly - handles Memlets going into and out of the Tasklet.</p> Refactor opportunity: Indexing (part two) <p>The indexing hacks done when building the DaCe-IR show here again because we now need to handle special cases, e.g for explicit vs. non-explicit indexing.</p> Refactor opportunity: Horizontal regions in Tasklets <p>Even after exposing control flow with this PR, some Tasklets still contain code flow. This comes from two sources: ternary operators (we don't care too much about that for now) and horizontal regions. In the future, we should aim for getting all horizontal regions out of Tasklet code.</p>"},{"location":"technical/backend/dace-bridge/#orchestration","title":"Orchestration","text":"<p>NDSL supercharges DaCe-backends by not only \"daceifying\" GT4Py stencils but also the code in between. This results in one big SDFG that can be analyzed with the powers of DaCe.</p>"},{"location":"technical/backend/dace-bridge/#future-work","title":"Future work","text":"<p>Future work includes leveraging DaCe's schedule tree to adapt the loop order and merge loops along the same axis (possibly with over-computation).</p> <p>We'd also like to look into HW-dependant scheduling and JIT tiling.</p> <ol> <li> <p>https://github.com/GridTools/gt4py/blob/main/src/gt4py/cartesian/gtc/dace/oir_to_dace.py \u21a9</p> </li> <li> <p>https://github.com/GridTools/gt4py/blob/main/src/gt4py/cartesian/backend/dace_backend.py \u21a9</p> </li> <li> <p>https://github.com/GridTools/gt4py/blob/main/src/gt4py/cartesian/gtc/dace/expansion/expansion.py \u21a9</p> </li> <li> <p>https://github.com/GridTools/gt4py/blob/main/src/gt4py/cartesian/gtc/dace/expansion/daceir_builder.py \u21a9</p> </li> <li> <p>https://github.com/GridTools/gt4py/issues/1898 \u21a9</p> </li> <li> <p>https://github.com/GridTools/gt4py/blob/main/src/gt4py/cartesian/gtc/dace/expansion/sdfg_builder.py \u21a9</p> </li> <li> <p>https://github.com/GridTools/gt4py/blob/main/src/gt4py/cartesian/gtc/dace/expansion/tasklet_codegen.py \u21a9</p> </li> </ol>"},{"location":"technical/backend/orchestration/","title":"Orchestration: One Code To Rule Them in The DaCeness Bind Them","text":"<p>\"Orchestration\" refers to the concept of parsing stencil code &amp; pythonc code together into a single <code>dace.program</code>. This system allows for full-context optimization and is the basis of the most performant version of the NDSL delivered code.</p>"},{"location":"technical/backend/orchestration/#orchestrating-code-a-partial-guide-to-a-sea-of-potholes","title":"Orchestrating code: a partial guide to a sea of potholes","text":""},{"location":"technical/backend/orchestration/#the-parser-wants-simple-things","title":"The parser wants simple things","text":"<p>The python parser of DaCe hates dynamicity. No allocations must be done in the runtime code. We supersede a lot of the python actions or guide them to be resolved but there's still a (ongoing) list of failure that could be triggered.</p> <p>Original documentation provides some introduction with very simple examples.</p>"},{"location":"technical/backend/orchestration/#the-list-of-issues","title":"The List of Issues","text":""},{"location":"technical/backend/orchestration/#conditional-code-on-input","title":"Conditional code on input","text":"<p>You shall not use <code>boolean</code> variable to switch between code</p> <pre><code>class Input_Conditional_Function_Call:\n    def __init__(self, stencil_factory: StencilFactory):\n        orchestrate(obj=self, config=stencil_factory.config.dace_config)\n        self._stencil_A = stcil_fctry.from_dims_halo(\n            func=stencil_A,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n        self._stencil_B = stcil_fctry.from_dims_halo(\n            func=stencil_B,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n        self._tmp_field = np.zeros(domain)\n\n    def _internal_computation_no_scalar(self, in_field, out_field):\n        out_field[:] = in_field[:] + 2\n\n    def _internal_computation_scalar(self, in_field, out_field, scalar_field):\n        out_field[:] = in_field[:] + scalar_field[:]\n\n    def __call__(\n        self,\n        in_field: FloatField,\n        out_field: FloatField,\n        cond_flag: bool = False,\n    ):\n        if cond_flag:\n            self._internal_computation_no_scalar(in_field, out_field)\n        else:\n            self._internal_computation_scalar(in_field, out_field, self._tmp_field)\n\nclass Faulty_Code_No_Stencils:\n    def __init__(self, stencil_factory: StencilFactory):\n        orchestrate(obj=self, config=stencil_factory.config.dace_config)\n        self._subclass_build_A = Input_Conditional_Function_Call(stencil_factory)\n        self._subclass_build_B = Input_Conditional_Function_Call(stencil_factory)\n\n    def __call__(self, in_field: FloatField, out_field: FloatField):\n        self._subclass_build_A(in_field, out_field)\n        self._subclass_build_B(in_field, out_field, cond_flag=True)\n\nif __name__ == \"__main__\":\n    domain = (3, 3, 4)\n\n    stcil_fctry, ijk_qty_fctry = get_factories_single_tile_orchestrated(\n        domain[0], domain[1], domain[2], 0, on_cpu=True\n    )\n\n    arr_I = ijk_qty_fctry._numpy.arange(\n        domain[0] * domain[1] * domain[2], dtype=np.float64\n    ).reshape(domain)\n    arr_O = ijk_qty_fctry._numpy.zeros(domain)\n\n    code = Faulty_Code_No_Stencils(stcil_fctry)\n    code(arr_I, arr_O)\n</code></pre> <p>This also fails when you mix in <code>stencils</code>. Issue: https://github.com/NOAA-GFDL/NDSL/issues/146</p>"},{"location":"technical/backend/schedule-tree/","title":"Current state of schedule tree feature","text":"<p>A first version of the schedule tree was merged into GT4Py.  Current work is focusing on (re-) enabling performance optimizations.</p>"},{"location":"technical/backend/schedule-tree/#working-branches","title":"Working branches","text":"<ul> <li>NDSL (merged into <code>develop</code>)<ul> <li>For Milestone 2 work, use nasa/milestone2 which contains experimental frontend features</li> </ul> </li> <li>GT4Py (merged into <code>main</code>)<ul> <li>DaCe version for cartesian follows <code>romanc/stree-to-sdfg</code> on the GridTool's fork</li> </ul> </li> <li> <p>DaCe branch <code>romanc/stree-to-sdfg</code> on the GridTool's fork</p> <p>The DaCe branch originally branched off from <code>v1/maintenance</code> (in SPCL/DaCe) and includes Tal's work from the branch <code>stree-to-sdfg</code>. For a quick overview of the changes, look at</p> <p>https://github.com/spcl/dace/compare/v1/maintenance...romanc:romanc/stree-to-sdfg</p> </li> </ul>"},{"location":"technical/backend/schedule-tree/#optimization-laundry-list","title":"Optimization laundry list","text":"<p>We have a long laundry list of planned optimizations that we either just got possible due to the schedule tree representation or that we need to re-add after the first feature branch merged.</p>"},{"location":"technical/backend/schedule-tree/#workflow","title":"Workflow","text":"<p>The (internal) NDSL / GT4Py workflow of the schedule tree feature is depicted (in detail) in the following diagram.</p> <p></p>"},{"location":"technical/backend/schedule-tree/#oir-to-schedule-tree","title":"OIR to schedule tree","text":"<p>OIR to schedule tree goes via a \"Tree IR\". The tree IR is just here to facilitate building the schedule tree. For now, we don't do any transformation on the tree IR.</p> <pre><code>flowchart LR\noir[\"\n    OIR\n    (GT4Py)\n\"]\ntreeir[\"Tree IR\"]\nstree[\"Schedule tree\"]\n\noir --&gt; treeir --&gt; stree</code></pre> <p>OIR to tree IR conversion has two visitors in separate files:</p> <ol> <li><code>oir_to_treeir</code> transpiles control flow</li> <li><code>oir_to_tasklet</code> transpiles computations (i.e. bodies of control flow elements) into tasklets</li> </ol> <p>While this incurs a bit of code duplications (e.g. for resolving indices), allows for separation of concerns. Everything that is related to the schedule is handled in <code>oir_to_treeir</code>. Note, for example, that we keep the distinction between horizontal mask and general <code>if</code> statements. This distinction is kept because horizontal regions might influence scheduling decisions.</p> <p>The conversion from tree IR to schedule tree is then a straight forward lowering.</p>"},{"location":"technical/backend/schedule-tree/#schedule-tree-to-sdfg","title":"Schedule tree to SDFG","text":"<p>In big terms, schedule tree to SDFG conversion has the following steps:</p> <ol> <li>Setup a new SDFG and initialize it's descriptor repository from the schedule tree.</li> <li>Insert (artificial) state boundary nodes in the schedule tree:<ul> <li>Insert state boundary nodes before control flow nodes and state labels.</li> <li>Insert memory dependency state boundaries (e.g. potential data races)</li> <li>Insert a state boundary after inter-state assignment nodes<sup>1</sup>.</li> <li>Insert state boundary before maps containing a nested SDFG<sup>2</sup>.</li> </ul> </li> <li>Visitor on the schedule tree, translating every node into the new SDFG, see class <code>StreeToSDFG</code>.</li> <li>Memlet propagation through the newly crated SDFG.</li> <li>Run <code>simplify()</code> on the newly created SDFG (optional).</li> </ol>"},{"location":"technical/backend/schedule-tree/#hacks-and-shortcuts","title":"Hacks and shortcuts","text":"<ul> <li><code>StreeToSDFG</code> has many visitors raising a <code>NonImplementedError</code>. I've implemented these visitors on an as-needed basis.</li> <li>I've added additional state boundaries around nested SDFGs (needed for state changes, e.g. <code>IfScope</code>, inside <code>MapNodes</code>) to force correct execution order.</li> <li>I've added additional state boundaries after inter-state assigns to ensure the symbols are defined before they are accessed. As far as I understand, that shouldn't be necessary. However, I've had SDFGs (todo: which ones?) with unused assigns at the end of the main visitor.</li> <li>I've written tests for some things as a way of developing the main visitor. For simple schedule trees, I've already added checks on the resulting SDFG, but pretty fast I ended up validating by \"looking at the resulting SDFG\".</li> </ul> <ol> <li> <p>as far as I understand <code>_insert_memory_dependency_state_boundaries</code>, this shouldn't be necessary. Might be related to extra state boundaries for nested SDFGs.\u00a0\u21a9</p> </li> <li> <p>Nested SDFGs are added when multiple states are needed inside a map.\u00a0\u21a9</p> </li> </ol>"},{"location":"technical/backend/ADRs/","title":"Architecture Decision Records","text":"<p>Architecture Decision Records (ADRs) are a form of tech documentation specializing in storing decisions behind why a feature is built the way it is (and not in any other). They're supposed to capture the trade-offs and the reasoning at the time (or before) feature development.</p> <p>Use the _template as a starting point.</p>"},{"location":"technical/backend/ADRs/#schedule-tree","title":"Schedule tree","text":"<ul> <li>Schedule trees</li> <li>Schedule tree - DaCe version</li> <li>Schedule tree - NDSL integration</li> </ul>"},{"location":"technical/backend/ADRs/_template/","title":"Title, e.g. name of the feature","text":"<p>Why-statement: In the context of [use case/user story], facing [concern], we decided to [do thing X] to achieve [system qualities/desired consequences]. We considered [thing Y] and accept [downsides / undesired consequences].</p>"},{"location":"technical/backend/ADRs/_template/#context","title":"Context","text":"<p>What is motivating this decision or change? Describe the context and problem statement, in free form.</p> <p>You might want to add a list of drivers, forces, concerns</p> <ul> <li>[driver 1, e.g., a force, facing concern, ...]</li> <li>[driver 2, e.g., a force, facing concern, ...]</li> </ul>"},{"location":"technical/backend/ADRs/_template/#decision","title":"Decision","text":"<p>What is the change that we're proposing and/or doing?</p> <p>We chose option X because [justification. e.g., only option, which meets k.o. criterion decision driver | which resolves force force | ... | comes out best (see below)].</p>"},{"location":"technical/backend/ADRs/_template/#consequences","title":"Consequences","text":"<p>What it now easier to do? What becomes more difficult with this change?</p> <p>Describe the positive (e.g., improvement of quality attribute satisfaction, follow-up decisions required, ...) as well as the negative (e.g., compromising quality attribute, follow-up decisions required, ...) outcomes of this decision.</p>"},{"location":"technical/backend/ADRs/_template/#alternatives-considered","title":"Alternatives considered","text":""},{"location":"technical/backend/ADRs/_template/#alternative-1","title":"Alternative 1","text":"<p>example | description | pointer to more information</p> <ul> <li>Good, because ...</li> <li>Bad, because ...</li> <li>...</li> </ul>"},{"location":"technical/backend/ADRs/_template/#alternative-2","title":"Alternative 2","text":"<p>example | description | pointer to more information</p> <ul> <li>Good, because ...</li> <li>Bad, because ...</li> <li>...</li> </ul>"},{"location":"technical/backend/ADRs/_template/#references","title":"References","text":"<p>If it helps, add references e.g. to issues and/or other planning documents.</p>"},{"location":"technical/backend/ADRs/stree/","title":"Schedule tree","text":"<p>In the context of the gt4py/dace backend, facing under performing map- &amp; state fusion, we decided to introduce schedule trees to achieve hardware dependent macro-level optimizations (e.g. loop merging and loop re-ordering). We considered writing custom fusion passes based on SDFG and accept the additional (maintenance &amp; codegen) overhead of converting from SDFG to schedule trees and back (for codegen from SDFG).</p>"},{"location":"technical/backend/ADRs/stree/#context","title":"Context","text":"<p>While there are map &amp; state fusion passes for SDFGs, they under-perform our expectations. Schedule Trees were thus drafted as an alternative representation to allow such high-level optimizations. Specifically, for NDSL, we are interested in two high-level optimizations</p> <ol> <li>Flip the iteration order from I-J-K to K-I-J, pushing the K-loop as far out as possible to gain cache locality on CPU. Note that this transformation should be optional to allow optimal iteration order based on the target hardware (CPU or GPU).</li> <li>Map merge on SDFGs currently fails for the most basic examples. Especially on GPUs, we'd like to merge as many maps as possible to cut down on the (currently excessive) amount of kernel launches.</li> <li>If possible, look at force-merging K-loops/maps inserting if statements (as guards) as needed (over.computation) to further cut down on kernel launches on the GPU.</li> </ol> <p>NDSL issue: https://github.com/GEOS-ESM/NDSL/issues/6</p>"},{"location":"technical/backend/ADRs/stree/#decision","title":"Decision","text":"<p>We chose to write macro-level optimizations (e.g. loop re-reordering, (forced) map merges) in the schedule tree representation.</p>"},{"location":"technical/backend/ADRs/stree/#consequences","title":"Consequences","text":"<p>With the schedule tree representation, writing potent map fusion and loop re-ordering passes will be easier than in the SDFG representation.</p> <p>We will need to write and maintain the back transformation from schedule tree to SDFG.</p>"},{"location":"technical/backend/ADRs/stree/#alternatives-considered","title":"Alternatives considered","text":""},{"location":"technical/backend/ADRs/stree/#improve-the-existing-map-fusion-pass","title":"Improve the existing map fusion pass","text":"<p>Philip M\u00fcller has done this work (for gt4py-next) and an improved version is merged in the unreleased mainline version of DaCe.</p> <p>We think we'll need a custom map fusion pass that let's us defined in which cases over-computation is desirable. A general map fusion pass will never allow this.</p>"},{"location":"technical/backend/ADRs/stree/#write-custom-map-fusion-based-on-sdfg-syntax","title":"Write custom map fusion based on SDFG syntax","text":"<p>Possible, but a lot more cumbersome than writing the same transformation based on the schedule tree syntax.</p>"},{"location":"technical/backend/ADRs/stree/#codegen-from-schedule-tree","title":"Codegen from schedule tree","text":"<p>While it is theoretically possible to generate code directly from Schedule Trees, we would loose the possibility to run (existing) optimization passes after loop transformations and map fusion, which could unlock things like vectorization. In addition, current AI research is based on the SDFG representation.</p>"},{"location":"technical/backend/ADRs/stree_dace-version/","title":"Schedule tree - DaCe version","text":"<p>In the context of schedule trees, facing time pressure and spill-over from Milestone 1, we decided to write the back transformation from schedule trees to SDFGs against the <code>v1/maintenance</code> branch of DaCe to minify up-front cost and deliver CPU performance as part of Milestone 2. We considered updating to the mainline version of DaCe and accept follow-up cost to rewrite part of the transformation once DaCe v2 releases.</p>"},{"location":"technical/backend/ADRs/stree_dace-version/#context","title":"Context","text":"<p>Milestone 1 didn't exactly turn out as we hoped and we were left we a bunch of tasks spilling over into Milestone 2. At the end of this milestone, we'd like to have comparable performance numbers on CPU runs.</p> <p>We blame much of the slowness of the current CPU version on macro-level optimizations that were hard-coded into the FORTRAN codebase, e.g. pushing the k-loop all the way out to the border of <code>D_SW</code>. To solve these performance challenges, we rely on the schedule tree representation to do that work automatically as part of a transformation in DaCe-land. This requires building the transformation back from schedule tress to SDFGs. DaCe is moving fast with breaking changes on <code>main</code> compared to the released <code>v1.x</code> versions. We thus had to answer the question if we should update to mainline DaCe first or build a first version against <code>v1.x</code>.</p>"},{"location":"technical/backend/ADRs/stree_dace-version/#decision","title":"Decision","text":"<p>We chose to build a first version of the schedule tree to SDFG back-transformation against the <code>v1.x</code> version of DaCe.</p>"},{"location":"technical/backend/ADRs/stree_dace-version/#consequences","title":"Consequences","text":"<ul> <li>We'll be able to code against a familiar API (same as the gt4py/dace bridge) and thus hope to get results faster.</li> <li>We won't be able to merge into <code>v1.x</code>.</li> </ul>"},{"location":"technical/backend/ADRs/stree_dace-version/#alternatives-considered","title":"Alternatives considered","text":""},{"location":"technical/backend/ADRs/stree_dace-version/#update-to-dace-mainline-first","title":"Update to DaCe mainline first","text":"<ul> <li>Good because mainline DaCe is accepting new features while <code>v1.x</code> is closed for new feature development.</li> <li>Bad because it incurs an up-front cost (we'd need to update the gt4py/dace bridge) and we are trying to minimize up-front cost to get results fast.</li> <li>Bad because we aren't trained to use the new control flow graphs (CFG).</li> <li>Bad because we heard that DaCe mainline isn't stable at the moment.</li> </ul>"},{"location":"technical/backend/ADRs/stree_dace-version/#references","title":"References","text":"<ul> <li>Why we chose schedule tree in the first place</li> </ul>"},{"location":"technical/backend/ADRs/stree_ndsl-integration/","title":"Schedule tree - NDSL integration","text":"<p>In the context of schedule trees, facing uncertainty of future usage, we decided to integrate schedule trees at the NDSL-level to facilitate writing GEOS-specific optimizations. We considered adding schedule trees at the GT4Py-level (as part of the DaCe backend) and accept that we have to revisit the question of where to integrate in the future.</p>"},{"location":"technical/backend/ADRs/stree_ndsl-integration/#context","title":"Context","text":"<p>Given first schedule tree passes from earlier experiments and a rudimentary back transformation from schedule trees to SDFG, questions popped up at which level to integrate schedule tress in the pipeline. Should this be an NDSL feature? Should it be an option in the dace bridge of GT4Py? How will pushing the k-loop outwards relate to the GT4Py feature of setting an \"expansion order\"?</p>"},{"location":"technical/backend/ADRs/stree_ndsl-integration/#decision","title":"Decision","text":"<p>We chose to integrate at the NDSL level to simplify writing GEOS-specific schedule tree passes and avoid having to write a pass registry in the DaCe backend of GT4Py.</p>"},{"location":"technical/backend/ADRs/stree_ndsl-integration/#consequences","title":"Consequences","text":"<ul> <li>No schedule tree optimizations for non-orchestrated code.</li> <li>No decision on how schedule tree optimizations will fit in the bigger picture (in DaCe as well as in GT4Py)</li> <li>Reduced start-up overhead and a lot of flexibility for Milestone 2.</li> <li>Given the results of Milestone 2, we'll be able to re-evaluate the questions above. Positive results lead the way to productize this experimental feature.</li> </ul>"},{"location":"technical/backend/ADRs/stree_ndsl-integration/#alternatives-considered","title":"Alternatives considered","text":""},{"location":"technical/backend/ADRs/stree_ndsl-integration/#integration-into-gt4py","title":"Integration into GT4Py","text":"<p>Most likely, the feature will move down into the DaCe backend of GT4Py in the future.</p> <ul> <li>Good: Allows schedule tree passes for orchestrated and non-orchestrated code.</li> <li>Good: Brings the power of schedule tree optimizations to the whole GT4Py community.</li> <li>Currently bad because it means building a system to register custom passes and opt in/out of default stree optimizations (assuming there'll be some).</li> <li>Currently bad because it raises questions about overlapping features, e.g. expansion specification and tiling.</li> </ul>"},{"location":"technical/backend/ADRs/stree_ndsl-integration/#references","title":"References","text":"<ul> <li>Why we chose schedule tree in the first place</li> </ul>"},{"location":"technical/backend/repositories/dace/","title":"DaCe development","text":"<p>Docs | README | Contribution guidelines</p>"},{"location":"technical/backend/repositories/dace/#notes-quirks","title":"Notes &amp; quirks","text":"<ul> <li>Install the VSCode extension</li> <li>You can call <code>sdfg.view()</code> from the debugger to look at any (intermediate) SDFG with the VSCode plugin</li> <li>DaCe only enforces automatic formatting on the <code>main</code> branch. If you are working on <code>v1/maintenance</code>, you might see spurious formatting changes in your PRs (see Discussion and this PR).</li> </ul>"},{"location":"technical/backend/repositories/dace/#community","title":"Community","text":"<ul> <li>Weekly community meeting to discuss new features / big changes</li> <li>Developers share a Mattermost instance</li> </ul>"},{"location":"technical/backend/repositories/gt4py/","title":"GT4Py development","text":"<p>Docs | README | Contributing | Coding guidelines</p>"},{"location":"technical/backend/repositories/gt4py/#up-and-running","title":"Up and running","text":"<p>Getting started: Run</p> <pre><code>uv sync --extra cartesian --group dace-cartesian\n</code></pre> <p>This installs a development environment (containing things like tests and pre-commit hooks) with the cartesian version of DaCe. Add <code>--extra cuda12</code> at the end for GPU support.</p>"},{"location":"technical/backend/repositories/gt4py/#notes-quirks","title":"Notes &amp; quirks","text":"<ul> <li>GT4Py cartesian and next live in the same repository. Both share the <code>eve</code> framework, <code>_core</code> definitions, and the test system.</li> <li>GT4Py cartesian uses a DaCe version based on <code>v1/maintenance</code>. Install the extra <code>dace-cartesian</code> to work with that version (see above).</li> <li>GT4Py next uses a DaCe version based on the <code>main</code> branch. This version is kept in the extra <code>dace-next</code>.</li> <li>To run cartesian tests that require DaCe (e.g. for bridge work):</li> </ul> <pre><code>nox -s \"test_cartesian-3.10(dace,cpu)\"`\n</code></pre> <ul> <li>Running tests with <code>nox</code> will use the local gt4py code, but install a clean environment.</li> <li>Commenting <code>cscs-ci run</code> allows to re-run CSCS-CI on PRs.</li> <li>To update the DaCe branch in the <code>uv.lock</code> file:</li> </ul> <pre><code>uv sync -P dace --extra cartesian --group dace-cartesian --extra cuda12\n</code></pre>"},{"location":"technical/backend/repositories/gt4py/#community","title":"Community","text":"<ul> <li>Monthly community meeting (shared between cartesian and next)</li> <li>Developers share a Slack channel</li> </ul>"},{"location":"technical/backend/repositories/ndsl/","title":"NDSL","text":"<p>README</p>"},{"location":"technical/backend/repositories/ndsl/#usage","title":"Usage","text":"<p>NDSL is used as backbone of pace, pyFV3, and pySHiELD.</p>"},{"location":"technical/backend/repositories/ndsl/#notes-quirks","title":"Notes &amp; quirks","text":"<ul> <li>NDSL has GT4Py and DaCe as submodules, which allows to easily debug and step through changed code in all three repos.</li> </ul>"},{"location":"technical/backend/repositories/ndsl/#community","title":"Community","text":"<ul> <li>Monthly community meetings</li> <li>Developers share a Mattermost instance</li> </ul>"},{"location":"technical/dev-setup/","title":"Development environment","text":"<p>This part of the documentation helps DSL developers to setup their environment. We collect handy VSCode extensions and use it as a central place to define the dev tech stack.</p> <p>As a reminder, DSL users are advised to stay with released versions of NDSL unless they absolutely need one of the experimental features.</p>"},{"location":"technical/dev-setup/tech-stack/","title":"Developer stack","text":"<p>Note</p> <p>NDSL users are advised to stick with released versions: https://github.com/NOAA-GFDL/NDSL/releases/latest</p> <ul> <li>NDSL   Follow branch <code>develop</code> in main repo.</li> <li>GT4Py   Follow branch <code>physics</code> on Stefano's fork, which includes experimental features as listed in this table.</li> <li>DaCe   default one, as configured in by NDSL</li> <li>Serialbox     Follow brach <code>feature/data_ijkbuff</code> on Florian's fork, which includes the following features:<ul> <li><code>data_buffered</code> keyword to allow buffer serialization (scalar by scalar) of Fields</li> <li><code>data_writeonly</code> keyword to allow <code>real, parameter :: X</code> style constants to be saved by removing the <code>read</code> capacity</li> <li><code>data_append</code> keyword to write scalars in a 1 dimensional field</li> <li><code>flush savepoint_name</code> to dump all data in savepoint irrespective or either or not the buffer is filled up</li> </ul> </li> </ul>"},{"location":"technical/dev-setup/vscode/","title":"VSCode Configuration","text":"<p>VSCode has many configuration options and an active plugin ecosystem. Editor configuration (as well as the editor itself) is a user choice and we respect this. This guide thus a a collection of useful snippets, extensions, and debug launch configurations, which we think are worth sharing with the team.</p>"},{"location":"technical/dev-setup/vscode/#extensions","title":"Extensions","text":"<p>A plethora of extensions are available for VSCode. Most of them target streamlining workflows, which can be a huge time-saver. We found the following to be useful (in no particular order)</p> <ul> <li>Python (language support including <code>pylance</code> &amp; debugger) / Black Formatter</li> <li>Modern Fortran (without the fortls engine or else the extension dies trying to figure out GEOS)</li> <li>H5Web for <code>netcdf</code> inline viewing</li> <li>DaCe SDFG Editor (in case you work with DaCe graphs)</li> <li>your standard set of <code>git</code> extensions<ul> <li>GitLens (in-code <code>git blame</code>)</li> <li>Git Graph (clean git graphs)</li> </ul> </li> <li>Live Share (remote pair-programming)</li> <li>Draw.io Integration (draw &amp; share graphs directly from within VSCode - we've seen scaling errors when mixed with graphs created from the website)</li> <li>Mermaid support for Markdown preview</li> <li>Footnotes support for Markdown preview</li> </ul>"},{"location":"technical/dev-setup/vscode/#format-on-save","title":"Format on save","text":"<p>While <code>pre-commit</code> is the source of truth, having format on save support in the editor can be a huge time-saver. To enable format on save</p> <ol> <li>Install the \"Black Formatter\" extension (see above)</li> <li>Configure \"Black Formatter\" as the default formatter for python files and enable format on save. In <code>.vscode/settings.json</code> add</li> </ol> <pre><code>{\n    \"[python]\": {\n        \"editor.defaultFormatter\": \"ms-python.black-formatter\",\n        \"editor.formatOnSave\": true\n    },\n}\n</code></pre>"},{"location":"technical/dev-setup/vscode/#run-pytests-in-parallel","title":"Run pytests in parallel","text":"<p><code>pytest</code> is the de-facto standard for testing in the python stack. VSCode has out-of-the-box support for <code>pytest</code>. To speed up test runs, you can run tests in parallel. <code>--numprocesses=auto</code> will pick a sensible default. Read more here.</p> <pre><code>{\n    \"python.testing.pytestEnabled\": true,\n    \"python.testing.pytestArgs\": [\n        \"--numprocesses=auto\",\n        \"tests\"\n    ],\n    \"python.testing.unittestEnabled\": false,\n}\n</code></pre>"},{"location":"technical/dev-setup/vscode/#debugging","title":"Debugging","text":"<p>In VSCode, debugging tasks can be configured with so called \u201claunch configurations\u201d, that live in <code>launch.json</code> files. Sharing these here will help the team debug faster.</p>"},{"location":"technical/dev-setup/vscode/#translate-tests","title":"Translate tests","text":"<p>Warning</p> <p>Blindly copy/pasting the snippet below will not work because of hard-coded paths in the config. We should clean this up and/or explain them in the snippet.</p> <pre><code>{\n    \"name\": \"Translate - pyMoist\",\n    \"type\": \"debugpy\",\n    \"request\": \"launch\",\n    \"module\": \"pytest\",\n    \"args\": [\n        \"-s\",\n        \"-v\",\n        \"-x\",\n        \"--data_path=/home/mad/work/fp/geos/src/Components/@GEOSgcm_GridComp/GEOSagcm_GridComp/GEOSphysics_GridComp/GEOSmoist_GridComp/pyMoist/test_data/geos_11.5.2/moist\",\n        \"--grid=default\",\n        \"--backend=numpy\",\n        \"--which_modules=evap_subl_pdf\",\n        \"/home/mad/work/fp/geos/src/Components/@GEOSgcm_GridComp/GEOSagcm_GridComp/GEOSphysics_GridComp/GEOSmoist_GridComp/pyMoist/tests\"\n    ],\n    \"env\": {\n        \"PACE_TEST_N_THRESHOLD_SAMPLES\": \"0\",\n        \"PACE_FLOAT_PRECISION\": \"32\"\n    }\n}\n</code></pre>"},{"location":"technical/frontend/","title":"Technical frontend documentation","text":"<p>This part of the docs includes</p> <ul> <li>a list of what NDSL features compared to using plain GT4Py</li> <li>and a list of experimental features, including their support in various backends.</li> </ul>"},{"location":"technical/frontend/experimental_features/","title":"Experimental \"Physics\" features","text":"<p>\u26a0\ufe0f This should live in NDSL or GT4Py or DaCe own documentation \u26a0\ufe0f</p>"},{"location":"technical/frontend/experimental_features/#summary","title":"Summary","text":"<p>Experimental work drops support for <code>gt</code> backends for the foreseeable future to allow for quicker iteration</p> Feature debug numpy dace:cpu dace:gpu test / example Absolute indexing in K \u2705 \u2705\ud83d\udc1e \u2705 \u2705 link Parametrizable precision \u2705 \u2705 \u2705 \u2705 Generic cast to precision ROUND function \u2705 \u2705 \u2705 \u2705 ERF function \u2705 \u2705 \u2705 \u2705 Type hinting of temporaries \u2705\ud83d\udc1e \u2705\ud83d\udc1e \u2705\ud83d\udc1e \u2705\ud83d\udc1e Variable indexing of data dimensions \u2705 \u2753 \u2705 \u2705 Exposing current K level as a scalar \u2705\ud83d\udc1e \u2705 \u2705 \u2705 Unrolling for-range loop \u2753 \u2705 \u2753 \u2753 Mutable arguments on gtscript.function \u2753 \u2705 \u2753 \u2753 Breakpoint injection Print 2D temporaries Runtime Interval Higher dim temporaries Computation mask Nested K interval/loop Field save to NetCDF Code-flow heatmap"},{"location":"technical/frontend/experimental_features/#details","title":"Details","text":""},{"location":"technical/frontend/experimental_features/#absolute-indexing-in-k","title":"Absolute indexing in K","text":"<ul> <li>Usage: <code>field.at(K=x, ddim=[y])</code> with <code>ddim</code> optional</li> <li>Todo:<ul> <li><code>numpy</code> doesn't handle data dimensions</li> <li>Unit tests for data dimensions feature</li> </ul> </li> <li>Merge to <code>main</code>: BLOCKED<ul> <li>Impossible in <code>gt:X</code> backends without changes to GridTools</li> </ul> </li> </ul>"},{"location":"technical/frontend/experimental_features/#parametrizable-precision","title":"Parametrizable precision","text":"<ul> <li>Usage: <code>literal_floating_point_precision</code> in <code>gt4py.cartesian.config.build_settings</code> OR <code>GT4PY_LITERAL_PRECISION</code> environment variable</li> <li>Todo: Unit test</li> <li>Ready for merge in <code>main</code></li> </ul>"},{"location":"technical/frontend/experimental_features/#generic-cast-to-precision","title":"Generic cast to precision","text":"<ul> <li>Usage: <code>a = int(b)</code> with types <code>i32</code>, <code>i64</code>, <code>f32</code>, <code>f64</code>, <code>int</code>, <code>float</code></li> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#round-erf-functions","title":"ROUND &amp; ERF functions","text":"<ul> <li>Merge to <code>main</code>: READY</li> </ul>"},{"location":"technical/frontend/experimental_features/#type-hinting-of-temporaries","title":"Type hinting of temporaries","text":"<ul> <li>Usage: <code>field: i32 = 0</code> with types <code>i32</code>, <code>i64</code>, <code>f32</code>, <code>f64</code></li> <li>ToDo:<ul> <li>missing generic <code>int</code>, <code>float</code></li> <li>unit tests</li> </ul> </li> <li>Merge to <code>main</code>: READY</li> </ul>"},{"location":"technical/frontend/experimental_features/#variable-indexing-of-data-dimensions","title":"Variable indexing of data dimensions","text":"<ul> <li>Usage: <code>field[0,0,0][x]</code></li> <li>ToDo:<ul> <li>Fix unit tests</li> <li><code>numpy</code> might not be working</li> </ul> </li> <li>Merge to <code>main</code>: READY</li> </ul>"},{"location":"technical/frontend/experimental_features/#exposing-current-k-level-as-scalar","title":"Exposing current K level as scalar","text":"<ul> <li>Usage: <code>THIS_K</code> as an <code>int</code></li> <li>ToDo:<ul> <li>Do not default to parametrized precision</li> </ul> </li> <li>Merge to <code>main</code>: BLOCKED (partial)<ul> <li>Merge after parametrizable precision</li> </ul> </li> </ul>"},{"location":"technical/frontend/experimental_features/#unrolling-for-range-loop","title":"Unrolling for-range loop","text":"<ul> <li>Usage: <code>for i in range(x)</code> all operations will be unrolled</li> <li>ToDo: TBD</li> <li>Merge to <code>main</code>: TBD</li> </ul>"},{"location":"technical/frontend/experimental_features/#mutable-arguments-on-gtscriptfunction","title":"Mutable arguments on gtscript.function","text":"<ul> <li>Usage: functions with no return statements have mutable arguments</li> <li>ToDo: TBD</li> <li>Merge to <code>main</code>: TBD</li> </ul>"},{"location":"technical/frontend/experimental_features/#breakpoint-injection","title":"Breakpoint injection","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#print","title":"Print","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#2d-temporaries","title":"2D temporaries","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#runtime-interval","title":"Runtime Interval","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#higher-dim-temporaries","title":"Higher dim temporaries","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#computation-mask","title":"Computation mask","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#nested-k-intervalloop","title":"Nested K interval/loop","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#field-save-to-netcdf","title":"Field save to NetCDF","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/experimental_features/#code-flow-heatmap","title":"Code-flow heatmap","text":"<ul> <li>TO BE IMPLEMENTED</li> </ul>"},{"location":"technical/frontend/ndsl_features/","title":"NDSL features","text":"<p>List of features that NDSL brings on top of GT4Py:</p> <ol> <li>Stencil- and Quantity-Factories</li> <li>Orchestration</li> </ol>"},{"location":"technical/frontend/ndsl_features/#tips-and-tricks","title":"Tips and tricks","text":"<p>The not so obvious stuff.</p> Experimental features <p>See Experimental \"Physics\" features for a list of experimental features, which might or might not make it to mainline in the future.</p> <p>Stencil factory with different K profile</p> <p>To generate a new sterncil factory from an existing one but with a different K profile (start and size), run</p> <pre><code>    new_factory = existing_factory.restrict_vertical(k_start=1)\n</code></pre>"},{"location":"technical/frontend/ADRs/","title":"Architecture Decision Records","text":"<p>Architecture Decision Records (ADRs) are a form of tech documentation specializing in storing decisions behind why a feature is built the way it is (and not in any other). They're supposed to capture the trade-offs and the reasoning at the time (or before) feature development.</p> <p>Use the _template as a starting point.</p> <p>Summary:</p> <ul> <li>Fields Bundle: allow named indexation, filtering and grouping for a semantically logical group of Fields</li> </ul>"},{"location":"technical/frontend/ADRs/fields_bundle/","title":"Fields Bundle","text":"<p>To allow semantic manipulation of a group of fields, we propose to implement a base class <code>FieldBundle</code> which will provide API to name, group, filter and deliver semantically grouped fields on top of a contiguous 4D memory representation. We considered using Python's dictionary but it won't fit the stencil-execution pattern, so we kept the underlying 4D and propose to build metadata and indexation on top.</p>"},{"location":"technical/frontend/ADRs/fields_bundle/#context","title":"Context","text":"<p>Throughout ESMs fields are semantically bundled together and transported on cartesian grid as 4D vectors. For example, Tracers have \"water species\", \"aerosols\", etc. In Fortran, the general mode of execution is:</p> <ul> <li>Define a 4D field with IJK + 4th dimension</li> <li>Use index to the last dimension as semantically relevant information (0 is \"vapor\", `1 is \"ice\")</li> </ul> <p>This allows a few manipulation we have to replicate:</p> <ul> <li>Blind iteration over all fields as 3D fields (loop over N fields with N size of 4th dimension)</li> <li>Direct access to a particular field semantically relevant</li> <li>Filtering on a subset of 3D fields (loop over N+x to N-y with x/y as relevant offsets)</li> </ul> <p>Pros:</p> <ul> <li>Single memory block to be moved around</li> <li>Clear 4th dimension usage</li> <li>Cache friendliness if the group/subgroups remain contiguous</li> </ul> <p>Cons:</p> <ul> <li>Code readability: indices or offset are difficult to read and pre-suppose to remember knowing correspondence</li> </ul> <p>Another aspect of those code is the re-organization of 3D fields within a 4D sequence either for scientific use (sort the interesting tracers so they are next to each other and offsetted loop can be used) or performance (reduce cache miss). Those operations are difficult to track in a codebase and easily forgotten in a methodology that often see the lower algorithmics (parameterization for example) and it's use in the larger model (driver) as separated tasks.</p> <p>Our proposition should aim at covering all use case, retain pros, improved on cons and allow advanced to tooling to detect memory manipulation (and/or forbid them).</p>"},{"location":"technical/frontend/ADRs/fields_bundle/#decision","title":"Decision","text":"<p>We propose to implement a base class <code>FieldBundle</code> with two main components:</p> <ul> <li>a 4D device-sensitive memory space</li> <li>a complex 4th dimensional <code>indexer</code>, carrying metadata (names, groups)</li> </ul> <p>The <code>indexer</code> operates on the memory and should have the following features:</p> <ul> <li>Access by name to a single 3D field (e.g. <code>bundle[\"vapor\"]</code> or <code>bundle.vapor</code>)</li> <li>Filtering by groups to access a subset of the bundle (e.g. <code>bundle.groupby(\"water species\")</code>)</li> <li>Sub-filtering a groups to access a subset of a given group (e.g. <code>bundle.groupby(\"water species\").exclude([\"rain\", \"ice\"])</code>)</li> <li>Blind access to a 4D gt4py-capable field (e.g. <code>bundle</code> of type <code>FloatField</code> + Data Dimension)</li> </ul> <p>The results will have to be <code>orchestratable</code> natively and allow for a quick and transparent access to 3D field as a <code>Quantity</code>.</p> <p>Once the first iteration of this code is available, we shall endeavor how we can refactor <code>pyFV3</code>'s <code>State</code> concept which has overlapping features.</p>"},{"location":"technical/frontend/ADRs/fields_bundle/#tooling-features","title":"Tooling / Features","text":"<ul> <li>Ability to dump all fields in a <code>xarray.Dataset</code> with options for grouping, single field save, etc.</li> </ul>"},{"location":"technical/frontend/ADRs/fields_bundle/#consequences","title":"Consequences","text":"<p>This will define a base class to be derived from. It will be implemented with pyFV3 (dynamics) and pySHiELD (physics) as workhorse. That strategy might narrow the field of design and miss important APIs but it seems the pragmatic angle to ensure we do not over-engineer.</p>"},{"location":"technical/frontend/ADRs/fields_bundle/#alternatives-considered","title":"Alternatives considered","text":"<p>N/A</p>"},{"location":"technical/frontend/ADRs/fields_bundle/#references","title":"References","text":"<p>N/A</p>"},{"location":"technical/porting/translate_test/","title":"Translate test","text":"<p>\u26a0\ufe0f This is a copy-paste of the older <code>pyFV3</code> documentation. It is out-of-date but concepts remain the same \u26a0\ufe0f</p>"},{"location":"technical/porting/translate_test/#writing-tests","title":"Writing tests","text":"<p>Generation of regression data occurs in the fv3gfs-fortran repo (https://github.com/VulcanClimateModeling/fv3gfs-fortran) with serialization statements and a build procedure defined in <code>tests/serialized_test_data_generation</code>. The version of data this repo currently tests against is defined in <code>FORTRAN_SERIALIZED_DATA_VERSION</code> in this repo's <code>docker/Makefile.image_names</code>. Fields serialized are defined in Fortran code with serialization comment statements such as:</p> <pre><code>    !$ser savepoint C_SW-In\n    !$ser data delpcd=delpc delpd=delp ptcd=ptc\n</code></pre> <p>where the name being assigned is the name the fv3core uses to identify the variable in the test code. When this name is not equal to the name of the variable, this was usually done to avoid conflicts with other parts of the code where the same name is used to reference a differently sized field.</p> <p>The majority of the logic for translating from data serialized from Fortran to something that can be used by Python, and the comparison of the results, is encompassed by the main Translate class in the tests/savepoint/translate/translate.py file. Any units not involving a halo update can be run using this framework, while those that need to be run in parallel can look to the ParallelTranslate class as the parent class in tests/savepoint/translate/parallel_translate.py. These parent classes provide generally useful operations for translating serialized data between Fortran and Python specifications, and for applying regression tests.</p> <p>A new unit test can be defined as a new child class of one of these, with a naming convention of <code>Translate&lt;Savepoint Name&gt;</code> where <code>Savepoint Name</code> is the name used in the serialization statements in the Fortran code, without the <code>-In</code> and <code>-Out</code> part of the name. A translate class can usually be minimally specify the input and output fields. Then, in cases where the parent compute function is insufficient to handle the complexity of either the data translation or the compute function, the appropriate methods can be overridden.</p> <p>For Translate objects</p> <ul> <li>The init function establishes the assumed translation setup for the class, which can be dynamically overridden as needed.</li> <li>The parent compute function:<ul> <li>makes gt4py storages of the max shape (grid.npx+1, grid.npy+1, grid.npz+1) aligning the data based on the start indices specified. (gt4py requires data fields have the same shape, so in this model we have buffer points so all calculations can be done easily without worrying about shape matching).</li> <li>runs the compute function (defined in self.compute_func) on the input data storages</li> <li>slices the computed Python fields to be compared to fortran regression data</li> </ul> </li> <li>The unit test then uses a modified relative error metric to determine whether the unit passes</li> <li>The init method for a Translate class:<ul> <li>The input (self.in_vars[\"data_vars\"]) and output (self.out_vars) variables are specified in dictionaries, where the keys are the name of the variable used in the model and the values are dictionaries specifying metadata for translation of serialized data to gt4py storages. The metadata that can be specified to override defaults are:</li> <li>Indices to line up data arrays into gt4py storages (which all get created as the max possible size needed by all operations, for simplicity): \"istart\", \"iend\", \"jstart\", \"jend\", \"kstart\", \"kend\". These should be set using the 'grid' object available to the Translate object, using equivalent index names as in the declaration of variables in the Fortran code, e.g. real:: cx(bd%is:bd%ie+1,bd%jsd:bd%jed ) means we should assign. Example:</li> </ul> </li> </ul> <pre><code>      self.in_vars[\"data_vars\"][\"cx\"] = {\"istart\": self.is\\_, \"iend\": self.ie + 1,\n                                         \"jstart\": self.jsd, \"jend\": self.jed,}\n</code></pre> <ul> <li>There is only a limited set of Fortran shapes declared, so abstractions defined in the grid can also be used,     e.g.: <code>self.out_vars[\"cx\"] = self.grid.x3d_compute_domain_y_dict()</code>. Note that the variables, e.g. <code>grid.is\\_</code> and <code>grid.ie</code> specify the 'compute' domain in the x direction of the current tile, equivalent to <code>bd%is</code> and <code>bd%ie</code> in the Fortran model EXCEPT that the Python variables are local to the current MPI rank (a subset of the tile face), while the Fortran values are global to the tile face. This is because these indices are used to slice into fields, which in Python is 0-based, and in Fortran is based on however the variables are declared. But, for the purposes of aligning data for computations and comparisons, we can match them in this framework. Shapes need to be defined in a dictionary per variable including <code>\"istart\"</code>, <code>\"iend\"</code>, <code>\"jstart\"</code>, <code>\"jend\"</code>, <code>\"kstart\"</code>, <code>\"kend\"</code> that represent the shape of that variable as defined in the Fortran code. The default shape assumed if a variable is specified with an empty dictionary is <code>isd:ied, jsd:jed, 0:npz - 1</code> inclusive, and variables that aren't that shape in the Fortran code need to have the 'start' indices specified for the in_vars dictionary , and 'start' and 'end' for the out_vars.</li> <li><code>\"serialname\"</code> can be used to specify a name used in the Fortran code declaration if we'd like the model to use a different name</li> <li><code>\"kaxis\"</code>: which dimension is the vertical direction. For most variables this is '2' and does not need to be specified. For Fortran variables that assign the vertical dimension to a different axis, this can be set to ensure we end up with 3d storages that have the vertical dimension where it is expected by GT4py.</li> <li><code>\"dummy_axes\"</code>: If set this will set of the storage to have singleton dimensions in the axes defined. This is to enable testing stencils where the full 3d data has not been collected and we want to run stencil tests on the data for a particular slice.</li> <li><code>\"names_4d\"</code>: If a 4d variable is being serialized, this can be set to specify the names of each 3d field. By default this is the list of tracers.</li> <li>input variables that are scalars should be added to <code>self.in_vars[\"parameters\"]</code></li> <li><code>self.compute_func</code> is the name of the model function that should be run by the compute method in the translate class</li> <li><code>self.max_error</code> overrides the parent classes relative error threshold. This should only be changed when the reasons for non-bit reproducibility are understood.</li> <li><code>self.max_shape</code> sets the size of the gt4py storage created for testing</li> <li><code>self.ignore_near_zero_errors[&lt;varname&gt;] = True</code>: This is an option to let some fields pass with higher relative error if the absolute error is very small</li> <li><code>self.skip_test</code>: This is an option to jump over the test case, to be used in the override file for temporary deactivation of tests.</li> </ul> <p>For <code>ParallelTranslate</code> objects:</p> <ul> <li>Inputs and outputs are defined at the class level, and these include metadata such as the \"name\" (e.g. understandable name for the symbol), dimensions, units and n_halo(numb er of halo lines)</li> <li>Both <code>compute_sequential</code> and <code>compute_parallel</code> methods may be defined, where a mock communicator is used in the <code>compute_sequential</code> case</li> <li>The parent assumes a state object for tracking fields and methods exist for translating from inputs to a state object and extracting the output variables from the state. It is assumed that Quantity objects are needed in the model method in order to do halo updates.</li> <li><code>ParallelTranslate2Py</code> is a slight variation of this used for many of the parallel units that do not yet utilize a state object and relies on the specification of the same index metadata of the Translate classes</li> <li><code>ParallelTranslateBaseSlicing</code> makes use of the state but relies on the Translate object of self._base, a Translate class object, to align the data before making quantities, computing and comparing.</li> </ul>"},{"location":"technical/porting/translate_test/#debugging-tests","title":"Debugging Tests","text":"<p>Pytest can be configured to give you a pdb session when a test fails. To route this properly through docker, you can run:</p> <pre><code>TEST_ARGS=\"-v -s --pdb\" RUN_FLAGS=\"--rm -it\" make tests\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#what-is-ndsl","title":"What is NDSL?","text":"<p>The NASA/NOAA Domain Specific Language (NDSL) is a Python based middleware which allows users to accelerate their code and seamlessly switch between CPU and GPU execution. To achieve this, NDSL leverages the functionality of GT4Py and optimization capabilities of DaCe to creating a smooth, unified user experience which allows for easy development of grid-based models.</p> <p>NDSL has extensive documentation, and this should serve as a first point of reference for questions about the system; however, it is important to note that GT4Py and DaCe also have their own sets of documentation, and these may be useful - particularly for more nuanced applications.</p> <p>NDSL - like all DSL's - is powerful because it is restrictive. Every degree of freedom added exponentially increases optimization difficulty, and ultimately lowers performance ceilings. While this software has numerous features designed to make the development process smoother, there will inevitably be situations where desired patterns fail to align seamlessly with core concepts of this language. In those moments, it is important to remember that these patterns were \"banned\" because their implementation would dramatically reduce (or, in some cases, completely eliminate) the create a nimble, efficient executable product.</p> <p>The requirement to (occasionally) rethink old methods may occasionally be a significant request; however, with it comes significant benefit. Below are a few examples of the performance gains achieved with NDSL:</p> <p>PERFORMANCE GAINS HERE</p> <p>NDSL User Manual</p> <p>A user manual has been compiled for NDSL. This guide has been designed to introduce important concepts and establish a solid foundation required to use NDSL. For that reason, it is highly recommended that you look through this guide before working with NDSL. </p>"},{"location":"tutorials/#what-is-geos","title":"What is GEOS","text":"<p>The Goddard Earth Observing System (GEOS) is the flagship Earth system model developed by NASA Goddard Space Flight Center. Traditionally developed and run in Fortran, this model brings together numerous components - atmopshere, ocean, radiation, land surface, chemistry, etc. - to  create a complete picture of the Earth's dynamic systems. Development is led by the GMAO, with support from numerous public and private partners. More information is available here.</p>"},{"location":"tutorials/#faq","title":"FAQ","text":"<p>For questions which are not answered by the tutorials, please check the list of frequently asked questions (FAQ). Additional questions can be submitted here FORM LINK HERE.</p>"},{"location":"tutorials/faq/","title":"Frequently Asked Questions (FAQ)","text":"Does NDSL support strings? <p>No. NDSL in no way supports strings. There are only three accepted data types: <code>Float</code>, <code>Int</code>, and <code>Bool</code>.</p>"},{"location":"tutorials/ndsl_user_manual/advanced_features/","title":"Advanced Stencil Properties and Techniques","text":"<p>NDSL has a number of features which are designed to streamline development.</p> <p>To help illustrate them, let's create a simple stencil where we convert temperature from Celsius to Kelvin:</p> <pre><code>``` py linenums=\"1\"\nfrom ndsl.dsl.gt4py import PARALLEL, computation, interval\nfrom ndsl import StencilFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\nfrom ndsl.dsl.typing import FloatField\nimport random\n\n\ndef celsius_to_kelvin(temperature_Celsius: FloatField, temperature_Kelvin: FloatField):\n    with computation(PARALLEL), interval(...):\n            # convert from Celsius to Kelvin\n            temperature_Kelvin = temperature_Celsius + 273.15\n\n\nclass Convert:\n    def __init__(self, stencil_factory: StencilFactory):\n\n        # construct the stencil\n        self.constructed_copy_stencil = stencil_factory.from_dims_halo(\n            func=celsius_to_kelvin,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n    def __call__(self, in_quantity: FloatField, out_quantity: FloatField):\n\n        # call the stencil\n        self.constructed_copy_stencil(in_quantity, out_quantity)\n\n\nif __name__ == \"__main__\":\n\n    # setup domain and generate factories\n    domain = (5, 5, 3)\n    nhalo = 0\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n    )\n\n    # initialize the class\n    convert = Convert(stencil_factory)\n\n    # initialize quantities\n    temperature_Celsius = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for i in range(temperature_Celsius.field.shape[0]):\n        for j in range(temperature_Celsius.field.shape[1]):\n            for k in range(temperature_Celsius.field.shape[2]):\n                temperature_Celsius.field[i, j, k] = 20 + round(\n                    random.uniform(-10, 10), 2\n                )\n\n    temperature_Kelvin = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    temperature_Kelvin.field[:] = -999\n\n    # call the class, perform the calculation\n    convert(temperature_Celsius, temperature_Kelvin)\n```\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/advanced_features/#externals","title":"Externals","text":"<p>NDSL has the ability build a stencil with immutable constants, called \"externals\", that can be referenced only within that instance of the stencil. In this example, we can pass 273.15 to the stencil as an external called <code>C_TO_K</code> and reference that throughout the stencil.</p> <p>This ability is particularly useful as code gets more complicated, where constants may need to be modified outside of the stencil (for instance, a tuning parameter which can vary from 0 to 1) and where a constant is referenced numerous times throughout a stencil.</p> <p>To build the stencil with an external, we just need to add a single argument to the build command:</p> <pre><code>        self.constructed_copy_stencil = stencil_factory.from_dims_halo(\n            func=celsius_to_kelvin,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n            externals={\n                \"C_TO_K\": 273.15,\n            },\n        )\n</code></pre> <p>And then to load in the external within the stencil:</p> <pre><code>def celsius_to_kelvin(temperature_Celsius: FloatField, temperature_Kelvin: FloatField):\n    # read in the external\n    from __externals__ import C_TO_K\n\n    with computation(PARALLEL), interval(...):\n            # convert from Celsius to Kelvin\n            temperature_Kelvin = temperature_Celsius + C_TO_K\n</code></pre> <p>Note that these externals are not automatically passed down to any functions called with the stencil. They must be passed in as an input.</p> <p>Externals may be of type <code>float</code>, <code>int</code>, or <code>bool</code>, but must be scalar values.</p> <p>NDSL has a a number of externals which are related to the compute domain of a stencil and are always available (we will discuss compute domain more in a later section). These are:</p> <ul> <li><code>i_start</code></li> <li><code>i_end</code></li> <li><code>j_start</code></li> <li><code>j_end</code></li> <li><code>k_start</code></li> <li><code>k_end</code></li> </ul>"},{"location":"tutorials/ndsl_user_manual/advanced_features/#restricting-the-compute-domain","title":"Restricting the Compute Domain","text":"<p>The compute domain is the subset of the model domain over which the stencil is being computed. By default, the compute domain is the entire model domain, but NDSL has tools to introduce restrictions. Thus far, we have used <code>from_dims_halo</code>, which always includes the entire domain. There is another method - <code>from_origin_domain</code>, which allows more flexibility (in fact, <code>from_dims_halo</code> calls this method with fixed arguments). Modifying our example above:</p> <pre><code>class Convert:\n    def __init__(self, stencil_factory: StencilFactory, domain):\n\n        self.constructed_copy_stencil = stencil_factory.from_origin_domain(\n            func=celcius_to_kelvin,\n            origin=(0, 0, 0),\n            domain=domain,\n            externals={\n                \"C_TO_K\": 273.15,\n            },\n        )\n</code></pre> <p>and now we need to pass in an additional argument to the class:</p> <pre><code>    convert = Convert(stencil_factory, domain)\n</code></pre> <p>The key arguments with <code>from_dims_halo</code> are <code>origin</code> (which specifies the starting point for all computations) and <code>domain</code> (which specifies the end point). Any restrictions on <code>interval</code> will count from these points. For example, if origin is set to <code>(0, 0, 1)</code>, and the stencil has a computation using <code>with interval(1, None)</code>, the calculations will begin at the second K level. A similar behavior occurs with <code>domain</code> and <code>interval</code> end points.</p> <p>Note that restricting <code>domain</code> is the only way to restrict computation across the X/Y plane. Additionally, a single stencil template can be used multiple times with different supporting arguments to create multiple executable stencils.</p> <p>Of course, using <code>from_dims_halo</code> requires information about the <code>domain</code> to be available, and a previous guide stated that <code>domain</code> would not (and should not) be explicitly defined when integrating code into a larger system. At that stage, information about the domain will be automatically generated and stored in a variable called <code>grid</code> - but we will talk more about that when we get there.</p>"},{"location":"tutorials/ndsl_user_manual/advanced_features/#four-dimensional-fields-and-data-dimensions","title":"Four Dimensional Fields and Data Dimensions","text":"<p>It is possible to create a four dimensional field in NDSL. This is constructed as a standard three dimensional field plus a fourth \"data dimension\". This fourth dimension cannot be parallelized, and therefore cannot be iterated over like the primary three dimensions.</p> <p>The example below shows how to create a four dimensional field, where the fourth dimension has size 36. </p> <pre><code>class example_4D_fields:\n    def __init__(\n        self,\n        stencil_factory: StencilFactory,\n        quantity_factory: QuantityFactory,\n    ) -&gt; None:\n\n        self.field_4D_quantity_factory = self.make_4D_quantity_factory(\n            self.quantity_factory,\n        )\n\n        self.field4D = self.field_4D_quantity_factory.zeros(\n            [X_DIM, Y_DIM, Z_DIM, \"extra_dim\"], \"n/a\"\n        )\n\n    @staticmethod\n    def make_4D_quantity_factory(\n        ijk_quantity_factory: QuantityFactory,\n    ):\n        field_4D_quantity_factory = copy.deepcopy(ijk_quantity_factory)\n        field_4D_quantity_factory.set_extra_dim_lengths(\n            **{\n                \"extra_dim\": 36,\n            }\n        )\n        return field_4D_quantity_factory\n</code></pre> <p>These fields have a unique accessing method: <code>field4D[0, 0, 0][0]</code>. The first three indexes are the standard relative indexing method, while the fourth is an absolute index corresponding to the desired location along the additional axis that you want to reference.</p> <p>Using a similar method as above, it is also possible to create data dimensions with one or two of the primary three dimensions. Note that there must always be one primary dimension present.</p>"},{"location":"tutorials/ndsl_user_manual/advanced_features/#typecasting","title":"Typecasting","text":"<p>NDSL uses the traditional Python functions <code>int()</code> and <code>float()</code> to cast numbers to integers or floating point precision, respectively. When using these casts, the precision is automatically set to line up with the specified global precision. It is possible; however, to overwrite this and cast explicitly to a 32 or 64 bit version with <code>i32()</code>/<code>i64()</code>/<code>f32()</code>/<code>f64()</code></p> <p>It is also possible to initiate a temporary field with a specific type. The correct nomenclature is: <code>field: type = 0</code> where <code>type</code> can be any of <code>i32</code>/<code>i64</code>/<code>f32</code>/<code>f64</code></p>"},{"location":"tutorials/ndsl_user_manual/advanced_features/#current-index-information","title":"Current Index Information","text":"<p>NDSL stores information about the current K level in a variable called <code>THIS_K</code> as type <code>Int</code>. This must be imported from <code>gt4py.cartesian.gtscript</code> prior to being used.</p>"},{"location":"tutorials/ndsl_user_manual/advanced_features/#absolute-k-indexing","title":"Absolute K Indexing","text":"<p>NDSL does have a method for absolute indexing within a stencil, but it should be used with caution. This can only be used at read (similar to offsets), and should only be used when absolutely necessary (i.e. do not rely on this when relative offsetting is sufficient).</p> <p>The proper nomenclature is <code>field.at(K=level)</code> where level is a <code>Int</code> type number, variable, or expression which corresponds to a level present in the accessed field.</p> <p>Similarly, absolute K-Indexing can be used on a four-dimensional field as follows:  <code>field4D.at(K=level, ddim=[n])</code>, where <code>n</code> represents the index being accessed along the fourth dimension.</p>"},{"location":"tutorials/ndsl_user_manual/advanced_features/#summary","title":"Summary","text":"<p>This guide introduced some more advanced features and exceptions to some of NDSL's rules. If used as designed these features will have no impact on performance, but it is possible to misuse these features in ways that will degrade performance. For that reason, it is recommended that these features are used sparingly, to that they do not become a crutch that enables poor coding habits and reduces the potency of the software as a whole.</p> <p>In the next guide, we will introduce some more details about the inner workings of NDSL, and in the process unlock more control over the acceleration process.</p>"},{"location":"tutorials/ndsl_user_manual/backends/","title":"Backends","text":"<p>Throughout this user manual, we have been building our factories with some version of the following code:</p> <pre><code>domain = (5, 5, 3)\nnhalo = 0\nbackend = \"numpy\"\nstencil_factory, quantity_factory = get_factories_single_tile(\n    domain[0],\n    domain[1],\n    domain[2],\n    nhalo,\n    backend,\n)\n</code></pre> <p>but we have thus far glossed over what \"backend\" means. It is now time to address that term.</p> <p>\"Backend\" refers to the underlying infrastructure that NDSL uses to construct and execute stencils. Each backend approaches acceleration in a slightly different way, and by extention has different  benefits and drawbacks. NDSL has a total of four backends:</p> <ul> <li><code>dace:cpu</code>: stencils are compiled in C and has multiple optimization passes tailored to CPU execution. longest compilation time, but best performance gain</li> <li><code>dace:gpu</code>: stencils are compiled in C and has multiple optimization passes tailored to GPU execution. longest compilation time, but best performance gain</li> <li><code>numpy</code>: stencils are compiled in Python with minimal optimization, moderate compilation time, moderate performance gain</li> <li><code>debug</code>: code is executed as written in plain Python, no optimization, no performance gain </li> </ul> <p>A couple of notes from this list: <code>dace</code> provides the best performance gain, but may come with a significant compilation time that makes debugging difficult. For this reason, we advise that you work in <code>numpy</code> when testing smaller code (the performance difference between <code>numpy</code> and <code>dace</code> will be minimal at this scale) and swap to <code>dace</code> for larger executions (e.g. running a model at scale). The <code>debug</code> backend should only be used as a last resort. The removal of optimization features means that this is an ideal backend for preliminary development and testing of new NDSL features, but execution with this backend is pitifully slow compared to <code>numpy</code> and <code>dace</code> supported backends.</p>"},{"location":"tutorials/ndsl_user_manual/best_coding_practices/","title":"Best Coding Practices","text":"<p>In this section, we provide some general guidelines for writing and structuring code in NDSL. While these practices are not necessarily required, we strongly encourage users to adhere to them as they are important for readability, maintainability, collaboration, and performance.</p>"},{"location":"tutorials/ndsl_user_manual/best_coding_practices/#docstrings","title":"Docstrings","text":"<p>When writing code using NDSL, it is important that your code is well-documented so that others can easily understand the purpose of your code without having to dig into the implementation details. We strongly encourage the use of docstrings to document your code.</p> <p>Docstrings are strings written immediately after the definition of an NDSL function, stencil, or class. They are enclosed in triple quotes (<code>\"\"\"</code> or <code>'''</code>) and can span multiple lines. A good docstring should include information about what the function, stencil, or class does. It should also include a summary of what the code does and a list of parameters, their type, and a description. See below for an example of how to write docstrings for a GT4Py function.</p> <pre><code>@gtscript.function\ndef sign(\n    a: Float,\n    b: Float,\n):\n    \"\"\"\n    Function that returns the magnitude of one argument and the sign of another.\n\n    Inputs:\n    a [Float]: Argument of which the magnitude is needed [unitless]\n    b [Float]: Argument of which the sign is needed [unitless]\n\n    Returns:\n    result [Float]: The magnitude of a and sign of b [unitless]\n    \"\"\"\n\n    if b &gt;= 0.0:\n        result = abs(a)\n    else:\n        result = -abs(a)\n\n    return result\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/best_coding_practices/#temporaries","title":"Temporaries","text":"<p>To create and store temporary fields in NDSL, which are not explicitly defined within a stencil or class, we strongly encourage the use of NDSL <code>dataclasses</code>. A <code>dataclass</code> is a Python class that is used to store or hold data. While the use of <code>dataclasses</code> are not required, we strongly encourage our users to store temporaries in a <code>dataclass</code> for cleanliness and readability purposes.</p> <p>See below for an example of how to create a <code>dataclass</code> to hold temporary fields.</p> <pre><code>from dataclasses import dataclass\n\nfrom ndsl import Quantity, QuantityFactory\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\n\n@dataclass\nclass Temporaries:\n    ssthl0: Quantity\n    ssqt0: Quantity\n    ssu0: Quantity\n    ssv0: Quantity\n\n    @classmethod\n    def make(cls, quantity_factory: QuantityFactory):\n        # FloatFields\n        ssthl0 = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n        ssqt0 = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n        ssu0 = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n        ssv0 = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n        return cls(\n            ssthl0,\n            ssqt0,\n            ssu0,\n            ssv0,\n        )\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/best_coding_practices/#general-structure-of-ndsl-repositories","title":"General structure of NDSL repositories","text":"<p>Now that we have covered pretty much all of the topics needed to start learning and developing code in NDSL, it's time to talk about how a repository containing NDSL code should be structured.</p> <p>In this example, we've created a mock-up repository which contains NDSL code to convert temperature from Fahrenheit to Kelvin and then back to Fahrenheit. We've named our mock-up  repository <code>tutorial</code>, which contains four Python scripts: <code>driver.py</code>, <code>stencils.py</code>,  <code>constants.py</code>, and <code>temporaries.py</code>. </p> <p>Each script has a unique purpose. For example, <code>driver.py</code> contains code to create and call the <code>class</code> that initializes the NDSL stencils.</p> <pre><code>from ndsl import StencilFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\nfrom ndsl.dsl.typing import FloatField\nfrom pyMoist.tutorial.stencils import convert_F_to_K, convert_K_to_F\nfrom pyMoist.tutorial.temporaries import Temporaries\nimport random\n\nclass Temperature_Conversion:\n    def __init__(self, stencil_factory: StencilFactory):\n        \"\"\"\n        Class to convert temperatures from Fahrenheit to Kelvin and then back to Fahrenheit\n\n        Parameters:\n        stencil_factory (StencilFactory): Factory for creating stencil computations\n        \"\"\"\n\n        # Build stencils\n        self.convert_F_to_K = stencil_factory.from_dims_halo(\n            func=convert_F_to_K,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n        self.convert_K_to_F = stencil_factory.from_dims_halo(\n            func=convert_K_to_F,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n        self.temporaries = Temporaries.make(quantity_factory)\n\n    def __call__(\n        self,\n        temp_F: FloatField,\n        temp_K: FloatField,\n    ):\n\n        self.convert_F_to_K(\n            temp_F,\n            temp_K,\n        )\n\n        self.convert_K_to_F(\n            temp_K,\n            self.temporaries.temp_C,\n            temp_F,\n        )\n\n\nif __name__ == \"__main__\":\n\n    # Setup domain and generate factories\n    domain = (5, 5, 10)\n    nhalo = 0\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n        backend=\"debug\",\n    )\n\n    # Initialize quantities\n    temp_F = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for i in range(temp_F.field.shape[0]):\n        for j in range(temp_F.field.shape[1]):\n            for k in range(temp_F.field.shape[2]):\n                temp_F.field[i, j, k] = round(random.uniform(70, 90), 2)\n\n    temp_K = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n    # Build stencil\n    code = Temperature_Conversion(stencil_factory)\n\n    # Check input data\n    print(temp_F.field[0, 0, :])\n\n    # Execute stencil\n    code(temp_F, temp_K)\n\n    # Check output data\n    print(temp_K.field[0, 0, :])\n    print(temp_F.field[0, 0, :])\n</code></pre> <p><code>stencils.py</code> contains both NDSL functions and stencils that do the temperature conversion.</p> <pre><code>from ndsl.dsl.gt4py import (\n    computation,\n    interval,\n    PARALLEL,\n)\nimport gt4py.cartesian.gtscript as gtscript\nfrom ndsl.dsl.typing import FloatField, Float\nimport pyMoist.tutorial.constants as constants\n\n\n@gtscript.function\ndef convert_F_to_C(\n    t_F: Float,\n):\n    \"\"\"\n    Function to convert Fahrenheit to Celsius.\n\n    Inputs:\n    t_F (Float): Temperature in Fahrenheit (degrees)\n\n    Returns:\n    t_C (Float): Temperature in Celsius (degrees)\n    \"\"\"\n    t_C = (t_F - 32) * (5 / 9)\n\n    return t_C\n\n\n@gtscript.function\ndef convert_C_to_F(\n    t_C: Float,\n):\n    \"\"\"\n    Function to convert Celsius to Fahrenheit.\n\n    Inputs:\n    t_C (Float): Temperature in Celsius (degrees)\n\n    Returns:\n    t_F (Float): Temperature in Fahrenheit (degrees)\n    \"\"\"\n    t_F = (t_C * (9 / 5)) + 32\n\n    return t_F\n\n\ndef convert_F_to_K(\n    temp_F: FloatField,\n    temp_K: FloatField,\n):\n    \"\"\"\n    Stencil to convert temperature from Fahrenheit to Kelvin.\n\n    Temperature is first converted to Celsius, then Celsius to Kelvin.\n\n    Inputs:\n    temp_F (FloatField): Temperature in degrees Fahrenheit\n\n    Outputs:\n    temp_K (FloatField): Temperature in Kelvin (unitless)\n    \"\"\"\n\n    with computation(PARALLEL), interval(...):\n        temp_C = convert_F_to_C(temp_F)\n        temp_K = temp_C + constants.absolute_zero\n\n\ndef convert_K_to_F(\n    temp_K: FloatField,\n    temp_C: FloatField,\n    temp_F: FloatField,\n):\n    \"\"\"\n    Stencil to convert temperature from Kelvin to Fahrenheit.\n\n    Temperature is first converted to Celsius, then Celsius to Fahrenheit.\n\n    Inputs:\n    temp_K (FloatField): Temperature in Kelvin (unitless)\n\n    Outputs:\n    temp_F (FloatField): Temperature in degrees Fahrenheit\n    \"\"\"\n\n    with computation(PARALLEL), interval(...):\n        temp_C = temp_K - constants.absolute_zero\n        temp_F = convert_C_to_F(temp_C)\n</code></pre> <p><code>temporaries.py</code> contains a <code>dataclass</code> that holds any temporary fields used in the stencil computations</p> <pre><code>from dataclasses import dataclass\n\nfrom ndsl import Quantity, QuantityFactory\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\n\n\n@dataclass\nclass Temporaries:\n    temp_C: Quantity\n\n    @classmethod\n    def make(cls, quantity_factory: QuantityFactory):\n        # FloatFields\n        temp_C = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n        return cls(\n            temp_C,\n        )\n</code></pre> <p><code>constants.py</code> contains any constants needed in the functions and stencils</p> <pre><code>from ndsl.dsl.typing import Float\n\nabsolute_zero = Float(273.15)\n</code></pre> <p>It is important to structure your NDSL repositories in a similar fashion not only for cleanliness and readability, but for scalability and debugging purposes as well.</p>"},{"location":"tutorials/ndsl_user_manual/common_patterns/","title":"Common Patterns","text":"<p>Now that we have introduced the core features of NDSL and highlighted features which enable more complex coding structures, it is prudent to provide examples of how NDSL is implemented.</p> <p>Below are a plethora of patterns which may be useful when developing code for weather and climate models. These examples have been generalized, but should be broadly applicable to a variety of situations. Each example has a \"source\" Fortran program, and a \"ported\" NDSL implementation.</p>"},{"location":"tutorials/ndsl_user_manual/common_patterns/#writing-to-a-z_interface_dim-variable","title":"Writing to a <code>Z_INTERFACE_DIM</code> Variable","text":"<p>If working with <code>Z_INTERFACE_DIM</code> quantities, one will inevitably need to write to the \"extra\" point. The easiest way to achieve this is by declaring your <code>compute_dims</code> to operate on the <code>Z_INTERFACE_DIM</code> instead of the <code>Z_DIM</code>, and then restrict your interval and offset <code>Z_DIM</code> stencil reads accordingly:</p> <p>Example \"Fortran code\":     <pre><code>program compute_height\n    implicit none\n\n    ! setup domain\n    integer, parameter :: X_DIM = 10\n    integer, parameter :: Y_DIM = 10\n    integer, parameter :: Z_DIM = 10\n\n    ! allocate scalars\n    integer :: i, j, k, p_crit\n    real :: seed, total\n\n    ! allocate arrays\n    real, dimension(X_DIM, Y_DIM, Z_DIM) :: d_height\n    real, dimension(X_DIM, Y_DIM, Z_DIM+1) :: height\n\n    ! initalize data\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            do k = 1, Z_DIM\n                call RANDOM_NUMBER(seed)\n                ! generate a random change in height for each layer in the range 125:175\n                d_height(i, j, k) = 125 + FLOOR(51*seed)\n            enddo\n        enddo\n    enddo\n\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            do k = 2, Z_DIM+1\n                height(i, j, k) = height(i, j, k-1) + d_height(i, j, k-1)\n            enddo\n        enddo\n    enddo\n\n    PRINT *, height(1, 1, :)\n\nend program compute_height\n</code></pre></p> <p>Example \"NDSL Code\"</p> <pre><code>``` py linenums=\"1\"\nfrom ndsl.dsl.gt4py import (\n    computation,\n    interval,\n    PARALLEL,\n)\nfrom ndsl import StencilFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM, Z_INTERFACE_DIM\nfrom ndsl.dsl.typing import FloatField\nimport random\n\n\ndef compute_height(\n    height: FloatField,\n    d_height: FloatField,\n):\n\n    with computation(PARALLEL), interval(1, None):\n        # d_height is offset down one because this field operates on the Z_DIM,\n        # while the stencil is computing on the Z_INTERFACE_DIM\n        height = height[0, 0, -1] + d_height[0, 0, -1]\n\n\nclass Code:\n    def __init__(self, stencil_factory: StencilFactory):\n\n        # build stencil\n        self.constructed_stencil = stencil_factory.from_dims_halo(\n            func=compute_height,\n            compute_dims=[X_DIM, Y_DIM, Z_INTERFACE_DIM],\n        )\n\n    def __call__(\n        self,\n        height: FloatField,\n        d_height: FloatField,\n    ):\n        # execute stencil\n        self.constructed_stencil(\n            height,\n            d_height,\n        )\n\n\nif __name__ == \"__main__\":\n\n    # setup domain and generate factories\n    domain = (10, 10, 10)\n    nhalo = 0\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n        backend=\"dace:cpu\",\n    )\n\n    # initialize data\n    height = quantity_factory.zeros([X_DIM, Y_DIM, Z_INTERFACE_DIM], \"n/a\")\n\n    d_height = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for i in range(d_height.field.shape[0]):\n        for j in range(d_height.field.shape[1]):\n            for k in range(d_height.field.shape[2]):\n                d_height.field[i, j, k] = round(random.uniform(125, 175))\n\n    # build stencil\n    code = Code(stencil_factory)\n\n    # execute stencil\n    code(height, d_height)\n\n    print(height.field[0, 0, :])\n```\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/common_patterns/#k-dimension-dependent-computations","title":"K-Dimension Dependent Computations","text":"<p>In weather and climate modeling, it is often necessary to identify a specific level, then perform one or more operations based on that level (e.g. identify LCL, compute convective parameters).</p> <p>Example \"Fortran Code\":</p> <pre><code>``` fortran linenums=\"1\"\nprogram average_below_level\n    implicit none\n\n    ! setup domain\n    integer, parameter :: X_DIM = 10\n    integer, parameter :: Y_DIM = 10\n    integer, parameter :: Z_DIM = 10\n\n    ! allocate scalars\n    integer :: i, j, k, p_crit\n    real :: seed, total\n\n    ! allocate arrays\n    integer, dimension(X_DIM, Y_DIM, Z_DIM) :: temperature, pressure\n    integer, dimension(X_DIM, Y_DIM) :: desired_level\n    real, dimension(X_DIM, Y_DIM) :: average_temperature\n\n    ! initalize data\n    p_crit = 500\n    do k = 1, Z_DIM\n        pressure(:, :, k) = 1000 - (k-1) * 100 ! pressure decreases by 100mb per level\n        do j = 1, Y_DIM\n            do i = 1, X_DIM\n                call RANDOM_NUMBER(seed)\n                ! generate a random temperature in the range 20:30\n                temperature(i, j, k) = 20 + FLOOR(11*seed)\n            enddo\n        enddo\n    enddo\n\n\n    ! determine k level where pressure meets a critical value\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            do k = 1, Z_DIM\n                if (pressure(i, j, k) &lt; p_crit) then\n                    desired_level(i, j) = k\n                    ! in this simplified example desired level is the same everywhere, but one can\n                    ! imagine a case where this is spatially variable (e.g. determine LCL or LFC)\n                    exit\n                endif\n            enddo\n        enddo\n    enddo\n\n    ! calculate average based on desired_level\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            total = 0\n            do k = 1, desired_level(i, j)\n                total = total + temperature(i, j, k)\n            enddo\n            average_temperature(i, j) = total/desired_level(i, j)\n        enddo\n    enddo\n\n    PRINT *, average_temperature\n\nend program average_below_level\n```\n</code></pre> <p>Example \"NDSL Code\"</p> <pre><code>``` py linenums=\"1\"\nfrom ndsl.dsl.gt4py import (\n    FORWARD,\n    computation,\n    interval,\n)\nfrom gt4py.cartesian.gtscript import THIS_K\nfrom ndsl import StencilFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\nfrom ndsl.dsl.typing import FloatField, FloatFieldIJ, IntFieldIJ, Int, Float\nimport random\n\n\ndef average_layers(\n    temperature: FloatField,\n    pressure: FloatField,\n    average_temperature: FloatFieldIJ,\n    desired_level: IntFieldIJ,\n):\n    from __externals__ import p_crit, k_end\n\n    with computation(FORWARD), interval(...):\n        # determine critical level\n        if pressure &gt; p_crit:\n            desired_level = THIS_K\n\n    with computation(FORWARD), interval(...):\n        # sum all temperatures below critical level\n        if THIS_K &lt;= desired_level:\n            average_temperature = average_temperature + temperature\n        # calculate the average on the final level\n        if THIS_K == k_end:\n            average_temperature = average_temperature / desired_level\n\n\nclass Code:\n    def __init__(self, stencil_factory: StencilFactory):\n\n        self.constructed_stencil = stencil_factory.from_dims_halo(\n            func=average_layers,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n            externals={\n                \"p_crit\": 500,\n            },\n        )\n\n    def __call__(\n        self,\n        temperature: FloatField,\n        pressure: FloatField,\n        average_temperature: FloatFieldIJ,\n        desired_level: IntFieldIJ,\n    ):\n        self.constructed_stencil(\n            temperature,\n            pressure,\n            average_temperature,\n            desired_level,\n        )\n\n\nif __name__ == \"__main__\":\n\n    # setup domain and generate factories\n    domain = (10, 10, 10)\n    nhalo = 0\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n        backend=\"dace:cpu\",\n    )\n\n    # initialize data\n    temperature = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for i in range(temperature.field.shape[0]):\n        for j in range(temperature.field.shape[1]):\n            for k in range(temperature.field.shape[2]):\n                temperature.field[i, j, k] = round(random.uniform(20, 30))\n\n    pressure = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for k in range(pressure.field.shape[2]):\n        pressure.field[:, :, k] = 1000 - k * 100\n\n    average_temperature = quantity_factory.zeros([X_DIM, Y_DIM], \"n/a\")\n    desired_level = quantity_factory.zeros([X_DIM, Y_DIM], \"n/a\", dtype=Int)\n\n    # build stencil\n    code = Code(stencil_factory)\n\n    # execute stencil\n    code(temperature, pressure, average_temperature, desired_level)\n\n    print(average_temperature.field)\n```\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/common_patterns/#global-tables","title":"Global Tables","text":"<p>There may be situations where a table is needed for referencing throughout the execution of a component/model. It is highly unlikely that these tables will conform to the grid system used by the rest of the model in any way. Generating these tables, therefore, requires a somewhat unconventional use of systems. The following example is an adaptation of code used to generate one of the saturation vapor pressure tables in the GEOS model, and displays the flexibility of NDSL systems:</p> <p>Example \"Fortran Code\"</p> <pre><code>``` fortran linenums=\"1\"\nprogram make_table\n\n    implicit none\n\n    integer, parameter :: size = 1000 ! dimension not related to the size of the encompassing model\n\n    real :: constant_one, constant_two\n    real, dimension(size) :: table\n\n    integer :: l\n\n    constant_one = 10\n    constant_two = 2\n\n    ! construct a table based on temperature input\n\n    do l = 1, size\n        table(l) = log(0.1 * (l-1) / constant_one) + constant_two\n    enddo\n\n    print *, table\n\nend program make_table\n```\n</code></pre> <p>Example \"NDSL Code\"</p> <pre><code>``` py linenums=\"1\"\nfrom ndsl.dsl.gt4py import (\n    computation,\n    interval,\n    log,\n    PARALLEL,\n    GlobalTable,\n)\nfrom ndsl import StencilFactory, QuantityFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\nfrom ndsl.dsl.typing import FloatField, Float\nfrom gt4py.cartesian.gtscript import THIS_K\n\n\n# NOTE Ideally, these next two statements should be done elsewhere (perhaps\n# in a constants and types file, respectively) and imported\n# declare table size\ntable_size = 1000\n# define table type\nGlobalTable_local_type = GlobalTable[(Float, int(table_size))]\n\n\ndef _compute_table(table: FloatField):\n    from __externals__ import constant_one, constant_two\n\n    with computation(PARALLEL), interval(1, None):\n        table = log(0.1 * THIS_K / constant_one) + constant_two\n\n\ndef _use_table(out_field: FloatField, table: GlobalTable_local_type):\n    with computation(PARALLEL), interval(...):\n        out_field = 2 * table.A[150]\n\n\nclass ConstructTable:\n    def __init__(self, stencil_factory: StencilFactory, quantity_factory: QuantityFactory):\n\n        # build stencil\n        self.compute_table = stencil_factory.from_dims_halo(\n            func=_compute_table,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n            externals={\n                \"constant_one\": 10,\n                \"constant_two\": 2,\n            },\n        )\n\n        self._table = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n    def __call__(self):\n        # execute stencil\n        self.compute_table(\n            self._table,\n        )\n\n        # return a GlobalTable object\n\n    @property\n    def table(self):\n        return self._table.field[0, 0, :]\n\n\nif __name__ == \"__main__\":\n    # consider the following model domain and factories are presnet\n    domain = (10, 10, 10)\n    nhalo = 0\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n        backend=\"dace:cpu\",\n    )\n\n    # we must create a new set for this table calculation, because we require an off-grid dimension\n    domain_table = (1, 1, table_size)\n    nhalo_table = 0\n    stencil_factory_table, quantity_factory_table = get_factories_single_tile(\n        domain_table[0],\n        domain_table[1],\n        domain_table[2],\n        nhalo_table,\n        backend=\"debug\",\n    )\n\n    # initialize data\n    temperature = quantity_factory_table.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n    for l in range(temperature.field.shape[2]):\n        temperature.field[:, :, l] = 10 + 0.01 * (l + 1)\n\n    # build stencil\n    construct_table = ConstructTable(stencil_factory_table, quantity_factory_table)\n\n    # execute stencil\n    construct_table()\n\n    # construct stencil that will use the table\n    use_table = stencil_factory.from_dims_halo(\n        func=_use_table,\n        compute_dims=[X_DIM, Y_DIM, Z_DIM],\n    )\n\n    # # initalize array for calculation using table\n    out_field = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n    use_table(out_field, construct_table.table)\n\n    print(construct_table.table)\n    print(\"Done \ud83d\ude80\")\n```\n</code></pre> <p>These tables must be subsequently referenced as a local variant of the <code>GlobalTable</code> type, informing the system that the object features a single off-grid axis, and may not conform to the larger model grid specifications:</p> <p>Example \"NDSL Code\"</p> <pre><code>This type is defined using the following pattern:\n``` py\nGlobalTable_local_type = GlobalTable[(&lt;data type (Float/Int/Bool)&gt;, int(table_size))]\n```\n\nAnd accurately typed and referenced within the stencil:\n``` py\ndef stencil(data: FloatField, table: GlobalTable_local_type):\n    with computation(PARALLEL), interval(...):\n        data = table.A[desired_index]\n```\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/common_patterns/#optional-inputs","title":"Optional Inputs","text":"<p>In Fortran - and in traditional Python - it is possible to have optional inputs to a function. NDSL does not support optional field inputs (a quantity with one or more dimensions) but it is possible to create  optional scalar inputs.</p> <p>For a field, the best way to create an \"optional\" input in NDSL is to create a situation where an input (which is always suppled) has the option of being used - a calculation tied to some boolean, perhaps. Furthermore, the field supplied need not be relevant. If the option will never be used, a dummy field can be passed to satisfy the API of the function and simply never touched (or touched, with the result discarded upon completion of the function).</p> <p>For scalar inputs, the notation is quite similar to that of traditional Python. Note that NDSL requires that all scalars - if not suppled - have a default value, and that default value must be of the declared type (see line 19 of the example below):</p> <p>Example \"NDSL Code\"</p> <pre><code>``` py linenums=\"1\"\n\nfrom ndsl.dsl.gt4py import (\n    computation,\n    interval,\n    PARALLEL,\n)\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\nfrom ndsl.dsl.typing import FloatField, Float\nfrom ndsl import StencilFactory, orchestrate\nimport numpy as np\n\ndomain = (2, 2, 5)\n\nstencil_factory, quantity_factory = get_factories_single_tile(\n    domain[0], domain[1], domain[2], 0, backend=\"numpy\"\n)\n\n\ndef the_stencil(in_field: FloatField, out_field: FloatField, factor: Float = 2.0):\n    with computation(PARALLEL), interval(...):\n        out_field = in_field * factor\n\n\nclass Code:\n    def __init__(self, stencil_factory: StencilFactory):\n        orchestrate(obj=self, config=stencil_factory.config.dace_config)\n        self._the_stencil = stencil_factory.from_dims_halo(\n            func=the_stencil,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n    def __call__(self, in_field: FloatField, out_field: FloatField):\n        self._the_stencil(in_field, out_field)\n\n\nif __name__ == \"__main__\":\n    in_arr = quantity_factory.zeros(\n        dims=[X_DIM, Y_DIM, Z_DIM],\n        units=\"inputs\",\n    )\n    sz = domain[0] * domain[1] * domain[2]\n    in_arr.view[:] = np.arange(sz, dtype=Float).reshape(domain)\n\n    out_arr = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], units=\"outputs\")\n\n    code = Code(stencil_factory)\n    code(in_arr, out_arr)\n\n    print(\"Done \ud83d\ude80\")\n```\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/common_patterns/#exit-statements-and-internal-masks","title":"Exit Statements and Internal Masks","text":"<p>Often there are times where it is necessary to control the execution of specific code paths dynamically within code execution (e.g. computing precipitation if there is sufficient liquid water present). In Fortran, this can be done easily with an <code>exit</code> statement. In NDSL, the Python equivalent <code>break</code> statement is strictly forbidden, as there is no way to stop a computation early. Instead, the correct way to control execution of different coordinates on the X/Y plane is by using two dimensional boolean fields, which act as masks to turn on/off chunks of code on a per-point basis.</p> <p>Example \"Fortran Code\"</p> <pre><code>``` fortran linenums=\"1\"\nprogram conditional_calculation\n    implicit none\n\n    ! setup domain\n    integer, parameter :: X_DIM = 5\n    integer, parameter :: Y_DIM = 5\n    integer, parameter :: Z_DIM = 3\n\n    ! allocate scalars\n    integer :: i, j, k\n    real :: seed, critical_value\n\n    ! allocate arrays\n    integer, dimension(X_DIM, Y_DIM, Z_DIM) :: in_data, out_data\n    logical, dimension(X_DIM, Y_DIM) :: mask\n\n    critical_value = 5\n    ! initalize data\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            do k = 1, Z_DIM\n                call RANDOM_NUMBER(seed)\n                ! generate a random number between 0 and 10\n                in_data(i, j, k) = nint(10*seed)\n            enddo\n        enddo\n    enddo\n\n\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            do k = 1, Z_DIM\n                ! if data is above a critical value anywhere in the column\n                ! perform the subsequenc calculation on the entire column\n                if (in_data(i, j, k) &gt; critical_value) then\n                    mask(i, j) = .true.\n                    exit\n                endif\n            enddo\n            if (mask(i,j) .eqv. .true.) then\n                out_data(i,j,:) = 10*in_data\n            else\n                out_data(i,j,:) = -999\n            endif\n        enddo\n    enddo\n\n    PRINT *, \"Input data: \", in_data\n    PRINT *, \"Mask data: \", mask\n    PRINT *, \"Output data: \", out_data\n\nend program conditional_calculation\n```\n</code></pre> <p>Example \"NDSL Code\"</p> <pre><code>``` py linenums=\"1\"\nfrom ndsl.dsl.gt4py import PARALLEL, FORWARD, computation, interval, exp, function\nfrom ndsl import StencilFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\nfrom ndsl.dsl.typing import FloatField, BoolFieldIJ, Bool\nimport random\n\n\ndef check_value(data: FloatField, mask: BoolFieldIJ):\n    from __externals__ import critical_value\n\n    with computation(FORWARD), interval(...):\n        # if the data surpasses a critical value anywhere in the column, set the mask to true\n        if data &gt; critical_value:\n            mask = True\n\n\ndef computation_stencil(data_in: FloatField, data_out: FloatField, mask: BoolFieldIJ):\n    with computation(PARALLEL), interval(...):\n        if mask == True:\n            data_out = 2 * exp(data_in)\n        else:\n            data_out = -999\n\n\nclass DoSomeMath:\n    def __init__(self, stencil_factory: StencilFactory):\n\n        self.check_value = stencil_factory.from_dims_halo(\n            func=check_value,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n            externals={\n                \"critical_value\": 5,\n            },\n        )\n\n        self.computation_stencil = stencil_factory.from_dims_halo(\n            func=computation_stencil,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n    def __call__(self, in_field: FloatField, out_field: FloatField, mask_field: BoolFieldIJ):\n        self.check_value(in_field, mask_field)\n        self.computation_stencil(in_field, out_field, mask_field)\n\n\nif __name__ == \"__main__\":\n\n    domain = (5, 5, 3)\n    nhalo = 0\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n    )\n\n    do_some_math = DoSomeMath(stencil_factory)\n\n    in_field = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for i in range(in_field.field.shape[0]):\n        for j in range(in_field.field.shape[1]):\n            for k in range(in_field.field.shape[2]):\n                in_field.field[i, j, k] = round(random.uniform(0, 10), 2)\n\n    out_field = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n    mask_field = quantity_factory.zeros([X_DIM, Y_DIM], \"n/a\", dtype=Bool)\n\n    do_some_math(in_field, out_field, mask_field)\n\n    print(f\"Input data: {in_field.field}\")\n    print(f\"Mask data: {mask_field.field}\")\n    print(f\"Output data: {out_field.field}\")\n```\n</code></pre>"},{"location":"tutorials/ndsl_user_manual/common_patterns/#nested-k-loops","title":"Nested K Loops","text":"<p>Occasionally there may be situations when a nested K loop is required (such as accumulating precipitation in a column). NDSL does not have the ability to nest computation/interval statements; however, such a calculation can be performed using a <code>while</code> loop and clever indexing within a single computation/iteration statement:</p> <p>Below is an example of a nested K loop from the lagrangian_contributions stencil. It is not  currently possible in NDSL to nest a <code>with computation(PARALLEL)</code> within a  <code>with computation(PARALLEL)</code>, however a <code>while</code>loop can be used to create a nested K loop  (lines x-x).</p> <p>Example \"Fortran Code\"</p> <pre><code>```fortran linenums=\"1\"\nprogram nested_k_loop\n    implicit none\n\n    ! setup domain\n    integer, parameter :: X_DIM = 5\n    integer, parameter :: Y_DIM = 5\n    integer, parameter :: Z_DIM = 10\n\n    ! allocate scalars\n    integer :: i, j, k, kk\n    real :: seed\n\n    ! allocate arrays\n    integer, dimension(X_DIM, Y_DIM, Z_DIM) :: in_data, out_data\n\n    ! initalize data\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            do k = 1, Z_DIM\n                call RANDOM_NUMBER(seed)\n                ! generate a random value between 0 and 10\n                in_data(i, j, k) = nint(10*seed)\n            enddo\n        enddo\n    enddo\n\n    out_data(:,:,:) = 0\n    do i = 1, X_DIM\n        do j = 1, Y_DIM\n            do k = 1, Z_DIM\n                do kk = 1, k\n                    ! sum all values at and below the current point\n                    out_data(i,j,k) = out_data(i,j,k) + in_data(i,j,kk)\n                enddo\n            enddo\n        enddo\n    enddo\n\n    PRINT *, \"Input data: \", in_data(1,1,:)\n    PRINT *, \"Output data: \", out_data(1,1,:)\n\nend program nested_k_loop\n```\n</code></pre> <p>Example \"NDSL Code\"</p> <pre><code>``` py linenums=\"1\"\nfrom ndsl.dsl.gt4py import (\n    computation,\n    interval,\n    PARALLEL,\n)\nfrom gt4py.cartesian.gtscript import THIS_K\nfrom ndsl import StencilFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\nfrom ndsl.dsl.typing import FloatField\nimport random\n\n\ndef nested_k_calculation(\n    in_data: FloatField,\n    out_data: FloatField,\n):\n\n    with computation(PARALLEL), interval(...):\n        nested_k_index = 0\n        while nested_k_index &lt;= THIS_K:\n            out_data = out_data + in_data.at(K=nested_k_index)\n            nested_k_index += 1\n\n\nclass Code:\n    def __init__(self, stencil_factory: StencilFactory):\n\n        # build stencil\n        self.constructed_stencil = stencil_factory.from_dims_halo(\n            func=nested_k_calculation,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n    def __call__(\n        self,\n        in_data: FloatField,\n        out_data: FloatField,\n    ):\n        # execute stencil\n        self.constructed_stencil(\n            in_data,\n            out_data,\n        )\n\n\nif __name__ == \"__main__\":\n\n    # setup domain and generate factories\n    domain = (5, 5, 10)\n    nhalo = 0\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n        backend=\"debug\",\n    )\n\n    # initialize data\n    out_data = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n\n    in_data = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for i in range(in_data.field.shape[0]):\n        for j in range(in_data.field.shape[1]):\n            for k in range(in_data.field.shape[2]):\n                in_data.field[i, j, k] = round(random.uniform(0, 10))\n\n    # build stencil\n    code = Code(stencil_factory)\n\n    # execute stencil\n    code(in_data, out_data)\n\n    print(in_data.field[0, 0, :])\n    print(out_data.field[0, 0, :])\n```\n</code></pre> <p>Nested K loops provide an excellent example of how thinking outside the box - and possessing a willingness to re-approach traditional coding practices - allows for a much wider application of the software and reveals that the rules put in place by NDSL are not necessarily as restrictive as they may seem.</p>"},{"location":"tutorials/ndsl_user_manual/common_patterns/#goto-statements","title":"Goto Statements","text":"<p>In Fortran, the <code>goto</code> construct allows the user to jump to another portion of the code. NDSL is incapable of \"jumping\" from one portion of code to another; stencils are always executed linearly and completely. Since <code>goto</code> statement are tremendously flexile, there is no \"standard\" way of translating a piece of code with a <code>goto</code> statement into NDSL. Indeed, the presence of <code>goto</code> statements often signals a non-parallelizable code structure, which requires refactoring to be implemented in NDSL. During this process, however, the aforementioned patterns - particularly the use of masks - may be extremely useful.</p>"},{"location":"tutorials/ndsl_user_manual/data/","title":"NDSL Data Types and Storage System","text":""},{"location":"tutorials/ndsl_user_manual/data/#types","title":"Types","text":"<p>NDSL uses unique data types (<code>Float</code>/<code>Int</code>/<code>Bool</code>) which link to commonly used Python data types (<code>float</code>/<code>int</code>/<code>bool</code>). Unlike python, however, with NDSL these will be either 32 or 64 bit, depending on the desired execution environment. By default, NDSL executes in 64 bit precision. To control this manually, ensure the environmental variable GT4PY_LITERAL_PRECISION is set to either 32 or 64 prior to execution.</p>"},{"location":"tutorials/ndsl_user_manual/data/#fields","title":"Fields","text":"<p>Unlike traditional Python, NDSL data types also implicitly carry information about the shape of the object. The types <code>Float</code>/<code>Int</code>/<code>Bool</code> all denote scalar (dimensionless) objects.</p> <p>All objects with one or more dimensions are considered \"fields\". NDSL assumes a cartesian I/J/K coordinate system, where I and J are horizontal dimensions and K is the vertical dimension, but allows these to be defined dynamically (more on this in the next section).</p> <p>NDSL fields are typed according to the following:  <code>[Type]Field[Axis][Precision]</code> - with <code>Type = [Int, Float, Bool]</code>; <code>Axis = [I, J, IJ, K]</code>; <code>Precision = [32, 64]</code> (optional), if not specified then default to global precision.</p> <p>Note that there is no <code>[Type]FieldIJK</code>; this is simply <code>[Type]Field</code>. These field types are only used within NDSL-specific code (\"stencils\", described in the next section) to provide the system with expected shapes  of arrays, facilitating many of the behind-the-scenes optimization processes.</p> <p>Below is few examples of NDSL field types:</p> <ul> <li><code>FloatFieldI</code>: one dimensional (I) field of type Float</li> <li><code>IntFieldK</code>: one dimensional (K) field of type Int</li> <li><code>FloatFieldIJ</code>: two dimensional (I, J) field of type Float</li> <li><code>IntField</code>: three dimensional (I, J, K) field of type Int</li> </ul> <p>NDSL has the ability to add a fourth dimension. This is a more complex process, and will be discussed more in the future once we have a firm grasp of the basics.</p>"},{"location":"tutorials/ndsl_user_manual/data/#data-storage","title":"Data Storage","text":"<p>NDSL stores all field (&gt;0 dimensions) data in a \"quantity\" object. Quantities allocate memory and assign type automatically based on the dimensions and axis present. Scalars are not stored in quantities, and therefore do not have access to the following functionality.</p> <p>Below is an example of how to initialize an NDSL quantity with three dimensions:</p> <pre><code>from ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM\n\ndomain = (3, 2, 1)\nnhalo = 0\nstencil_factory, quantity_factory = get_factories_single_tile(\n    domain[0], domain[1], domain[2], nhalo,\n)\n\nquantity_example = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\", dtype=Float)\n</code></pre> <p>For now, let's just worry about line 10. Here, we use the <code>quantity_factory</code> object (more about this later) to initialize a quantity. The first argument, <code>[X_DIM, Y_DIM, Z_DIM]</code>, tells the system which dimensions will be present. The size of each dimension is set in the <code>quantity_factory</code> object, and is applied automatically. This size is immutable - to obtain a different size quantity, you must generate another <code>quantity_factory</code>.</p> <p>The second argument, <code>\"n/a\"</code> in this case, specifies the units of the data stored. This is only for metadata and ease of use, and has no impact on calculations. The final argument <code>dtype</code> controls the type of data stored in the quantity, and can be <code>Float</code>/<code>Int</code>/<code>Bool</code>.</p> <p>Finally, we can print the quantity we have just created to check our work. Based on the code above,</p> <pre><code>print(quantity_example)\n</code></pre> <p>will return:</p> <pre><code>Quantity(\n    data=\n[[[0. 0.]\n  [0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]\n  [0. 0.]]],\n    dims=('x', 'y', 'z'),\n    units=n/a,\n    origin=(0, 0, 0),\n    extent=(3, 2, 1)\n)\n</code></pre> <p>Here you can see information about the dimensions present, size (extent), units, and origin (a concept we will discuss later).</p> <p>But wait, if our extent is (3, 2, 1), why is <code>data</code> size (4, 3, 2)?</p>"},{"location":"tutorials/ndsl_user_manual/data/#center-vs-interface-computations","title":"Center vs Interface Computations","text":"<p>This extra index along each dimension are for interface computations. In weather and climate modeling, there are often situations where it is necessary to perform calculations on the interface between grid points, rather than at the center of grid points - requiring one more point along that particular axis. NDSL always creates quantities with one extra grid point on each dimension for this purpose; however, this extra point is ignored by the system unless you explicitly state that it should be considered by replacing (for example) <code>Z_DIM</code> with <code>Z_INTERFACE_DIM</code>. Specifying <code>Z_INTERFACE_DIM</code> does not add an additional point along that dimension. It simple \"enables\" the point that is already there.</p>"},{"location":"tutorials/ndsl_user_manual/data/#halo","title":"Halo","text":"<p>NDSL quantities can be constructed with a halo on the X and Y dimensions. This is useful when working with components such as the FV3 core, which uses a halo to facilitate data exchange between faces of the cube. In the example above, the halo is set to zero (<code>nhalo=0</code>), but this can be set to any value smaller than the smallest X/Y dimension.</p>"},{"location":"tutorials/ndsl_user_manual/data/#accessing-data","title":"Accessing Data","text":"<p>There are two main methods for accessing data stored within a quantity:</p> <ul> <li> <p><code>quantity.field[:]</code>: returns the compute domain (excludes halos) of the quantity as a NumPy-like  array. Note this will include the interface dimension point for axis specified to be operating on the interface. Note that, since this is a NumPy-like  array, it can be accessed using normal Python accessing rules, and much of the functionality of  NumPy arrays is also available.</p> </li> <li> <p><code>quantity.data[:]</code>: returns all data contained within the quantity, including the interface dimension point (regardless of if it is including in the compute domain) and any halo present.</p> </li> </ul>"},{"location":"tutorials/ndsl_user_manual/data/#stencilquantity-factories","title":"Stencil/Quantity Factories","text":"<p>NDSL comes with a number of pre-designed factory functions (e.g. <code>get_factories_single_tile</code>). These are designed to provide users with easy entry points to features while developing new code.</p> <p>When working in a larger system the tasks of determining the domain and constructing factories (lines 4-8 from the example above) are done automatically, and as such this code will not be needed.</p> <p>Therefore, we recommend you don't worry about how <code>get_factories_single_tile</code> works for now. As we move through more advanced guides we will introduce additional details and complexities, and those can be reapplied to understand these functions, but knowledge of this function is not critical to using the software.</p> <p>The <code>QuantityFactory</code> and <code>StencilFactory</code> types will be present in all your code, but once again you need not worry about how they function. For now, just remember that a <code>QuantityFactory</code> produces quantities and a <code>StencilFactory</code> produces stencils (something we will talk about in the next guide), and as time progresses, we will introduce some of their more important methods.</p>"},{"location":"tutorials/ndsl_user_manual/data/#summary","title":"Summary","text":"<p>In this guide, we have discussed the unique NDSL data types and storage objects, focusing on how to create, access, and print their contents.</p> <p>Next, we will discuss how to write accelerable code with NDSL.</p>"},{"location":"tutorials/ndsl_user_manual/ndsl_introduction/","title":"Introduction to NDSL","text":"<p>This user manual introduces relevant concepts and provides knowledge needed to use NDSL. By the end of this guide, we will introduce:</p> <ul> <li>Unique data types and storage objects used by NDSL</li> <li>How to write basic NDSL code</li> <li>Advanced NDSL features and capabilities</li> <li>Examples of how to implement common patterns in NDSL</li> <li>Good coding practices to maintian when using NDSL</li> <li>How and why classes are used with NDSL</li> <li>The underlying infrastrcuture used by NDSL</li> </ul> <p>This guide is not a FAQ or a replacement for proper documentation. These resources are available [LINK(s) HERE]</p>"},{"location":"tutorials/ndsl_user_manual/why_use_classes/","title":"Why use Classes?","text":""},{"location":"tutorials/ndsl_user_manual/why_use_classes/#what-is-a-python-class","title":"What is a Python Class?","text":"<p>A Python <code>class</code> is like a template or blueprint for creating objects \u2014 in this example, our class  creates tools to check if the condensation is likely to occur based on temperature and dew point at a certain location.</p> <p>Think of it like this:  - A <code>function</code> does one task.  - A <code>class</code> bundles together data and functions (called methods) that relate to a single concept \u2014  like checking condensation.</p> <p>For example: <pre><code>class CondensationChecker:\n    def __init__(self, location, temperature_c, dew_point_c):\n        self.location = location\n        self.temperature_c = temperature_c\n        self.dew_point_c = dew_point_c\n\n    def check_condensation(self):\n        return self.temperature_c &lt;= self.dew_point_c\n\n    def report(self):\n        # Prints the current condition and whether condensation is likely\n</code></pre></p> <p>Here:  The data: temperature, dew point, location  The behavior: check_condensation(), report() </p>"},{"location":"tutorials/ndsl_user_manual/why_use_classes/#what-are-classes-used-for","title":"What are Classes used for?","text":"<p>In this example, we use a <code>class</code> to create objects that represent weather conditions that will be used to check if condensation is likely to occur.</p> <pre><code>station = CondensationChecker(\"Berlin\", 12.0, 12.5)\nstation.report()\n</code></pre> <p>The object <code>station</code> holds its own data and can run its own analysis on the data provided.</p>"},{"location":"tutorials/ndsl_user_manual/why_use_classes/#why-use-a-class-instead-of-just-functions","title":"Why use a Class instead of just functions?","text":"<p>Let's compare using a class vs. just using functions.</p> <p>With just functions:</p> <pre><code>def check_condensation(temp, dew_point):\n    return temp &lt;= dew_point\n</code></pre> <p>You\u2019d need to manually pass temperature and dew point every single time, and it doesn't naturally  group this data together. You also can't easily add more features like location, time, or logging.</p> <p>With a <code>class</code>: <pre><code>station = CondensationChecker(\"Berlin\", 12.0, 12.5)\nstation.report()\n</code></pre> This is a much cleaner option \u2014 all related data is stored inside the object, and methods operate  on that data.</p>"},{"location":"tutorials/ndsl_user_manual/why_use_classes/#benefits-of-using-a-class","title":"Benefits of using a Class","text":"<p>Organization</p> <p>A class brings data and the functions that operate on it together in one place.</p> <p>In CondensationChecker:  The data: temperature, dew point, location  The behavior: check_condensation(), report() </p> <p>These things belong together logically. Instead of keeping temperature and dew point as separate  variables and writing separate functions, the class keeps them bundled as one logical unit.</p> <p>Reusability</p> <p>You can reuse the same class to create multiple objects representing different conditions \u2014  without repeating code.</p> <p>Example: <pre><code>station1 = CondensationChecker(\"London\", 15, 12)\nstation2 = CondensationChecker(\"Barcelona\", 28, 27)\n\nstation1.report()\nstation2.report()\n</code></pre></p> <p>Each station is independent, and the logic to check condensation is shared and reusable.</p> <p>Without a class, you'd have to manage multiple sets of variables manually and pass them into  functions every time \u2014 more error-prone and harder to manage.</p> <p>Easy to Add New Features</p> <p>When your code grows in complexity, classes make it easy to add new functionality without breaking  existing logic.</p> <p>For example, you can add a method to estimate relative humidity based on existing data: <pre><code>def estimate_relative_humidity(self):\n    # Use formula here\n</code></pre></p> <p>This method now becomes part of the condensation checker \u2014 you don\u2019t have to touch outside code.</p> <p>Modularity</p> <p>Classes act like building blocks for larger systems. You can isolate pieces of your program into  logical units.</p> <p>Maintainability and Cleanliness: Easier to Read, Debug, and Scale</p> <p>When your project grows, keeping code maintainable is very important.</p> <p>With a class:  - Each part of the program has a clear purpose.  - You can fix or update just one class without affecting others.  - You don\u2019t have to trace global variables across multiple files. </p> <p>If someone new joins your team, they can understand what CondensationChecker does just by reading  that one class.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/","title":"Writing Code in NDSL","text":"<p>NDSL finds power in its ability to accelerate and dynamically compile code. To do this, NDSL creates an interface to two GT4Py constructs which are used to denote and contain accelerable  code: \"stencils\" and \"functions\". Conceptually, the two are similar, but their uses are different.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#stencils","title":"Stencils","text":"<p>Stencils are the primary method of creating parallelizable code with NDSL, and indeed in NDSL everything must begin with a stencil.</p> <p>Within a 3-dimensional domain, NDSL evaluates computations in two parts. If we assume an (I, J, K) coordinate system as a reference, NDSL separates computations in the horizontal (I, J) plane from the vertical (Z) column.</p> <p>In the horizontal plane, computations are always executed in parallel, which means that there is no assumed calculation order within the plane. This concept is the foundation of of NDSL's performance capabilities, and cannot be altered.</p> <p>In the vertical column, computations are performed by an iteration policy that is declared within the stencil. This is done to enable the implementation of more scientific patterns using NDSL. We will discuss this in more detail shortly.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#basic-stencil-example","title":"Basic Stencil Example","text":"<p>To demonstrate how to implement a NDSL stencil and introduce the most important keywords, let's step through an example of a stencil that copies the values of one field into another field.</p> <p>First, we import several packages:</p> <pre><code>from ndsl import StencilFactory\nfrom ndsl.boilerplate import get_factories_single_tile\nfrom ndsl.constants import X_DIM, Y_DIM, Z_DIM, Z_INTERFACE_DIM\nfrom ndsl.dsl.typing import Float, FloatField\nimport gt4py.cartesian.gtscript as gtscript\nfrom gt4py.cartesian.gtscript import PARALLEL, computation, interval\n</code></pre> <p>Next, we define our stencil template:</p> <pre><code>def copy_stencil(in_field: FloatField, out_field: FloatField):\n    with computation(PARALLEL):\n        with interval(...):\n            out_field = in_field\n</code></pre> <p>Note that there is no return statement here. Stencils modify fields in place may not contain a return statement, and therefore must have all inputs and outputs passed into it at call.</p> <p>This stencil template has a number of important features and keywords. Let's start with the inputs: <code>in_field</code> and <code>out_field</code>. These are both declared to be type <code>FloatField</code>. This notation is used in traditional Python, and may be familiar to you as optional \"type hinting\". For stencils (and functions) these type hints are required, and the code will not execute if the supplied type does not match the declared type.</p> <p>Looking into the stencil code, we can see the two most important keywords in NDSL.</p> <p>The statement <code>with computation([argument])</code> sets the iteration policy of the nested code. In this case, we have declared <code>with computation(PARALLEL), signaling that *all three* dimensions can be executed in parallel. The statement</code>with interval([argument])<code>sets the domain of the nested code. Once again, in this case, we have declared</code>with interval(...)`, signaling that the computation should apply to all vertical levels in the compute domain.</p> <p>A stencil may have multiple sequential computation policies, and each computation policy may have multiple intervals.</p> <p>Now we set up our class:</p> <pre><code>class CopyData:\n    def __init__(self, stencil_factory: StencilFactory):\n\n        self.constructed_copy_stencil = stencil_factory.from_dims_halo(\n            func=copy_stencil,\n            compute_dims=[X_DIM, Y_DIM, Z_DIM],\n        )\n\n    def __call__(self, in_quantity: FloatField, out_quantity: FloatField):\n        self.constructed_copy_stencil(in_quantity, out_quantity)\n</code></pre> <p>Here is where we actually build our stencil (lines 14-17). Behind the scenes the system is compiling code based on a number of considerations, most important of which is the target architecture: CPU or GPU. In this example, we use the method <code>from_dims_halo</code>, which is the most straightforward way to build a stencil. With this method, you will always have to specify <code>func</code> (to determine what stencil is being built), and <code>compute_dims</code>. Stencils can also be built using <code>from_origin_domain</code>, which requires manual entry of the <code>origin</code> and <code>domain</code> of the stencil. Behind the scenes, <code>from_dims_halo</code> computes these and calls <code>from_origin_domain</code> automatically, so we recommend using <code>from_dims_halo</code>, as it will suffice for the vast majority of situations.</p> <p>Finally we can run the program:</p> <pre><code>if __name__ == \"__main__\":\n\n    domain = (5, 5, 3)\n    nhalo = 0\n    backend = \"numpy\"\n    stencil_factory, quantity_factory = get_factories_single_tile(\n        domain[0],\n        domain[1],\n        domain[2],\n        nhalo,\n        backend,\n    )\n\n    copy_data = CopyData(stencil_factory)\n\n    in_quantity = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    for i in range(in_quantity.field.shape[0]):\n        for j in range(in_quantity.field.shape[1]):\n            for k in range(in_quantity.field.shape[2]):\n                in_quantity.field[i, j, k] = i * 100 + j * 10 + k\n\n    out_quantity = quantity_factory.zeros([X_DIM, Y_DIM, Z_DIM], \"n/a\")\n    out_quantity.field[:] = -999\n\n    copy_data(in_quantity, out_quantity)\n</code></pre> <p>To run the code, we first need to build the factories that will be used to construct the stencil and quantities. In this small-scale example, we use the boilerplate function <code>get_factories_single_tile</code>, supplying it the domain size, halo size, and backend. This function has limited capabilities, but is sufficient for most small scale cases - testing code, debugging specific issues, etc. For larger projects (such as a full Earth system model), it may be necessary to move away from the boilerplate code to get more control over how these factoris are generated - but for now, just focus on using <code>get_factories_single_tile</code>, as that will serve you well while you are learning the systems.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#temporary-fields","title":"Temporary Fields","text":"<p>NDSL has the ability to generate temporary quantities within a stencil. All temporary quantities (defined as variables which are used within the stencil but not passed to the stencil at call) are initialized as a field of dimensions equal to the full stencil domain. These fields can be used just as any other field can be used, and are unavailable outside of the stencil.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#offsets","title":"Offsets","text":"<p>Within a stencil, points are referenced relative to each other. For example, the statement <code>field[0, 0, 1]</code> implies that you want an offset of positive one along the K axis (Z dimension in our example). This offset occurs at each point in the domain independently, so you will always  be reading one \"above\" your current position.</p> <p>Offsets can only occur at read; NDSL does not allow writing with an offset. Additionally, it is not possible to write to a field when you read from it with an offset in the same statement (e.g. <code>field = field[0, 0, 1]</code> is illegal).</p> <p>With this knowledge, we can now create a stencil that copies data from the level above:</p> <pre><code>def copy_with_offset(in_field: FloatField, out_field: FloatField):\n    with computation(PARALLEL):\n        with interval(0, -1):\n            out_field = in_field[0, 0, 1]\n</code></pre> <p>Note that the interval is restricted to prevent the computation from occurring on the top level of <code>out_field</code>, as looking \"up\" from the top level would look into the extra point included for interface calculations. Since this computation is not being performed on the interface (both quantities are created using <code>Z_DIM</code>, not <code>Z_INTERFACE_DIM</code>), that row of data will be zero, and accessing it here will have unintended consequences in subsequent calculations.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#intervals-and-iteration-policies","title":"Intervals and Iteration Policies","text":"<p>The statement <code>with interval()</code> controls the subset of the K axis over which the stencil is executed, and is controlled using traditional Python indexing (e.g. <code>interval(0, 10)</code>, <code>interval(1, -1)</code>). The argument <code>None</code> can be used to say \"go to end of the domain\" (e.g. <code>interval(10, None)</code>). The argument <code>...</code> signals compute at all levels, equivalent to <code>0, None</code>.</p> <p>NDSL has three possible iteration policies: <code>PARALLEL</code>, <code>FORWARD</code>, and <code>BACKWARD</code>. As previously mentioned, choosing <code>PARALLEL</code> states that all three dimension will be executed in parallel. In this state, each point in the compute domain is computed independently in the fastest possible order. This means that fields are being written in random order, and therefore any operations which depend on data at other points in a field which is being written (e.g. <code>out_field = field_computed_locally[0, 0, 1]</code>) cannot use <code>PARALLEL</code>.</p> <p>The <code>FORWARD</code> and <code>BACKWARD</code> options can be considered non-parallel options for the K axis. These options require that all calculations for a particular K level are computed before moving on to the next K level. This is often significantly slower than <code>PARALLEL</code>, but ensures that each kernel has the correct information for the present level before moving on to the next one. <code>FORWARD</code> executes from the first argument in the <code>with interval()</code> statement to the second (e.g. <code>with computation(FORWARD), interval(0, 10)</code> begins at 0 and ends at 9), while <code>BACKWARD</code> does the opposite (begins at 9, ends at 0).</p> <p><code>FORWARD</code> and <code>BACKWARD</code> are useful for more complex situations where data is being read with an offset and written in the same stencil:</p> <pre><code>def offset_read_with_write(in_field: FloatField, out_field: FloatField):\n    with computation(FORWARD):\n        with interval(0, -1):\n            out_field = in_field[0, 0, 1]\n            in_field = in_field * 2\n</code></pre> <p>In this example, <code>in_field</code> is being read in but also modified. It is therefore necessary to use <code>FORWARD</code> to ensure that there is not a situation where <code>in_field</code> is doubled at a level <code>n</code> before it is read at level <code>n - 1</code>.</p> <p>Using offsets often requires a careful consideration of iteration policy.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#flow-control","title":"Flow Control","text":"<p>A number of traditional Python flow control keywords can be used within NDSL stencils. These are:</p> <ul> <li><code>if</code></li> <li><code>elif</code></li> <li><code>else</code></li> <li><code>while</code></li> </ul>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#conditionals","title":"Conditionals","text":"<p>NDSL allows conditionals to be used inside of a stencil in the same way they would be used in traditional Python.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#loops","title":"Loops","text":"<p>It is possible to use a <code>while</code> loops within an NDSL stencil. All loops must have definite limits (e.g. no <code>while True</code>), but these limits do not necessarily need to be hard coded. Other variables can be used a bounds of the loop, creating a situation where the bound of the loop is potentially different at each point within the domain.</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#functions","title":"Functions","text":"<p>Functions in NDSL - much like traditional Python functions - serve as a way to store commonly used code so that it can be referenced easily from multiple places. NDSL functions (hereafter referred to as \"functions\") can only be used from within stencils, and often act as extentions of the stencil, performing repetitive or particualrly detailed operations. Critically, however, functions have a additional set of rules which make them different in both appearence and operation stencils which house them.</p> <p>Functions: - cannot be called outside of a stencil - cannot contain the keywords <code>computation</code> or <code>interval</code> (they rely on the host stencil for this info) - are \"point operations\" - the are executed independently at each point in the compute domain (see below) - must have a single return statement, but can return multiple values - are not tied to a single stencil, and may be reused multiple times in one or many stencils - do not need to be independently constructed with a stencil factory (they are built with the stencil)</p> <p>The concept of a \"point operation\" is particularly important, and warrants its own discussion. There are two important ideas which come along with this concept: functions perform operation at each point in the compute domain independently, in isolation from all other points; and (despite this) functions may take scalar or fields as inputs. Functions take an entire field as an import (despite only operating on a single point in any particular instance) to allow for offset reads of these inputs. It may be necessary read an offset from a field within a stencil, and it would be overly combersome to require a series of scalar inputs for each of these offsets.</p> <p>Beyond their use for potentially reading offsets from the inputs, the concept of a field is effectively banned within a stencil. All calculations are performed using scalars. There are no arrays, lists, fields, etc. Furthermore, reading a offset (such as <code>field[0, 0, 1]</code>) will alwyas produce a scalar, which fits this paradigm as the rest of the field is effectively discarded.</p> <p>As a consequence of these rules, functions always return a scalar value. The stencil then takes this value and writes it to the correct place in the field.</p> <p>Below is an example of a NDSL function, called from within a stencil:</p> <pre><code>@gtscript.function\ndef add_five(in_field: FloatField):\n    out_value = in_field + 5\n    return out_value\n\n\ndef copy_stencil(in_field: FloatField, out_field: FloatField):\n    with computation(PARALLEL):\n        with interval(...):\n            out_field = add_five(in_field)\n</code></pre> <p>It is worth reiterating that, while functions can only have a single return statment, they can return multiple value. Such a case would take the following pattern: <pre><code>    field_1, field_2 = my_function(input_1, input_2, input_3)\n</code></pre></p> <p>Note that functions with multiple returns cannot be integrated into larger expressions - they must be written on their own line, and each output must be recieved (or discarded with <code>_</code>).</p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#builtin-functions","title":"Builtin Functions","text":"<p>NDSL provides access to a number of builtin GT4Py functions:</p> <ul> <li><code>abs</code>: absolute value</li> <li><code>min</code>: minimum</li> <li><code>max</code>: maximum</li> <li><code>mod</code>: modulo</li> <li><code>sin</code>: sine</li> <li><code>cos</code>: cosine</li> <li><code>tan</code>: tangent</li> <li><code>sinh</code>: hyperbolic sine</li> <li><code>cosh</code>: hyperbolic cosine</li> <li><code>tanh</code>: hyperbolic tangent</li> <li><code>asin</code>: arc sine</li> <li><code>acos</code>: arc cosine</li> <li><code>atan</code>: arc tangent</li> <li><code>asinh</code>: inverse hyperbolic sine</li> <li><code>acosh</code>: inverse hyperbolic cosine</li> <li><code>atanh</code>: inverse hyperbolic tangent</li> <li><code>sqrt</code>: square root</li> <li><code>exp</code>: inverse hyperbolic sine</li> <li><code>log</code>: natural log</li> <li><code>log10</code>: base 10 log</li> <li><code>gamma</code>: gamma function</li> <li><code>cbrt</code>: cubic root</li> <li><code>isfinite</code>: determine if number is finite</li> <li><code>isinf</code>: determine if number is infinite</li> <li><code>isnan</code>: determine if number is nan</li> <li><code>floor</code>: round down to nearest integer</li> <li><code>ceil</code>: round up to nearest integer</li> <li><code>trunc</code>: truncate</li> <li><code>round</code>: round to nearest integer</li> <li><code>erf</code>: error function</li> <li><code>erfc</code>: complementary error function</li> <li><code>int32</code>: cast to a 32 bit integer</li> <li><code>int64</code>: cast to a 64 bit integer</li> <li><code>float32</code>: cast to a 32 bit float</li> <li><code>float64</code>: cast to a 64 bit float</li> </ul> <p>All of these functions are available via the module <code>ndsl.dsl.gt4py</code></p>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#stencils-vs-functions","title":"Stencils vs Functions","text":"<p>Every block of NDSL-accelerable code begins and ends in a stencil. The stencil signals that parallel computation is possible, defines the iteration policy and sets the interval. From this point the following logic applies:</p> <ul> <li> <p>It is not possible to call one stencil from within another, as that would create a situation where there are two layers of parallelization. If you want to reuse code across multiple stencils, it should be put into a function.</p> </li> <li> <p>For similar reasons, it is not possible to call a stencil from within a function.</p> </li> <li> <p>It is possible to call one function from within another function, and there is no limit on maximum depth.</p> </li> </ul>"},{"location":"tutorials/ndsl_user_manual/writing_ndsl_code/#summary","title":"Summary","text":"<p>This guide introduced the basic principles of stencils and functions. We have discussed how and when to use each, and highlighted features that make their use more flexible, and discussed limitations which act as guardrails against unfavorable outcomes.</p> <p>With this knowledge, it is possible to use NDSL and obtain much of the designed performance; however, development may at times seem tedious and implementing more complicated patterns may be challenging. Future sections will introduce more complex ideas and discuss quality of life features which aim to alleviates these issues.</p>"}]}